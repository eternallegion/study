{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48be7a35-9150-4a08-8ea5-8ffde639a380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'pretrained_models/2stems', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.7\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
      "INFO:tensorflow:Apply unet for accompaniment_spectrogram\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from pretrained_models/2stems/model\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 18:19:32.070264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-22 18:19:32.070362: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:spleeter:File /home/eternal/song/output_directory/04. Memories/vocals.wav written succesfully\n",
      "INFO:spleeter:File /home/eternal/song/output_directory/04. Memories/accompaniment.wav written succesfully\n",
      "분리가 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from spleeter.separator import Separator\n",
    "\n",
    "# 분리할 노래 파일 경로\n",
    "input_audio_path = '/home/eternal/song/04. Memories.mp3'\n",
    "output_path = '/home/eternal/song/output_directory'\n",
    "\n",
    "# Spleeter separator 객체 생성 (2스템 분리: 보컬과 나머지)\n",
    "separator = Separator('spleeter:2stems')\n",
    "\n",
    "# 분리 수행\n",
    "separator.separate_to_file(input_audio_path, output_path)\n",
    "\n",
    "print('분리가 완료되었습니다.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcd2896d-d24b-474e-8bdd-2e8bc4289860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'pretrained_models/2stems', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.7\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Apply unet for vocals_spectrogram\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <generator object Estimator.predict at 0x7f1908209620>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eternal/.local/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 618, in predict\n",
      "    with tf.Graph().as_default() as g:\n",
      "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/eternal/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 5821, in get_controller\n",
      "    with super(_DefaultGraphStack,\n",
      "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/eternal/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 5633, in get_controller\n",
      "    raise AssertionError(\n",
      "AssertionError: Nesting violated for default stack of <class 'tensorflow.python.framework.ops.Graph'> objects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Apply unet for accompaniment_spectrogram\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from pretrained_models/2stems/model\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 18:42:30.534355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-22 18:42:30.534465: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:spleeter:File /home/eternal/song/output_directory/04. Memories/04. Memories/vocals.wav written succesfully\n",
      "INFO:spleeter:File /home/eternal/song/output_directory/04. Memories/04. Memories/accompaniment.wav written succesfully\n",
      "보컬 분리 완료\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/eternal/song/output_directorys/04. Memories/output_no_silence.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m     non_silent_audio \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m chunk\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# 결과 저장\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mnon_silent_audio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m공백 제거 완료 및 저장\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# 임시 출력 디렉토리 정리 (선택 사항)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydub/audio_segment.py:867\u001b[0m, in \u001b[0;36mAudioSegment.export\u001b[0;34m(self, out_f, format, codec, bitrate, parameters, tags, id3v2_version, cover)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (codec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m parameters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    863\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCan not invoke ffmpeg when export format is \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    864\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecify an ffmpeg raw format like format=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms16le\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m instead \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    865\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mor call export(format=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) with no codec or parameters\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 867\u001b[0m out_f, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_fd_or_path_or_tempfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m out_f\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydub/utils.py:60\u001b[0m, in \u001b[0;36m_fd_or_path_or_tempfile\u001b[0;34m(fd, mode, tempfile)\u001b[0m\n\u001b[1;32m     57\u001b[0m     close_fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fd, basestring):\n\u001b[0;32m---> 60\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     close_fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/eternal/song/output_directorys/04. Memories/output_no_silence.wav'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from spleeter.separator import Separator\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "# 파일 경로 설정\n",
    "input_audio_path = '/home/eternal/song/04. Memories.mp3'  # 입력 오디오 파일 경로\n",
    "temp_output_directory = '/home/eternal/song/output_directory/04. Memories'   # 임시 출력 디렉토리\n",
    "output_file_path = '/home/eternal/song/output_directorys/04. Memories/output_no_silence.wav'        # 최종 출력 파일 경로\n",
    "\n",
    "# 임시 출력 디렉토리가 존재하지 않으면 생성\n",
    "os.makedirs(temp_output_directory, exist_ok=True)\n",
    "\n",
    "# Spleeter separator 객체 생성 (2스템 분리: 보컬과 나머지)\n",
    "separator = Separator('spleeter:2stems')\n",
    "\n",
    "# 보컬 분리\n",
    "separator.separate_to_file(input_audio_path, temp_output_directory)\n",
    "print('보컬 분리 완료')\n",
    "\n",
    "# 분리된 보컬 파일 로드\n",
    "vocal_file = os.path.join(temp_output_directory, '04. Memories', 'vocals.wav')\n",
    "vocal_audio = AudioSegment.from_wav(vocal_file)\n",
    "\n",
    "# 공백 제거\n",
    "chunks = split_on_silence(vocal_audio, \n",
    "                          min_silence_len=500, \n",
    "                          silence_thresh=-40)\n",
    "\n",
    "# 공백이 제거된 오디오를 다시 하나의 오디오로 병합\n",
    "non_silent_audio = AudioSegment.empty()\n",
    "for chunk in chunks:\n",
    "    non_silent_audio += chunk\n",
    "\n",
    "# 결과 저장\n",
    "non_silent_audio.export(output_file_path, format=\"wav\")\n",
    "print('공백 제거 완료 및 저장')\n",
    "\n",
    "# 임시 출력 디렉토리 정리 (선택 사항)\n",
    "import shutil\n",
    "shutil.rmtree(temp_output_directory)\n",
    "print('임시 파일 정리 완료')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c17836-d957-4902-ad79-4596496128ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'pretrained_models/2stems', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.7\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
      "INFO:tensorflow:Apply unet for accompaniment_spectrogram\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from pretrained_models/2stems/model\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 18:45:10.828252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-22 18:45:10.828325: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:spleeter:File /home/eternal/song/output_directory/04. Memories/04. Memories/vocals.wav written succesfully\n",
      "INFO:spleeter:File /home/eternal/song/output_directory/04. Memories/04. Memories/accompaniment.wav written succesfully\n",
      "보컬 분리 완료\n",
      "공백 제거 완료 및 저장\n",
      "임시 파일 정리 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from spleeter.separator import Separator\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "# 파일 경로 설정\n",
    "input_audio_path = '/home/eternal/song/04. Memories.mp3'  # 입력 오디오 파일 경로\n",
    "temp_output_directory = '/home/eternal/song/output_directory/04. Memories'   # 임시 출력 디렉토리\n",
    "output_file_path = '/home/eternal/song/output_directorys/04. Memories/output_no_silence.wav'        # 최종 출력 파일 경로\n",
    "\n",
    "# 임시 출력 디렉토리가 존재하지 않으면 생성\n",
    "os.makedirs(temp_output_directory, exist_ok=True)\n",
    "\n",
    "# 최종 출력 디렉토리가 존재하지 않으면 생성\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "\n",
    "# Spleeter separator 객체 생성 (2스템 분리: 보컬과 나머지)\n",
    "separator = Separator('spleeter:2stems')\n",
    "\n",
    "# 보컬 분리\n",
    "separator.separate_to_file(input_audio_path, temp_output_directory)\n",
    "print('보컬 분리 완료')\n",
    "\n",
    "# 분리된 보컬 파일 로드\n",
    "vocal_file = os.path.join(temp_output_directory, 'vocals.wav')\n",
    "if not os.path.exists(vocal_file):\n",
    "    # 서브 디렉토리에 저장되었을 경우를 대비해 추가 확인\n",
    "    sub_dir = os.path.splitext(os.path.basename(input_audio_path))[0]\n",
    "    vocal_file = os.path.join(temp_output_directory, sub_dir, 'vocals.wav')\n",
    "\n",
    "vocal_audio = AudioSegment.from_wav(vocal_file)\n",
    "\n",
    "# 공백 제거\n",
    "chunks = split_on_silence(vocal_audio, \n",
    "                          min_silence_len=500, \n",
    "                          silence_thresh=-40)\n",
    "\n",
    "# 공백이 제거된 오디오를 다시 하나의 오디오로 병합\n",
    "non_silent_audio = AudioSegment.empty()\n",
    "for chunk in chunks:\n",
    "    non_silent_audio += chunk\n",
    "\n",
    "# 결과 저장\n",
    "non_silent_audio.export(output_file_path, format=\"wav\")\n",
    "print('공백 제거 완료 및 저장')\n",
    "\n",
    "# 임시 출력 디렉토리 정리 (선택 사항)\n",
    "import shutil\n",
    "shutil.rmtree(temp_output_directory)\n",
    "print('임시 파일 정리 완료')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e127a51-cb9d-4aae-bb8f-362647d86171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'pretrained_models/2stems', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.7\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
      "INFO:tensorflow:Apply unet for accompaniment_spectrogram\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from pretrained_models/2stems/model\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 18:49:58.155799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-22 18:49:58.155883: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:spleeter:File /home/eternal/song/output_directory/04. Memories/04. Memories/vocals.wav written succesfully\n",
      "INFO:spleeter:File /home/eternal/song/output_directory/04. Memories/04. Memories/accompaniment.wav written succesfully\n",
      "보컬 분리 완료: /home/eternal/song/output_directory/04. Memories\n",
      "보컬 파일 경로: /home/eternal/song/output_directory/04. Memories/04. Memories/vocals.wav\n",
      "공백 제거 완료 및 저장: /home/eternal/song/output_directorys/04. Memories/output_no_silence.wav\n",
      "임시 파일 정리 완료: /home/eternal/song/output_directory/04. Memories\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from spleeter.separator import Separator\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "# 파일 경로 설정\n",
    "input_audio_path = '/home/eternal/song/04. Memories.mp3'  # 입력 오디오 파일 경로\n",
    "temp_output_directory = '/home/eternal/song/output_directory/04. Memories'   # 임시 출력 디렉토리\n",
    "output_file_path = '/home/eternal/song/output_directorys/04. Memories/output_no_silence.wav'        # 최종 출력 파일 경로\n",
    "\n",
    "# 임시 출력 디렉토리가 존재하지 않으면 생성\n",
    "os.makedirs(temp_output_directory, exist_ok=True)\n",
    "\n",
    "# 최종 출력 디렉토리가 존재하지 않으면 생성\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "\n",
    "# Spleeter separator 객체 생성 (2스템 분리: 보컬과 나머지)\n",
    "separator = Separator('spleeter:2stems')\n",
    "\n",
    "# 보컬 분리\n",
    "separator.separate_to_file(input_audio_path, temp_output_directory)\n",
    "print(f'보컬 분리 완료: {temp_output_directory}')\n",
    "\n",
    "# 분리된 보컬 파일 경로 설정\n",
    "vocal_file = os.path.join(temp_output_directory, 'vocals.wav')\n",
    "if not os.path.exists(vocal_file):\n",
    "    # 서브 디렉토리에 저장되었을 경우를 대비해 추가 확인\n",
    "    sub_dir = os.path.splitext(os.path.basename(input_audio_path))[0]\n",
    "    vocal_file = os.path.join(temp_output_directory, sub_dir, 'vocals.wav')\n",
    "\n",
    "print(f'보컬 파일 경로: {vocal_file}')\n",
    "\n",
    "# 보컬 파일 로드\n",
    "if os.path.exists(vocal_file):\n",
    "    vocal_audio = AudioSegment.from_wav(vocal_file)\n",
    "else:\n",
    "    print(f'보컬 파일을 찾을 수 없습니다: {vocal_file}')\n",
    "    exit(1)\n",
    "\n",
    "# 공백 제거\n",
    "chunks = split_on_silence(vocal_audio, \n",
    "                          min_silence_len=500, \n",
    "                          silence_thresh=-40)\n",
    "\n",
    "# 공백이 제거된 오디오를 다시 하나의 오디오로 병합\n",
    "non_silent_audio = AudioSegment.empty()\n",
    "for chunk in chunks:\n",
    "    non_silent_audio += chunk\n",
    "\n",
    "# 결과 저장\n",
    "non_silent_audio.export(output_file_path, format=\"wav\")\n",
    "print(f'공백 제거 완료 및 저장: {output_file_path}')\n",
    "\n",
    "# 임시 출력 디렉토리 정리 (선택 사항)\n",
    "import shutil\n",
    "shutil.rmtree(temp_output_directory)\n",
    "print(f'임시 파일 정리 완료: {temp_output_directory}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6974759c-41a5-44ee-a07a-7449ece5b008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'pretrained_models/2stems', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.7\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <generator object Estimator.predict at 0x7f1357e174c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eternal/.local/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 618, in predict\n",
      "    with tf.Graph().as_default() as g:\n",
      "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/eternal/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 5821, in get_controller\n",
      "    with super(_DefaultGraphStack,\n",
      "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/eternal/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 5633, in get_controller\n",
      "    raise AssertionError(\n",
      "AssertionError: Nesting violated for default stack of <class 'tensorflow.python.framework.ops.Graph'> objects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
      "INFO:tensorflow:Apply unet for accompaniment_spectrogram\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from pretrained_models/2stems/model\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 20:32:23.288490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-22 20:32:23.288566: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:spleeter:File /home/eternal/song/output_directory/04. Memories/04. Memories/vocals.wav written succesfully\n",
      "INFO:spleeter:File /home/eternal/song/output_directory/04. Memories/04. Memories/accompaniment.wav written succesfully\n",
      "보컬 분리 완료: /home/eternal/song/output_directory/04. Memories\n",
      "보컬 파일 경로: /home/eternal/song/output_directory/04. Memories/04. Memories/vocals.wav\n",
      "임시 파일 정리 완료: /home/eternal/song/output_directory/04. Memories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40795/3145751903.py:67: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(wav_file, sr=None)\n",
      "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/eternal/song/output_directorys/04. Memories/04. Memories/vocals.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:175\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:208\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[0;31mLibsndfileError\u001b[0m: Error opening '/home/eternal/song/output_directorys/04. Memories/04. Memories/vocals.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# 스펙트로그램 파일 경로 설정\u001b[39;00m\n\u001b[1;32m     80\u001b[0m spectrogram_output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/eternal/song/output_directorys/04. Memories/spectrogram.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 81\u001b[0m \u001b[43mplot_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspectrogram_output_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m스펙트로그램 생성 완료 및 저장: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspectrogram_output_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 67\u001b[0m, in \u001b[0;36mplot_spectrogram\u001b[0;34m(wav_file, output_image)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_spectrogram\u001b[39m(wav_file, output_image):\n\u001b[0;32m---> 67\u001b[0m     y, sr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     S \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmelspectrogram(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39msr, n_mels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m     69\u001b[0m     S_dB \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mpower_to_db(S, ref\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[1;32m    180\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    182\u001b[0m     )\n\u001b[0;32m--> 183\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/util/decorators.py:59\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[1;32m     58\u001b[0m )\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:239\u001b[0m, in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    236\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43maudioread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[1;32m    242\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/audioread/__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBackendClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/audioread/rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/eternal/song/output_directorys/04. Memories/04. Memories/vocals.wav'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from spleeter.separator import Separator\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "# 파일 경로 설정\n",
    "input_audio_path = '/home/eternal/song/04. Memories.mp3'  # 입력 오디오 파일 경로\n",
    "temp_output_directory = '/home/eternal/song/output_directory/04. Memories'   # 임시 출력 디렉토리\n",
    "output_file_path = '/home/eternal/song/output_directorys/04. Memories/04. Memories/vocals.wav'  # 최종 출력 파일 경로\n",
    "\n",
    "#output_file_path = '/home/eternal/song/output_directorys/04. Memories/output_no_silence.wav'  # 최종 출력 파일 경로\n",
    "\n",
    "# 임시 출력 디렉토리가 존재하지 않으면 생성\n",
    "os.makedirs(temp_output_directory, exist_ok=True)\n",
    "\n",
    "# 최종 출력 디렉토리가 존재하지 않으면 생성\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "\n",
    "# Spleeter separator 객체 생성 (2스템 분리: 보컬과 나머지)\n",
    "separator = Separator('spleeter:2stems')\n",
    "\n",
    "# 보컬 분리\n",
    "separator.separate_to_file(input_audio_path, temp_output_directory)\n",
    "print(f'보컬 분리 완료: {temp_output_directory}')\n",
    "\n",
    "# 분리된 보컬 파일 경로 설정\n",
    "vocal_file = os.path.join(temp_output_directory, 'vocals.wav')\n",
    "if not os.path.exists(vocal_file):\n",
    "    # 서브 디렉토리에 저장되었을 경우를 대비해 추가 확인\n",
    "    sub_dir = os.path.splitext(os.path.basename(input_audio_path))[0]\n",
    "    vocal_file = os.path.join(temp_output_directory, sub_dir, 'vocals.wav')\n",
    "\n",
    "print(f'보컬 파일 경로: {vocal_file}')\n",
    "\n",
    "# 보컬 파일 로드\n",
    "if os.path.exists(vocal_file):\n",
    "    vocal_audio = AudioSegment.from_wav(vocal_file)\n",
    "else:\n",
    "    print(f'보컬 파일을 찾을 수 없습니다: {vocal_file}')\n",
    "    exit(1)\n",
    "'''\n",
    "# 공백 제거\n",
    "chunks = split_on_silence(vocal_audio, \n",
    "                          min_silence_len=500, \n",
    "                          silence_thresh=-40)\n",
    "\n",
    "# 공백이 제거된 오디오를 다시 하나의 오디오로 병합\n",
    "non_silent_audio = AudioSegment.empty()\n",
    "for chunk in chunks:\n",
    "    non_silent_audio += chunk\n",
    "\n",
    "# 결과 저장\n",
    "non_silent_audio.export(output_file_path, format=\"wav\")\n",
    "print(f'공백 제거 완료 및 저장: {output_file_path}')\n",
    "'''\n",
    "# 임시 출력 디렉토리 정리 (선택 사항)\n",
    "shutil.rmtree(temp_output_directory)\n",
    "print(f'임시 파일 정리 완료: {temp_output_directory}')\n",
    "\n",
    "# 스펙트로그램 생성\n",
    "def plot_spectrogram(wav_file, output_image):\n",
    "    y, sr = librosa.load(wav_file, sr=None)\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel-frequency spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_image)\n",
    "    plt.close()\n",
    "\n",
    "# 스펙트로그램 파일 경로 설정\n",
    "spectrogram_output_path = '/home/eternal/song/output_directorys/04. Memories/spectrogram.png'\n",
    "plot_spectrogram(output_file_path, spectrogram_output_path)\n",
    "print(f'스펙트로그램 생성 완료 및 저장: {spectrogram_output_path}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f93d8cf-1b04-47b3-9774-2315c6528c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'pretrained_models/2stems', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.7\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
      "INFO:tensorflow:Apply unet for accompaniment_spectrogram\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <generator object Estimator.predict at 0x7f137fe38270>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eternal/.local/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 618, in predict\n",
      "    with tf.Graph().as_default() as g:\n",
      "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/eternal/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 5821, in get_controller\n",
      "    with super(_DefaultGraphStack,\n",
      "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/eternal/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 5633, in get_controller\n",
      "    raise AssertionError(\n",
      "AssertionError: Nesting violated for default stack of <class 'tensorflow.python.framework.ops.Graph'> objects\n",
      "Exception ignored in: <generator object Estimator.predict at 0x7f11a0d483c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eternal/.local/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 618, in predict\n",
      "    with tf.Graph().as_default() as g:\n",
      "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/eternal/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 5821, in get_controller\n",
      "    with super(_DefaultGraphStack,\n",
      "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/eternal/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 5633, in get_controller\n",
      "    raise AssertionError(\n",
      "AssertionError: Nesting violated for default stack of <class 'tensorflow.python.framework.ops.Graph'> objects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from pretrained_models/2stems/model\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 20:37:24.393516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-22 20:37:24.393611: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:spleeter:File /home/eternal/song/output_directory/04. Memories/04. Memories/vocals.wav written succesfully\n",
      "INFO:spleeter:File /home/eternal/song/output_directory/04. Memories/04. Memories/accompaniment.wav written succesfully\n",
      "보컬 분리 완료: /home/eternal/song/output_directory/04. Memories\n",
      "보컬 파일 경로: /home/eternal/song/output_directory/04. Memories/04. Memories/vocals.wav\n",
      "보컬 파일 저장 완료: /home/eternal/song/output_directorys/04. Memories/vocals.wav\n",
      "임시 파일 정리 완료: /home/eternal/song/output_directory/04. Memories\n",
      "Starting spectrogram creation for /home/eternal/song/output_directorys/04. Memories/vocals.wav\n",
      "Audio loaded: y.shape=(13561044,), sr=44100\n",
      "Spectrogram saved to /home/eternal/song/output_directorys/04. Memories/spectrogram.png\n",
      "스펙트로그램 생성 완료 및 저장: /home/eternal/song/output_directorys/04. Memories/spectrogram.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from spleeter.separator import Separator\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# 파일 경로 설정\n",
    "input_audio_path = '/home/eternal/song/04. Memories.mp3'  # 입력 오디오 파일 경로\n",
    "temp_output_directory = '/home/eternal/song/output_directory/04. Memories'   # 임시 출력 디렉토리\n",
    "output_file_path = '/home/eternal/song/output_directorys/04. Memories/vocals.wav'  # 최종 출력 파일 경로\n",
    "\n",
    "# 임시 출력 디렉토리가 존재하지 않으면 생성\n",
    "os.makedirs(temp_output_directory, exist_ok=True)\n",
    "\n",
    "# 최종 출력 디렉토리가 존재하지 않으면 생성\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "\n",
    "# Spleeter separator 객체 생성 (2스템 분리: 보컬과 나머지)\n",
    "separator = Separator('spleeter:2stems')\n",
    "\n",
    "# 보컬 분리\n",
    "separator.separate_to_file(input_audio_path, temp_output_directory)\n",
    "print(f'보컬 분리 완료: {temp_output_directory}')\n",
    "\n",
    "# 분리된 보컬 파일 경로 설정\n",
    "vocal_file = os.path.join(temp_output_directory, 'vocals.wav')\n",
    "if not os.path.exists(vocal_file):\n",
    "    # 서브 디렉토리에 저장되었을 경우를 대비해 추가 확인\n",
    "    sub_dir = os.path.splitext(os.path.basename(input_audio_path))[0]\n",
    "    vocal_file = os.path.join(temp_output_directory, sub_dir, 'vocals.wav')\n",
    "\n",
    "print(f'보컬 파일 경로: {vocal_file}')\n",
    "\n",
    "# 보컬 파일 로드\n",
    "if os.path.exists(vocal_file):\n",
    "    vocal_audio = AudioSegment.from_wav(vocal_file)\n",
    "else:\n",
    "    print(f'보컬 파일을 찾을 수 없습니다: {vocal_file}')\n",
    "    exit(1)\n",
    "\n",
    "# 보컬 파일을 지정된 경로에 복사\n",
    "vocal_audio.export(output_file_path, format=\"wav\")\n",
    "print(f'보컬 파일 저장 완료: {output_file_path}')\n",
    "\n",
    "# 임시 출력 디렉토리 정리 (선택 사항)\n",
    "shutil.rmtree(temp_output_directory)\n",
    "print(f'임시 파일 정리 완료: {temp_output_directory}')\n",
    "\n",
    "# 스펙트로그램 생성\n",
    "def plot_spectrogram(wav_file, output_image):\n",
    "    print(f'Starting spectrogram creation for {wav_file}')\n",
    "    y, sr = librosa.load(wav_file, sr=None)\n",
    "    print(f'Audio loaded: y.shape={y.shape}, sr={sr}')\n",
    "    \n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel-frequency spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_image)\n",
    "    print(f'Spectrogram saved to {output_image}')\n",
    "    plt.close()\n",
    "\n",
    "# 스펙트로그램 파일 경로 설정\n",
    "spectrogram_output_path = '/home/eternal/song/output_directorys/04. Memories/spectrogram.png'\n",
    "plot_spectrogram(output_file_path, spectrogram_output_path)\n",
    "print(f'스펙트로그램 생성 완료 및 저장: {spectrogram_output_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db928014-60d6-4346-9398-f92620a57144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'pretrained_models/2stems', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.7\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
      "INFO:tensorflow:Apply unet for accompaniment_spectrogram\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from pretrained_models/2stems/model\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 22:42:50.582977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-22 22:42:50.583058: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:spleeter:File /home/eternal/song/output_directory/04. Memories/04. Memories/vocals.wav written succesfully\n",
      "INFO:spleeter:File /home/eternal/song/output_directory/04. Memories/04. Memories/accompaniment.wav written succesfully\n",
      "보컬 분리 완료: /home/eternal/song/output_directory/04. Memories\n",
      "보컬 파일 경로: /home/eternal/song/output_directory/04. Memories/04. Memories/vocals.wav\n",
      "보컬 파일 저장 완료: /home/eternal/song/output_directorys/04. Memories/vocals.wav\n",
      "임시 파일 정리 완료: /home/eternal/song/output_directory/04. Memories\n",
      "Starting spectrogram creation for /home/eternal/song/output_directorys/04. Memories/vocals.wav\n",
      "Audio loaded: y.shape=(13561044,), sr=44100\n",
      "Spectrogram saved to /home/eternal/song/output_directorys/04. Memories/spectrogram.png\n",
      "스펙트로그램 생성 완료 및 저장: /home/eternal/song/output_directorys/04. Memories/spectrogram.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from spleeter.separator import Separator\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# 파일 경로 설정\n",
    "input_audio_path = '/home/eternal/song/04. Memories.mp3'  # 입력 오디오 파일 경로\n",
    "temp_output_directory = '/home/eternal/song/output_directory/04. Memories'   # 임시 출력 디렉토리\n",
    "output_file_path = '/home/eternal/song/output_directorys/04. Memories/vocals.wav'  # 최종 출력 파일 경로\n",
    "\n",
    "# 임시 출력 디렉토리가 존재하지 않으면 생성\n",
    "os.makedirs(temp_output_directory, exist_ok=True)\n",
    "\n",
    "# 최종 출력 디렉토리가 존재하지 않으면 생성\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "\n",
    "# Spleeter separator 객체 생성 (2스템 분리: 보컬과 나머지)\n",
    "separator = Separator('spleeter:2stems')\n",
    "\n",
    "# 보컬 분리\n",
    "separator.separate_to_file(input_audio_path, temp_output_directory)\n",
    "print(f'보컬 분리 완료: {temp_output_directory}')\n",
    "\n",
    "# 분리된 보컬 파일 경로 설정\n",
    "vocal_file = os.path.join(temp_output_directory, 'vocals.wav')\n",
    "if not os.path.exists(vocal_file):\n",
    "    # 서브 디렉토리에 저장되었을 경우를 대비해 추가 확인\n",
    "    sub_dir = os.path.splitext(os.path.basename(input_audio_path))[0]\n",
    "    vocal_file = os.path.join(temp_output_directory, sub_dir, 'vocals.wav')\n",
    "\n",
    "print(f'보컬 파일 경로: {vocal_file}')\n",
    "\n",
    "# 보컬 파일 로드\n",
    "if os.path.exists(vocal_file):\n",
    "    vocal_audio = AudioSegment.from_wav(vocal_file)\n",
    "else:\n",
    "    print(f'보컬 파일을 찾을 수 없습니다: {vocal_file}')\n",
    "    exit(1)\n",
    "\n",
    "# 보컬 파일을 지정된 경로에 복사\n",
    "vocal_audio.export(output_file_path, format=\"wav\")\n",
    "print(f'보컬 파일 저장 완료: {output_file_path}')\n",
    "\n",
    "# 임시 출력 디렉토리 정리 (선택 사항)\n",
    "shutil.rmtree(temp_output_directory)\n",
    "print(f'임시 파일 정리 완료: {temp_output_directory}')\n",
    "\n",
    "# 스펙트로그램 생성\n",
    "def plot_spectrogram(wav_file, output_image):\n",
    "    print(f'Starting spectrogram creation for {wav_file}')\n",
    "    y, sr = librosa.load(wav_file, sr=None)\n",
    "    y = librosa.util.normalize(y)  # 정규화 추가\n",
    "    print(f'Audio loaded: y.shape={y.shape}, sr={sr}')\n",
    "    \n",
    "    # 스펙트로그램 파라미터 설정\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    win_length = None\n",
    "\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, win_length=win_length, n_mels=128)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel', hop_length=hop_length)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel-frequency spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_image)\n",
    "    print(f'Spectrogram saved to {output_image}')\n",
    "    plt.close()\n",
    "\n",
    "# 스펙트로그램 파일 경로 설정\n",
    "spectrogram_output_path = '/home/eternal/song/output_directorys/04. Memories/spectrogram.png'\n",
    "plot_spectrogram(output_file_path, spectrogram_output_path)\n",
    "print(f'스펙트로그램 생성 완료 및 저장: {spectrogram_output_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
