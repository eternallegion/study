{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce89dad0-0c36-4c51-b62f-7f49d4ea8b4a",
   "metadata": {},
   "source": [
    "# 모델 체크포인트 저장 및 불러오기\n",
    "\n",
    "## 오늘의 목표\n",
    "1.체크포인트 저장의 필요성 및 개념 이해\n",
    "\n",
    "학습 도중 최적 모델을 저장하여, 나중에 재학습하거나 평가 시점까지 이어서 사용할 수 있습니다.\n",
    "\n",
    "학습 시간이 오래 걸리는 모델이라면, 중간에 학습을 중단하고 다시 시작할 때 유용합니다.\n",
    "\n",
    "2.모델 상태(state_dict) 저장 및 불러오기\n",
    "\n",
    "PyTorch에서 torch.save() 함수를 사용해 모델과 옵티마이저의 상태(state_dict)를 저장하는 방법을 배웁니다.\n",
    "\n",
    "torch.load()와 model.load_state_dict()를 사용해 저장된 상태를 불러오는 방법을 학습합니다.\n",
    "\n",
    "3.체크포인트 저장 전략\n",
    "\n",
    "정기적으로(예: 에폭마다 또는 성능이 개선될 때) 저장하는 방법\n",
    "\n",
    "Best model(최적 모델) 저장, 에폭 번호를 함께 저장하는 방법 등을 소개합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a46676-9ae3-4eec-a883-13634b436b05",
   "metadata": {},
   "source": [
    "### 1. 체크포인트 저장의 기본 개념\n",
    "-모델 상태 (state_dict):\n",
    "\n",
    "모델 내부의 모든 파라미터(가중치, 바이어스 등)와 버퍼(예: BatchNorm의 running_mean 등)를 저장합니다.\n",
    "\n",
    "-옵티마이저 상태:\n",
    "\n",
    "옵티마이저가 사용하는 gradient, 모멘텀, 학습률 등 업데이트에 필요한 상태 정보를 포함합니다.\n",
    "\n",
    "-저장 시점:\n",
    "\n",
    "학습 도중 매 에폭마다, 또는 Validation 성능이 개선될 때 등 원하는 시점에 저장할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a6fb3a-1703-4d73-9b67-bde16d8871d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4f5f2dca-63fd-4eae-9708-79e8d478309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader as loader\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "13a4bde7-c610-4459-849e-386e97a148e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model,self).__init__()\n",
    "        self.conv1=nn.Conv2d(1,32, kernel_size=3, stride=1,padding=1)\n",
    "        self.conv2=nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1)\n",
    "        self.pool=nn.MaxPool2d(2,2)\n",
    "        self.fc1=nn.Linear(64*7*7,128)\n",
    "        self.fc2=nn.Linear(128,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=f.relu(self.conv1(x))\n",
    "        x=self.pool(x)\n",
    "        x=f.relu(self.conv2(x))\n",
    "        x=self.pool(x)\n",
    "        x=x.view(-1,64*7*7)\n",
    "        x=f.relu(self.fc1(x))\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "36d1bd02-0d95-4af0-9141-d7bbf63d279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 함수 (체크포인트 저장 포함)\n",
    "def train_mode(model, train_loader,criter, optimy, num_epoch=5, save_every=2):\n",
    "    model.train()\n",
    "    for epoch in range(num_epoch):\n",
    "        total=0.0\n",
    "        for data, target in train_loader:\n",
    "            optimy.zero_grad()\n",
    "            out=model(data)\n",
    "            loss=criter(out,target)\n",
    "            loss.backward()\n",
    "            optimy.step()\n",
    "            total+=loss.item()\n",
    "        avg_loss=total/len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epoch}, Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        if (epoch+1)%save_every==0:\n",
    "            save_check(model, optimy, epoch+1, filename=f\"checkpoint_epoch{epoch+1}.pth\")\n",
    "        return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d8796cc0-c752-44ce-8a29-efbf19d6ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#평가 함수 (eval_mode)\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    all_pred = []\n",
    "    all_target = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            out = model(data)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "            total += data.size(0)  # 오타: 여기서는 data.size(0)\n",
    "            all_pred.extend(pred.cpu().numpy())\n",
    "            all_target.extend(target.cpu().numpy())\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "def eval_mode(model, test_loader):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    all_pred = []\n",
    "    all_target = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            out = model(data)\n",
    "            pred = out.argmax(dim=1)\n",
    "            all_pred.extend(pred.cpu().numpy())\n",
    "            all_target.extend(target.cpu().numpy())\n",
    "            correct += pred.eq(target).sum().item()\n",
    "            total += data.size(0)\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return accuracy, np.array(all_target), np.array(all_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c9f8f6-a95c-424a-be20-25c14d9a2c9b",
   "metadata": {},
   "source": [
    "# 체크포인트 저장 및 불러오기 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c61d8395-fb0c-49fe-8d8d-6f8cea06038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_check(model, optimy, epoch, filename=\"checkpoint.pth\"):\n",
    "    check={\"epoch\":epoch, # 현재 에폭 번호\n",
    "    \"model_state\":model.state_dict(),# 모델 가중치\n",
    "    \"optimy\":optimy.state_dict(),# 옵티마이저 상태(모멘텀, 학습률 등)\n",
    "    \"loss\":loss}# 현재 손실 값 (선택 사항)\n",
    "    # \"scheduler_state_dict\": scheduler.state_dict(),  # 사용 중이면 학습률 스케줄러 상태\n",
    "    filepath=os.path.join(checkpoint_dir,filename)\n",
    "    torch.save(checkpoint_dir,filename)\n",
    "    print(f\"Checkpoint saved at epoch {epoch}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a11a0d40-7fdd-419b-aedb-8368210fe3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_check(model, optimy, filename=\"checkpoint.pth\"):\n",
    "    checkpoint=torch.load(os.path.join(checkpoint_dir, filename))# 체크포인트 파일 로드\n",
    "    model.load_state_dict(checkpoint['model_state'])# 모델 상태 복원\n",
    "    optimy.load_state_state_dict(checkpoint['optimyt'])# 옵티마이저 상태 복원\n",
    "\n",
    "    start_epoch=checkpoint['epoch']+1# 이어서 학습하려면, 현재 에폭을 복원합니다.\n",
    "    print(f\"Checkpoint loaded. Resuming from epoch {start_epoch}.\")\n",
    "    return start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "91bd370e-7109-4863-a72f-4919af262bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Epoch 1/5, Training Loss: 0.1333\n",
      "Test Accuracy: 98.39%\n"
     ]
    }
   ],
   "source": [
    "#데이터셋 및 DataLoader 생성\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))\n",
    "])\n",
    "\n",
    "train_data=datasets.MNIST(root='./data',train=True,download=True, transform=transform)\n",
    "test_data=datasets.MNIST(root='./data',train=False,download=True,transform=transform)\n",
    "train_loader=loader(train_data,batch_size=64,shuffle=True)\n",
    "test_loader=loader(test_data,batch_size=1000,shuffle=True)\n",
    "\n",
    "checkpoint_dir=\"./checkpoints\"\n",
    "os.makedirs(checkpoint_dir,exist_ok=True)\n",
    "\n",
    "model=model()\n",
    "print(model)\n",
    "criter=nn.CrossEntropyLoss()\n",
    "optimy=optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "num_epoch=10\n",
    "train_mode(model, train_loader,criter, optimy, num_epoch=5, save_every=2)\n",
    "test_accuracy, y_true, y_pred = eval_mode(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "95393cdc-cef6-4c94-a1e8-cdd3a5b2e56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "체크포인트가 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 체크포인트 저장 (모델과 옵티마이저 상태)\n",
    "torch.save(model.state_dict(), 'cnn_checkpoint.pth')\n",
    "torch.save(optimy.state_dict(), 'optimizer_checkpoint.pth')\n",
    "print(\"체크포인트가 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c51f0667-5d25-45ed-9da0-ccc21064323f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 976    0    0    0    0    0    1    2    0    1]\n",
      " [   0 1131    1    1    0    0    0    1    1    0]\n",
      " [   1    3 1014    0    1    0    1   10    1    1]\n",
      " [   2    0    2  984    0    8    0   10    2    2]\n",
      " [   0    0    0    0  960    0    1    1    0   20]\n",
      " [   2    1    0    2    0  871    6    3    0    7]\n",
      " [   3    2    0    0    1    1  951    0    0    0]\n",
      " [   0    0    6    0    0    0    0 1018    1    3]\n",
      " [   5    2    5    0    5    0    8    3  939    7]\n",
      " [   0    2    0    1    2    2    0    5    2  995]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       980\n",
      "           1       0.99      1.00      0.99      1135\n",
      "           2       0.99      0.98      0.98      1032\n",
      "           3       1.00      0.97      0.98      1010\n",
      "           4       0.99      0.98      0.98       982\n",
      "           5       0.99      0.98      0.98       892\n",
      "           6       0.98      0.99      0.99       958\n",
      "           7       0.97      0.99      0.98      1028\n",
      "           8       0.99      0.96      0.98       974\n",
      "           9       0.96      0.99      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8503642-97b5-4f12-abc9-cd01e8a877bd",
   "metadata": {},
   "source": [
    "state_dict(): 지금 모델이나 옵티마이저의 모든 값을 '캡처'해 딕셔너리로 만든다.\n",
    "\n",
    "load_state_dict(): 저장했던 그 딕셔너리를 모델에 '적용'하여, 저장 당시의 상태로 복원한다.\n",
    "\n",
    "모델 체크포인트:\n",
    "\n",
    "목적:\n",
    "학습 도중에 중간 상태(예: 특정 에폭마다의 모델 가중치, 옵티마이저 상태, 현재 에폭 정보 등)를 저장하여, 나중에 학습을 이어서 진행하거나, 최적의 모델 상태를 보존하기 위해 사용됩니다.\n",
    "\n",
    "저장 내용:\n",
    "모델의 state_dict, 옵티마이저의 state_dict, 에폭 번호, 그리고 경우에 따라 학습 손실 등 추가 정보를 포함할 수 있습니다.\n",
    "\n",
    "사용 시점:\n",
    "주기적으로 또는 Validation 성능이 향상되지 않을 때 저장하여, 중단되거나 최적의 상태로 학습을 재개할 수 있도록 합니다.\n",
    "\n",
    "모델 저장 (Final Model Save):\n",
    "\n",
    "목적:\n",
    "학습이 완료된 최종 모델을 저장하여, 추후 추론(inference), 배포, 또는 다른 작업에 활용할 수 있도록 합니다.\n",
    "\n",
    "저장 내용:\n",
    "보통 모델의 state_dict만 저장하거나, 전체 모델 아키텍처와 가중치를 함께 저장합니다.\n",
    "\n",
    "사용 시점:\n",
    "학습이 끝난 후 최종 결과를 저장하여, 나중에 로드 후 바로 추론에 사용할 수 있도록 합니다.\n",
    "\n",
    "\n",
    "요약하면,\n",
    "체크포인트는 학습 중간 상태를 저장하여, 학습 재개나 디버깅 목적으로 사용합니다.\n",
    "모델 저장은 최종 모델을 저장하여, 추론, 배포, 또는 다른 후속 작업에 사용합니다.\n",
    "두 방법 모두 모델의 상태를 저장하는 것이지만, 저장하는 목적과 포함하는 정보가 다르다고 이해하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad9d05f-95bb-4a4a-9073-86f133bac6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
