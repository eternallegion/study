{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "776b9779-93f9-4472-8303-78798a1247d2",
   "metadata": {},
   "source": [
    "from tensorflow.keras.layers import ConV1D,GlobalMaxPooling1D\n",
    "\n",
    "model=Sequential()\n",
    "model.add(ConV1D(num_filters,kernel_size,padding='valid',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70928a22-e4ea-4066-8b34-420c0ca1a5b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Conv1D.__init__() missing 1 required positional argument: 'filters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m=\u001b[39mSequential()\n\u001b[0;32m----> 5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(\u001b[43mConv1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39madd(GlobalMaxPooling1D)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/dtensor/utils.py:96\u001b[0m, in \u001b[0;36mallow_initializer_layout.<locals>._wrap_function\u001b[0;34m(layer_instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m layout:\n\u001b[1;32m     94\u001b[0m             layout_args[variable_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_layout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m layout\n\u001b[0;32m---> 96\u001b[0m \u001b[43minit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Inject the layout parameter after the invocation of __init__()\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layout_param_name, layout \u001b[38;5;129;01min\u001b[39;00m layout_args\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mTypeError\u001b[0m: Conv1D.__init__() missing 1 required positional argument: 'filters'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D,GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv1D(num_filters=4,kernel_size=2,padding='valid',activation='relu'))\n",
    "model.add(GlobalMaxPooling1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb85292-78d5-43c2-9395-ea0cb79da38a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e3bd1-bbae-4a1b-9fb1-7cb23c979780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e8377d2-dfa1-4aca-b8ea-e9eab5a1440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size=10000\n",
    "(x_train,y_train),(x_test,y_test)=datasets.imdb.load_data(num_words=vocab_size)#num_words : 명령어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1d66d85-02b4-4f49-88e9-476af1b69e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32])\n",
      " list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n",
      " list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])\n",
      " list([1, 4, 2, 2, 33, 2804, 4, 2040, 432, 111, 153, 103, 4, 1494, 13, 70, 131, 67, 11, 61, 2, 744, 35, 3715, 761, 61, 5766, 452, 9214, 4, 985, 7, 2, 59, 166, 4, 105, 216, 1239, 41, 1797, 9, 15, 7, 35, 744, 2413, 31, 8, 4, 687, 23, 4, 2, 7339, 6, 3693, 42, 38, 39, 121, 59, 456, 10, 10, 7, 265, 12, 575, 111, 153, 159, 59, 16, 1447, 21, 25, 586, 482, 39, 4, 96, 59, 716, 12, 4, 172, 65, 9, 579, 11, 6004, 4, 1615, 5, 2, 7, 5168, 17, 13, 7064, 12, 19, 6, 464, 31, 314, 11, 2, 6, 719, 605, 11, 8, 202, 27, 310, 4, 3772, 3501, 8, 2722, 58, 10, 10, 537, 2116, 180, 40, 14, 413, 173, 7, 263, 112, 37, 152, 377, 4, 537, 263, 846, 579, 178, 54, 75, 71, 476, 36, 413, 263, 2504, 182, 5, 17, 75, 2306, 922, 36, 279, 131, 2895, 17, 2867, 42, 17, 35, 921, 2, 192, 5, 1219, 3890, 19, 2, 217, 4122, 1710, 537, 2, 1236, 5, 736, 10, 10, 61, 403, 9, 2, 40, 61, 4494, 5, 27, 4494, 159, 90, 263, 2311, 4319, 309, 8, 178, 5, 82, 4319, 4, 65, 15, 9225, 145, 143, 5122, 12, 7039, 537, 746, 537, 537, 15, 7979, 4, 2, 594, 7, 5168, 94, 9096, 3987, 2, 11, 2, 4, 538, 7, 1795, 246, 2, 9, 2, 11, 635, 14, 9, 51, 408, 12, 94, 318, 1382, 12, 47, 6, 2683, 936, 5, 6307, 2, 19, 49, 7, 4, 1885, 2, 1118, 25, 80, 126, 842, 10, 10, 2, 2, 4726, 27, 4494, 11, 1550, 3633, 159, 27, 341, 29, 2733, 19, 4185, 173, 7, 90, 2, 8, 30, 11, 4, 1784, 86, 1117, 8, 3261, 46, 11, 2, 21, 29, 9, 2841, 23, 4, 1010, 2, 793, 6, 2, 1386, 1830, 10, 10, 246, 50, 9, 6, 2750, 1944, 746, 90, 29, 2, 8, 124, 4, 882, 4, 882, 496, 27, 2, 2213, 537, 121, 127, 1219, 130, 5, 29, 494, 8, 124, 4, 882, 496, 4, 341, 7, 27, 846, 10, 10, 29, 9, 1906, 8, 97, 6, 236, 2, 1311, 8, 4, 2, 7, 31, 7, 2, 91, 2, 3987, 70, 4, 882, 30, 579, 42, 9, 12, 32, 11, 537, 10, 10, 11, 14, 65, 44, 537, 75, 2, 1775, 3353, 2, 1846, 4, 2, 7, 154, 5, 4, 518, 53, 2, 2, 7, 3211, 882, 11, 399, 38, 75, 257, 3807, 19, 2, 17, 29, 456, 4, 65, 7, 27, 205, 113, 10, 10, 2, 4, 2, 2, 9, 242, 4, 91, 1202, 2, 5, 2070, 307, 22, 7, 5168, 126, 93, 40, 2, 13, 188, 1076, 3222, 19, 4, 2, 7, 2348, 537, 23, 53, 537, 21, 82, 40, 2, 13, 2, 14, 280, 13, 219, 4, 2, 431, 758, 859, 4, 953, 1052, 2, 7, 5991, 5, 94, 40, 25, 238, 60, 2, 4, 2, 804, 2, 7, 4, 9941, 132, 8, 67, 6, 22, 15, 9, 283, 8, 5168, 14, 31, 9, 242, 955, 48, 25, 279, 2, 23, 12, 1685, 195, 25, 238, 60, 796, 2, 4, 671, 7, 2804, 5, 4, 559, 154, 888, 7, 726, 50, 26, 49, 7008, 15, 566, 30, 579, 21, 64, 2574])\n",
      " list([1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 14, 20, 56, 33, 2401, 18, 457, 88, 13, 2626, 1400, 45, 3171, 13, 70, 79, 49, 706, 919, 13, 16, 355, 340, 355, 1696, 96, 143, 4, 22, 32, 289, 7, 61, 369, 71, 2359, 5, 13, 16, 131, 2073, 249, 114, 249, 229, 249, 20, 13, 28, 126, 110, 13, 473, 8, 569, 61, 419, 56, 429, 6, 1513, 18, 35, 534, 95, 474, 570, 5, 25, 124, 138, 88, 12, 421, 1543, 52, 725, 6397, 61, 419, 11, 13, 1571, 15, 1543, 20, 11, 4, 2, 5, 296, 12, 3524, 5, 15, 421, 128, 74, 233, 334, 207, 126, 224, 12, 562, 298, 2167, 1272, 7, 2601, 5, 516, 988, 43, 8, 79, 120, 15, 595, 13, 784, 25, 3171, 18, 165, 170, 143, 19, 14, 5, 7224, 6, 226, 251, 7, 61, 113])]\n",
      "X_train의 크기(shape) : (25000, 200)\n",
      "X_test의 크기(shape) : (25000, 200)\n",
      "[1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:5])\n",
    "\n",
    "max_len=200\n",
    "x_train=pad_sequences(x_train,maxlen=max_len)\n",
    "x_test=pad_sequences(x_test,maxlen=max_len)\n",
    "print('X_train의 크기(shape) :',x_train.shape)\n",
    "print('X_test의 크기(shape) :',x_test.shape)\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed82112c-e00c-4a93-a22e-81d79fcfac11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f32aa276-7c21-45cd-b95f-706b7222f3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "601/782 [======================>.......] - ETA: 3s - loss: 0.4307 - acc: 0.7841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1705936078.185973  143506 graph_launch.cc:161] Evict all gpu graphs from executor 0x55cfb742ca50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 0.3977 - acc: 0.8063\n",
      "Epoch 1: val_loss improved from -inf to 0.27447, saving model to test_models.5h\n",
      "INFO:tensorflow:Assets written to: test_models.5h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test_models.5h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 13s 17ms/step - loss: 0.3977 - acc: 0.8063 - val_loss: 0.2745 - val_acc: 0.8828\n",
      "Epoch 2/20\n",
      "139/782 [====>.........................] - ETA: 3s - loss: 0.1958 - acc: 0.9305"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1705936080.947266  143506 graph_launch.cc:161] Evict all gpu graphs from executor 0x55cfb742ca50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590/782 [=====================>........] - ETA: 0s - loss: 0.2007 - acc: 0.9247"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1705936082.572828  143506 graph_launch.cc:161] Evict all gpu graphs from executor 0x55cfb742ca50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 0.2039 - acc: 0.9232\n",
      "Epoch 2: val_loss improved from 0.27447 to 0.27938, saving model to test_models.5h\n",
      "INFO:tensorflow:Assets written to: test_models.5h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test_models.5h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2039 - acc: 0.9232 - val_loss: 0.2794 - val_acc: 0.8827\n",
      "Epoch 3/20\n",
      "283/782 [=========>....................] - ETA: 1s - loss: 0.0824 - acc: 0.9749"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1705936084.721762  143507 graph_launch.cc:161] Evict all gpu graphs from executor 0x55cfb742ca50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 0.0897 - acc: 0.9699"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1705936085.989368  143505 graph_launch.cc:161] Evict all gpu graphs from executor 0x55cfb742ca50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: val_loss improved from 0.27938 to 0.30082, saving model to test_models.5h\n",
      "INFO:tensorflow:Assets written to: test_models.5h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test_models.5h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 3s 3ms/step - loss: 0.0897 - acc: 0.9699 - val_loss: 0.3008 - val_acc: 0.8880\n",
      "Epoch 4/20\n",
      "580/782 [=====================>........] - ETA: 0s - loss: 0.0351 - acc: 0.9892"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1705936088.144103  143504 graph_launch.cc:161] Evict all gpu graphs from executor 0x55cfb742ca50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 0.0378 - acc: 0.9879\n",
      "Epoch 4: val_loss improved from 0.30082 to 0.40195, saving model to test_models.5h\n",
      "INFO:tensorflow:Assets written to: test_models.5h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test_models.5h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0378 - acc: 0.9879 - val_loss: 0.4020 - val_acc: 0.8825\n",
      "Epoch 4: early stopping\n",
      "782/782 [==============================] - 1s 646us/step - loss: 0.4020 - acc: 0.8825\n",
      "\n",
      " 테스트 정확도: 0.8825\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dropout,Conv1D,GlobalMaxPooling1D,Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "embedding=256\n",
    "dropout=0.3\n",
    "num_filters=256\n",
    "kernel_size=3\n",
    "hidden=128\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size,embedding))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Conv1D(num_filters,kernel_size,padding='valid',activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(hidden,activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "es=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=3)\n",
    "mc=ModelCheckpoint('test_models.5h',moniter='val_acc',mode='max',verbose=1,save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc'])\n",
    "#history=model.fit(x_train,y_train,epochs=20,validation_data=(x_test,y_test),callbacks=[es,mc])\n",
    "history = model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test), callbacks=[es, mc])\n",
    "\n",
    "load_model=load_model('test_models.5h')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (load_model.evaluate(x_test, y_test)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64019ecb-b6c5-45b5-b38a-5a9c9cfcdc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11d6ca1-a043-45c1-bd44-0bdc0654cb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a346406-898f-4e2e-8224-96a2ffcee9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.6244 - acc: 0.6420\n",
      "Epoch 1: val_acc improved from -inf to 0.77620, saving model to best_model.h5\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 0.6244 - acc: 0.6420 - val_loss: 0.4836 - val_acc: 0.7762\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.4363 - acc: 0.8033\n",
      "Epoch 2: val_acc improved from 0.77620 to 0.83360, saving model to best_model.h5\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.4363 - acc: 0.8033 - val_loss: 0.3909 - val_acc: 0.8336\n",
      "Epoch 3/10\n",
      "102/313 [========>.....................] - ETA: 1s - loss: 0.3571 - acc: 0.8534"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1705936548.276543  143504 graph_launch.cc:161] Evict all gpu graphs from executor 0x55cfb742ca50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - ETA: 0s - loss: 0.3455 - acc: 0.8560\n",
      "Epoch 3: val_acc improved from 0.83360 to 0.85740, saving model to best_model.h5\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.3455 - acc: 0.8560 - val_loss: 0.3446 - val_acc: 0.8574\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.2752 - acc: 0.8928\n",
      "Epoch 4: val_acc improved from 0.85740 to 0.86080, saving model to best_model.h5\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2752 - acc: 0.8928 - val_loss: 0.3364 - val_acc: 0.8608\n",
      "Epoch 5/10\n",
      " 78/313 [======>.......................] - ETA: 1s - loss: 0.2232 - acc: 0.9199"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1705936551.889960  143509 graph_launch.cc:161] Evict all gpu graphs from executor 0x55cfb742ca50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - ETA: 0s - loss: 0.2274 - acc: 0.9154\n",
      "Epoch 5: val_acc improved from 0.86080 to 0.86180, saving model to best_model.h5\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2274 - acc: 0.9154 - val_loss: 0.3439 - val_acc: 0.8618\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.1878 - acc: 0.9323\n",
      "Epoch 6: val_acc did not improve from 0.86180\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1878 - acc: 0.9323 - val_loss: 0.3580 - val_acc: 0.8584\n",
      "Epoch 7/10\n",
      " 63/313 [=====>........................] - ETA: 0s - loss: 0.1372 - acc: 0.9561"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1705936554.065988  143504 graph_launch.cc:161] Evict all gpu graphs from executor 0x55cfb742ca50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - ETA: 0s - loss: 0.1546 - acc: 0.9473\n",
      "Epoch 7: val_acc did not improve from 0.86180\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1546 - acc: 0.9473 - val_loss: 0.3727 - val_acc: 0.8554\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv1D, GlobalMaxPooling1D, Embedding, Dropout, MaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "tokenizer=Tokenizer()\n",
    "\n",
    "embedding_dim = 32\n",
    "dropout_ratio = 0.3\n",
    "num_filters = 32\n",
    "kernel_size = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Conv1D(num_filters, kernel_size, padding='valid', activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor = 'val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2, callbacks=[es, mc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d6bbc92-4d39-464b-a874-57199f8cebad",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_test_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtexts_to_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m x_test_padded \u001b[38;5;241m=\u001b[39m pad_sequences(x_test_encoded, maxlen \u001b[38;5;241m=\u001b[39m max_len)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m 테스트 정확도: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (model\u001b[38;5;241m.\u001b[39mevaluate(x_test_padded, y_test)[\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/preprocessing/text.py:357\u001b[0m, in \u001b[0;36mTokenizer.texts_to_sequences\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtexts_to_sequences\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts):\n\u001b[1;32m    346\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transforms each text in texts to a sequence of integers.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    Only top `num_words-1` most frequent words will be taken into account.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m        A list of sequences.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtexts_to_sequences_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/preprocessing/text.py:386\u001b[0m, in \u001b[0;36mTokenizer.texts_to_sequences_generator\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 386\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[43mtext_to_word_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m            \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyzer(text)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/preprocessing/text.py:74\u001b[0m, in \u001b[0;36mtext_to_word_sequence\u001b[0;34m(input_text, filters, lower, split)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Converts a text to a sequence of words (or tokens).\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03mDeprecated: `tf.keras.preprocessing.text.text_to_word_sequence` does not\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    A list of words (or tokens).\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[0;32m---> 74\u001b[0m     input_text \u001b[38;5;241m=\u001b[39m \u001b[43minput_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[1;32m     76\u001b[0m translate_dict \u001b[38;5;241m=\u001b[39m {c: split \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m filters}\n\u001b[1;32m     77\u001b[0m translate_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mmaketrans(translate_dict)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "x_test_encoded = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_padded = pad_sequences(x_test_encoded, maxlen = max_len)\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(x_test_padded, y_test)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b41c5d5-e9bb-43e5-b746-571781544f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed69868-385b-4e43-8e70-a5e9d2b7da4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b371c7fb-4e4f-4051-9033-01d4d2216660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1705939763.503012  143502 graph_launch.cc:161] Evict all gpu graphs from executor 0x55cfb742ca50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_acc improved from -inf to 0.73420, saving model to CNN_model.h5\n",
      "313/313 - 9s - loss: 0.6642 - acc: 0.5694 - val_loss: 0.5213 - val_acc: 0.7342 - 9s/epoch - 28ms/step\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1705939767.236324  143503 graph_launch.cc:161] Evict all gpu graphs from executor 0x55cfb742ca50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_acc improved from 0.73420 to 0.83700, saving model to CNN_model.h5\n",
      "313/313 - 3s - loss: 0.4578 - acc: 0.7873 - val_loss: 0.3670 - val_acc: 0.8370 - 3s/epoch - 11ms/step\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1705939769.456466  143509 graph_launch.cc:161] Evict all gpu graphs from executor 0x55cfb742ca50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: val_acc improved from 0.83700 to 0.86080, saving model to CNN_model.h5\n",
      "313/313 - 2s - loss: 0.3495 - acc: 0.8511 - val_loss: 0.3302 - val_acc: 0.8608 - 2s/epoch - 7ms/step\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1705939770.881857  143500 graph_launch.cc:161] Evict all gpu graphs from executor 0x55cfb742ca50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: val_acc improved from 0.86080 to 0.86920, saving model to CNN_model.h5\n",
      "313/313 - 1s - loss: 0.2782 - acc: 0.8881 - val_loss: 0.3232 - val_acc: 0.8692 - 1s/epoch - 5ms/step\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1705939772.353067  143500 graph_launch.cc:161] Evict all gpu graphs from executor 0x55cfb742ca50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: val_acc did not improve from 0.86920\n",
      "313/313 - 2s - loss: 0.2328 - acc: 0.9102 - val_loss: 0.3286 - val_acc: 0.8668 - 2s/epoch - 5ms/step\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1705939773.571683  143506 graph_launch.cc:161] Evict all gpu graphs from executor 0x55cfb742ca50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: val_acc did not improve from 0.86920\n",
      "313/313 - 1s - loss: 0.1926 - acc: 0.9270 - val_loss: 0.3366 - val_acc: 0.8636 - 1s/epoch - 4ms/step\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1705939774.726502  143508 graph_launch.cc:161] Evict all gpu graphs from executor 0x55cfb742ca50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: val_acc did not improve from 0.86920\n",
      "313/313 - 1s - loss: 0.1642 - acc: 0.9389 - val_loss: 0.3617 - val_acc: 0.8600 - 1s/epoch - 3ms/step\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1705939775.787700  143500 graph_launch.cc:161] Evict all gpu graphs from executor 0x55cfb742ca50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: val_acc did not improve from 0.86920\n",
      "313/313 - 1s - loss: 0.1451 - acc: 0.9449 - val_loss: 0.3828 - val_acc: 0.8576 - 1s/epoch - 3ms/step\n",
      "Epoch 8: early stopping\n",
      "782/782 [==============================] - 1s 735us/step - loss: 0.3346 - acc: 0.8595\n",
      "\n",
      " 테스트 정확도: 0.8595\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense, Input, Flatten, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "embedding_dim = 128\n",
    "dropout_ratio = (0.5, 0.8)\n",
    "num_filters = 128\n",
    "hidden_units = 128\n",
    "model_input = Input(shape = (max_len,))\n",
    "z = Embedding(vocab_size, embedding_dim, input_length = max_len, name=\"embedding\")(model_input)\n",
    "z = Dropout(dropout_ratio[0])(z)\n",
    "conv_blocks = []\n",
    "\n",
    "for sz in [3, 4, 5]:\n",
    "    conv = Conv1D(filters = num_filters,\n",
    "                         kernel_size = sz,\n",
    "                         padding = \"valid\",\n",
    "                         activation = \"relu\",\n",
    "                         strides = 1)(z)\n",
    "    conv = GlobalMaxPooling1D()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "z = Dropout(dropout_ratio[1])(z)\n",
    "z = Dense(hidden_units, activation=\"relu\")(z)\n",
    "model_output = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('CNN_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_split=0.2, verbose=2, callbacks=[es, mc])\n",
    "loaded_model = load_model('CNN_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(x_test, y_test)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "24541be3-ffac-439a-ab87-44e37337b549",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m 확률로 부정 리뷰입니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m score) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m))\n\u001b[0;32m---> 21\u001b[0m \u001b[43msentence_pred\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m이 영화 개꿀잼 ㅋㅋㅋ\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m sentence_pred(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m이 영화 핵노잼 ㅠㅠ\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m sentence_pred(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m이딴게 영화냐 ㅉㅉ\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[90], line 15\u001b[0m, in \u001b[0;36msentence_pred\u001b[0;34m(N_sentence)\u001b[0m\n\u001b[1;32m     12\u001b[0m encode\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences([N_sentence])\n\u001b[1;32m     13\u001b[0m pad_new\u001b[38;5;241m=\u001b[39mpad_sequences(encode,maxlen\u001b[38;5;241m=\u001b[39mmax_len)\n\u001b[0;32m---> 15\u001b[0m score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[43mload_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(pad_new))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(score\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m 확률로 긍정 리뷰입니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(score \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "\n",
    "mecab=Mecab()\n",
    "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게', '만', '게임', '겜', '되', '음', '면']\n",
    "\n",
    "def sentence_pred(N_sentence):\n",
    "    N_sentence=re.sub(r'[^ㄱ-ㅎ ㅏ-ㅑ 가-힣]',' ',N_sentence)\n",
    "    N_sentence=mecab.morphs(N_sentence)\n",
    "    N_sentence=[word for word in N_sentence if not word in stopwords]\n",
    "    encode=tokenizer.texts_to_sequences([N_sentence])\n",
    "    pad_new=pad_sequences(encode,maxlen=max_len)\n",
    "\n",
    "    score=float(load_model.predict(pad_new))\n",
    "    if(score>0.5):\n",
    "        print(\"{:.2f}% 확률로 긍정 리뷰입니다.\".format(score * 100))\n",
    "    else:\n",
    "        print(\"{:.2f}% 확률로 부정 리뷰입니다.\".format((1 - score) * 100))\n",
    "\n",
    "sentence_pred('이 영화 개꿀잼 ㅋㅋㅋ')\n",
    "sentence_pred('이 영화 핵노잼 ㅠㅠ')\n",
    "sentence_pred('이딴게 영화냐 ㅉㅉ')\n",
    "sentence_pred('감독 뭐하는 놈이냐?')\n",
    "sentence_pred('와 개쩐다 정말 세계관 최강자들의 영화다')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb1cbb5-00f0-4358-a5ca-000731cf64e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6028cc-4d92-4220-be38-ace4efaed797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5d740-d160-4b1b-8caa-28a234bc0f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
