{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fc665fe-7dc0-4ae8-9717-cf6ad190af2c",
   "metadata": {},
   "source": [
    "# **Day 27: Bayesian 최적화 & 하이퍼파라미터 자동 탐색**\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Theory: 왜 Bayesian 최적화인가?\n",
    "\n",
    "* **Grid Search/Random Search 한계**\n",
    "\n",
    "  * 그리드: 탐색 공간이 커지면 조합 수가 폭발적으로 증가\n",
    "  * 랜덤: 좋은 영역을 놓칠 가능성\n",
    "\n",
    "* **Bayesian 최적화**\n",
    "\n",
    "  1. **Surrogate Model**\n",
    "\n",
    "     * 보통 **가우시안 프로세스(GP)** 또는 **트리 기반** 모델로\n",
    "     * 실제 목적 함수(예: 검증 정확도)를 근사\n",
    "  2. **Acquisition Function**\n",
    "\n",
    "     * 탐색과 활용 사이의 균형을 조절\n",
    "     * 대표 예: **Expected Improvement (EI)**, **Upper Confidence Bound (UCB)**\n",
    "  3. **반복 루프**\n",
    "\n",
    "     1. 초기 몇 점을 무작위로 평가\n",
    "     2. Surrogate를 학습\n",
    "     3. Acquisition을 최대화하는 차기 점 선택\n",
    "     4. 실제 모델 평가 → 데이터에 추가 → 2단계로 돌아감\n",
    "  4. **장점**\n",
    "\n",
    "     * 제한된 평가 횟수에선 가장 유망한 후보를 뽑아 효율적으로 탐색\n",
    "     * 고차원·비선형 공간에서도 강건\n",
    "\n",
    "---\n",
    "\n",
    "## 3. 실습 과제\n",
    "\n",
    "1. **다른 파라미터 추가**\n",
    "\n",
    "   * 예: `criterion=['gini','entropy']`, `max_features=['auto','sqrt']`\n",
    "2. **다른 모델** 적용\n",
    "\n",
    "   * SVM(`trial.suggest_categorical('kernel', [...])`), XGBoost 등\n",
    "3. **딥러닝 모델 튜닝**\n",
    "\n",
    "   * PyTorch MLP에서 `lr`, `dropout_p`, `weight_decay` 등을 Optuna로 자동 탐색\n",
    "   * `epoch` 수, `batch_size`까지 포함해 보세요\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ddd372f-6019-46a9-9435-6f25a2064469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "#optuna: Bayesian 최적화 프레임워크\n",
    "#load_iris: 예제용 Iris 데이터셋 로드 함수\n",
    "#RandomForestClassifier: 탐색할 모델\n",
    "#cross_val_score: 교차검증 점수 계산 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6e538b5-24ac-4490-a875-0f9ea9416231",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()\n",
    "x,y=iris.data, iris.target\n",
    "#X: 특성 행렬, shape = (150, 4)\n",
    "#y: 정답 레이블 벡터, shape = (150,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1b70038-988e-46b4-888a-a2ccbc0edf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(train):\n",
    "    n_estimator=train.suggest_int('n_estimator', 10, 200)\n",
    "    max_depth=train.suggest_int('max_depth',2,20)\n",
    "    min_sample_split=train.suggest_int('min_sample_split',2,10)\n",
    "\n",
    "    clf=RandomForestClassifier(\n",
    "        n_estimators=n_estimator,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_sample_split,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    score=cross_val_score(clf, x,y,cv=3).mean()\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497bac8b-d332-4c84-be93-4028349a0cfc",
   "metadata": {},
   "source": [
    "\n",
    "objective 함수\n",
    "\n",
    "Optuna가 “한 번의 trial(실험)”마다 평가하는 함수\n",
    "\n",
    "trial.suggest_int(name, low, high)\n",
    "\n",
    "이름(name)으로 파라미터를 등록하고, 구간 [low, high] 사이 정수 값을 샘플링\n",
    "\n",
    "여기서는\n",
    "\n",
    "n_estimator: 트리 개수 (10~200)\n",
    "\n",
    "max_depth: 최대 깊이 (2~20)\n",
    "\n",
    "min_sample_split: 내부 노드 분할 최소 샘플 수 (2~10)\n",
    "\n",
    "이 파라미터들로 랜덤포레스트 모델을 만들고,\n",
    "\n",
    "cross_val_score(..., cv=3) 로 3-폴드 교차검증 정확도를 계산 → 평균값을 score로 반환\n",
    "\n",
    "Optuna는 objective가 반환하는 score를 최대화하려고 시도\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83e06002-9b6c-4e6b-b9b9-44629e61c442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 14:00:09,948] A new study created in memory with name: no-name-d5625eb0-2ae9-4a4f-a0d4-d6a63ecd2598\n",
      "[I 2025-05-16 14:00:10,149] Trial 0 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 118, 'max_depth': 3, 'min_samples_split': 2, 'criterion': 'entropy', 'max_features': 0.5}. Best is trial 0 with value: 0.9533333333333333.\n",
      "[I 2025-05-16 14:00:10,214] Trial 1 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 37, 'max_depth': 17, 'min_samples_split': 3, 'criterion': 'gini', 'max_features': 0.5}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:10,351] Trial 2 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 83, 'max_depth': 9, 'min_samples_split': 6, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:10,480] Trial 3 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 77, 'max_depth': 10, 'min_samples_split': 8, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:10,682] Trial 4 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 121, 'max_depth': 9, 'min_samples_split': 7, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:10,983] Trial 5 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 184, 'max_depth': 17, 'min_samples_split': 5, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:11,112] Trial 6 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 72, 'max_depth': 14, 'min_samples_split': 10, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:11,394] Trial 7 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 164, 'max_depth': 7, 'min_samples_split': 6, 'criterion': 'gini', 'max_features': 0.5}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:11,616] Trial 8 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 135, 'max_depth': 2, 'min_samples_split': 3, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:11,694] Trial 9 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 44, 'max_depth': 17, 'min_samples_split': 7, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:11,736] Trial 10 finished with value: 0.96 and parameters: {'n_estimators': 18, 'max_depth': 20, 'min_samples_split': 4, 'criterion': 'gini', 'max_features': None}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:11,855] Trial 11 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 65, 'max_depth': 13, 'min_samples_split': 2, 'criterion': 'entropy', 'max_features': 0.5}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:11,886] Trial 12 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 10, 'max_depth': 6, 'min_samples_split': 4, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:12,052] Trial 13 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 94, 'max_depth': 13, 'min_samples_split': 9, 'criterion': 'entropy', 'max_features': None}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:12,141] Trial 14 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 47, 'max_depth': 17, 'min_samples_split': 5, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:12,225] Trial 15 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 41, 'max_depth': 6, 'min_samples_split': 4, 'criterion': 'gini', 'max_features': 0.5}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:12,402] Trial 16 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 102, 'max_depth': 20, 'min_samples_split': 6, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:12,463] Trial 17 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 30, 'max_depth': 12, 'min_samples_split': 3, 'criterion': 'gini', 'max_features': 0.5}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:12,585] Trial 18 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 64, 'max_depth': 15, 'min_samples_split': 8, 'criterion': 'gini', 'max_features': None}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:12,831] Trial 19 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 145, 'max_depth': 8, 'min_samples_split': 5, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:12,983] Trial 20 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 87, 'max_depth': 4, 'min_samples_split': 3, 'criterion': 'gini', 'max_features': 0.5}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:13,130] Trial 21 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 81, 'max_depth': 10, 'min_samples_split': 8, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:13,231] Trial 22 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 53, 'max_depth': 11, 'min_samples_split': 9, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:13,293] Trial 23 finished with value: 0.96 and parameters: {'n_estimators': 30, 'max_depth': 10, 'min_samples_split': 7, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:13,498] Trial 24 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 114, 'max_depth': 15, 'min_samples_split': 10, 'criterion': 'entropy', 'max_features': 0.5}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:13,649] Trial 25 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 78, 'max_depth': 8, 'min_samples_split': 8, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:13,757] Trial 26 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 59, 'max_depth': 11, 'min_samples_split': 9, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:13,931] Trial 27 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 99, 'max_depth': 5, 'min_samples_split': 6, 'criterion': 'entropy', 'max_features': None}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:13,994] Trial 28 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 28, 'max_depth': 9, 'min_samples_split': 7, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:14,218] Trial 29 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 124, 'max_depth': 18, 'min_samples_split': 2, 'criterion': 'entropy', 'max_features': 0.5}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:14,413] Trial 30 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 111, 'max_depth': 12, 'min_samples_split': 5, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:14,632] Trial 31 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 126, 'max_depth': 9, 'min_samples_split': 7, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:14,876] Trial 32 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 141, 'max_depth': 9, 'min_samples_split': 8, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:15,192] Trial 33 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 186, 'max_depth': 7, 'min_samples_split': 6, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:15,471] Trial 34 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 159, 'max_depth': 8, 'min_samples_split': 7, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:15,805] Trial 35 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 199, 'max_depth': 10, 'min_samples_split': 9, 'criterion': 'entropy', 'max_features': 0.5}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:15,963] Trial 36 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 89, 'max_depth': 12, 'min_samples_split': 10, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:16,099] Trial 37 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 76, 'max_depth': 7, 'min_samples_split': 8, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:16,287] Trial 38 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 109, 'max_depth': 15, 'min_samples_split': 6, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:16,410] Trial 39 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 69, 'max_depth': 2, 'min_samples_split': 4, 'criterion': 'gini', 'max_features': 0.5}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:16,635] Trial 40 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 123, 'max_depth': 14, 'min_samples_split': 2, 'criterion': 'entropy', 'max_features': None}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:16,914] Trial 41 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 167, 'max_depth': 19, 'min_samples_split': 5, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:17,228] Trial 42 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 182, 'max_depth': 17, 'min_samples_split': 6, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:17,498] Trial 43 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 158, 'max_depth': 16, 'min_samples_split': 7, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:17,528] Trial 44 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 10, 'max_depth': 18, 'min_samples_split': 3, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:17,615] Trial 45 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 47, 'max_depth': 13, 'min_samples_split': 5, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:17,783] Trial 46 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 95, 'max_depth': 11, 'min_samples_split': 4, 'criterion': 'gini', 'max_features': 0.5}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:17,851] Trial 47 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 36, 'max_depth': 6, 'min_samples_split': 6, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:17,957] Trial 48 finished with value: 0.96 and parameters: {'n_estimators': 56, 'max_depth': 14, 'min_samples_split': 7, 'criterion': 'entropy', 'max_features': None}. Best is trial 1 with value: 0.9666666666666667.\n",
      "[I 2025-05-16 14:00:18,107] Trial 49 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 84, 'max_depth': 16, 'min_samples_split': 5, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9666666666666667.\n"
     ]
    }
   ],
   "source": [
    "study=optuna.create_study(direction='maximize')\n",
    "#study.optimize(objective,n_trials=50)\n",
    "study.optimize(objector,n_trials=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebfd639-dcbf-4a35-a1b9-82c37427ff12",
   "metadata": {},
   "source": [
    "스터디 생성 및 최적화 실행\n",
    "\n",
    "create_study(direction='maximize')\n",
    "\n",
    "goal: objective의 반환값(정확도)을 최대화\n",
    "\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "objective 함수를 최대 50번 호출\n",
    "\n",
    "각 trial마다\n",
    "\n",
    "suggest_*로 파라미터 샘플링\n",
    "\n",
    "모델 학습·평가\n",
    "\n",
    "score 기록\n",
    "\n",
    "surrogate 모델(GP 등) 업데이트 → 다음 trial에 더 좋은 후보 제안"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4590f2d-39e3-46fa-94a9-6dd59f5008e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.9666666666666667\n",
      "Best Params:\n",
      "  n_estimator: 69\n",
      "  max_depth: 16\n",
      "  min_sample_split: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n결과 조회\\nstudy.best_value: 최적 trial이 낸 최고 점수(교차검증 정확도)\\nstudy.best_trial.params: 최적 trial에서 선택된 파라미터 조합\\n\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best Accuracy:\", study.best_value)\n",
    "print(\"Best Params:\")\n",
    "for key, val in study.best_trial.params.items():\n",
    "    print(f\"  {key}: {val}\")\n",
    "\n",
    "'''\n",
    "결과 조회\n",
    "study.best_value: 최적 trial이 낸 최고 점수(교차검증 정확도)\n",
    "study.best_trial.params: 최적 trial에서 선택된 파라미터 조합\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e13c8a-cdfb-4d7d-accb-b56d252523df",
   "metadata": {},
   "source": [
    "\n",
    "### 전체 흐름 요약\n",
    "\n",
    "1. **데이터 준비** → 2. **objective 함수 정의**\n",
    "2. **파라미터 공간**을 `suggest_*`로 설정\n",
    "3. `cross_val_score`로 모델 성능 측정\n",
    "4. **Optuna 스터디** 생성 → `optimize()` 호출\n",
    "\n",
    "   * surrogate → acquisition → 파라미터 제안 → 평가 → 업데이트\n",
    "5. **최적값**과 **최적 파라미터**를 `study.best_value`/`study.best_trial.params`로 확인\n",
    "\n",
    "이 과정을 통해 전통적인 Grid/Random Search보다 훨씬 적은 실험 횟수로, 높은 성능을 내는 파라미터 조합을 효율적으로 찾을 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46bf64-fed0-4a41-b2cf-734efb5d0143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f56be062-e58e-4ab1-b813-e0fdf0d47aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objector(trial):\n",
    "    # 기존 파라미터\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
    "    max_depth    = trial.suggest_int('max_depth', 2, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "\n",
    "    # 추가 탐색 파라미터\n",
    "    criterion    = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    max_features = trial.suggest_categorical('max_features',\n",
    "                                             ['sqrt', 'log2', 0.5,None])\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        criterion=criterion,\n",
    "        max_features=max_features,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    score = cross_val_score(clf, x, y, cv=3).mean()\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab445f79-a244-4965-9031-f7e6c5035899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#다른 파라미터 추가하기\n",
    "def objector(train):\n",
    "    n_estimator=train.suggest_int('n_estimator', 10, 200)\n",
    "    max_depth=train.suggest_int('max_depth',2,20)\n",
    "    min_sample_split=train.suggest_int('min_sample_split',2,10)\n",
    "    \n",
    "    criter=train.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    max_feature=train.suggest_categorical('max_features',\n",
    "                                             ['auto', 'sqrt', 'log2', 0.5])\n",
    "\n",
    "    clf=RandomForestClassifier(\n",
    "        n_estimators=n_estimator,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_sample_split,\n",
    "        criterion=criter,\n",
    "        max_features=max_feature,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    score=cross_val_score(clf, x,y,cv=3).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7b459a-478c-42ce-a406-c2695e23d166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e04ac49d-fd66-4a0e-863e-6da8b17a6b05",
   "metadata": {},
   "source": [
    "# 다른 모델 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "606711db-4183-432c-9673-bd5715b144bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 14:10:39,957] A new study created in memory with name: no-name-3e6e571e-eb5f-405d-b55a-1a239005a0df\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:39,964] Trial 0 finished with value: 0.98 and parameters: {'C': 75.04826342309957, 'kernel': 'rbf', 'gamma': 0.003190074554097529}. Best is trial 0 with value: 0.98.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:39,970] Trial 1 finished with value: 0.32 and parameters: {'C': 0.0013844650972591847, 'kernel': 'poly', 'gamma': 0.004372189925182807}. Best is trial 0 with value: 0.98.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:39,978] Trial 2 finished with value: 0.96 and parameters: {'C': 3.892264358091974, 'kernel': 'rbf', 'gamma': 0.013981786897332605}. Best is trial 0 with value: 0.98.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:39,988] Trial 3 finished with value: 0.7799999999999999 and parameters: {'C': 0.2585191325116475, 'kernel': 'rbf', 'gamma': 0.010107044327467776}. Best is trial 0 with value: 0.98.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:39,996] Trial 4 finished with value: 0.32 and parameters: {'C': 0.004156780943675241, 'kernel': 'poly', 'gamma': 0.002262417145278674}. Best is trial 0 with value: 0.98.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,002] Trial 5 finished with value: 0.9533333333333333 and parameters: {'C': 0.047282321745351207, 'kernel': 'linear', 'gamma': 0.01753466601454157}. Best is trial 0 with value: 0.98.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,009] Trial 6 finished with value: 0.32 and parameters: {'C': 0.0018685990346118493, 'kernel': 'poly', 'gamma': 0.0002839690058423705}. Best is trial 0 with value: 0.98.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,018] Trial 7 finished with value: 0.7333333333333334 and parameters: {'C': 0.04984164628315159, 'kernel': 'rbf', 'gamma': 0.040990235080986655}. Best is trial 0 with value: 0.98.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,025] Trial 8 finished with value: 0.9666666666666667 and parameters: {'C': 0.6985846850099858, 'kernel': 'rbf', 'gamma': 0.05215722921175674}. Best is trial 0 with value: 0.98.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,033] Trial 9 finished with value: 0.94 and parameters: {'C': 11.838124791580604, 'kernel': 'rbf', 'gamma': 0.0010673119758576345}. Best is trial 0 with value: 0.98.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,044] Trial 10 finished with value: 0.9666666666666667 and parameters: {'C': 645.1570640557003, 'kernel': 'linear', 'gamma': 0.0001436412190266747}. Best is trial 0 with value: 0.98.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,054] Trial 11 finished with value: 0.9733333333333333 and parameters: {'C': 60.887237042811726, 'kernel': 'rbf', 'gamma': 0.09077680892842377}. Best is trial 0 with value: 0.98.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,064] Trial 12 finished with value: 0.96 and parameters: {'C': 204.18878285250068, 'kernel': 'rbf', 'gamma': 0.09051730590315324}. Best is trial 0 with value: 0.98.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,075] Trial 13 finished with value: 0.9666666666666667 and parameters: {'C': 50.933893037263665, 'kernel': 'rbf', 'gamma': 0.0006768765690373358}. Best is trial 0 with value: 0.98.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,086] Trial 14 finished with value: 0.96 and parameters: {'C': 36.96434754530277, 'kernel': 'rbf', 'gamma': 0.0035632043776889577}. Best is trial 0 with value: 0.98.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,098] Trial 15 finished with value: 0.9666666666666667 and parameters: {'C': 983.0389722896131, 'kernel': 'linear', 'gamma': 0.0008274089606868623}. Best is trial 0 with value: 0.98.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,112] Trial 16 finished with value: 0.9866666666666667 and parameters: {'C': 107.88786161733881, 'kernel': 'rbf', 'gamma': 0.006723794237109261}. Best is trial 16 with value: 0.9866666666666667.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,125] Trial 17 finished with value: 0.9666666666666667 and parameters: {'C': 4.3782589386522295, 'kernel': 'rbf', 'gamma': 0.007258766235123019}. Best is trial 16 with value: 0.9866666666666667.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,136] Trial 18 finished with value: 0.9666666666666667 and parameters: {'C': 154.26305468192962, 'kernel': 'linear', 'gamma': 0.0016471668511696593}. Best is trial 16 with value: 0.9866666666666667.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,148] Trial 19 finished with value: 0.8666666666666667 and parameters: {'C': 7.359345778984599, 'kernel': 'poly', 'gamma': 0.0059369174925002505}. Best is trial 16 with value: 0.9866666666666667.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,156] Trial 20 finished with value: 0.9733333333333333 and parameters: {'C': 203.779588408024, 'kernel': 'rbf', 'gamma': 0.021454389961802312}. Best is trial 16 with value: 0.9866666666666667.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,167] Trial 21 finished with value: 0.9933333333333333 and parameters: {'C': 29.106180624532662, 'kernel': 'rbf', 'gamma': 0.0269021457677597}. Best is trial 21 with value: 0.9933333333333333.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,176] Trial 22 finished with value: 0.9866666666666667 and parameters: {'C': 17.62484272356481, 'kernel': 'rbf', 'gamma': 0.02874422544346159}. Best is trial 21 with value: 0.9933333333333333.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,186] Trial 23 finished with value: 0.9866666666666667 and parameters: {'C': 18.053998441293206, 'kernel': 'rbf', 'gamma': 0.029879599260339364}. Best is trial 21 with value: 0.9933333333333333.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,198] Trial 24 finished with value: 0.9199999999999999 and parameters: {'C': 0.707376020278621, 'kernel': 'rbf', 'gamma': 0.01152749639174431}. Best is trial 21 with value: 0.9933333333333333.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,208] Trial 25 finished with value: 0.96 and parameters: {'C': 1.8121371561875372, 'kernel': 'rbf', 'gamma': 0.029488718202132867}. Best is trial 21 with value: 0.9933333333333333.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,217] Trial 26 finished with value: 0.98 and parameters: {'C': 21.279687423815226, 'kernel': 'rbf', 'gamma': 0.05131178752347855}. Best is trial 21 with value: 0.9933333333333333.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,226] Trial 27 finished with value: 0.9666666666666667 and parameters: {'C': 286.27769339743725, 'kernel': 'rbf', 'gamma': 0.007706205296063061}. Best is trial 21 with value: 0.9933333333333333.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,236] Trial 28 finished with value: 0.9733333333333333 and parameters: {'C': 1.9470933483052404, 'kernel': 'poly', 'gamma': 0.025021651426732926}. Best is trial 21 with value: 0.9933333333333333.\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1590068917.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
      "[I 2025-05-16 14:10:40,244] Trial 29 finished with value: 0.9666666666666667 and parameters: {'C': 65.86911445446873, 'kernel': 'linear', 'gamma': 0.01641712528979384}. Best is trial 21 with value: 0.9933333333333333.\n"
     ]
    }
   ],
   "source": [
    "#SVM 분류기\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def objector_svc(trial):\n",
    "    C=trial.suggest_loguniform(\"C\",1e-3, 1e3)\n",
    "    kernel=trial.suggest_categorical('kernel',['linear', 'rbf', 'poly'])\n",
    "    gamma=trial.suggest_loguniform('gamma',1e-4, 1e-1)\n",
    "\n",
    "    clf=SVC(C=C,kernel=kernel,gamma=gamma,probability=True)\n",
    "\n",
    "    score=cross_val_score(clf,x,y,cv=3).mean()\n",
    "    return score\n",
    "\n",
    "\n",
    "study_svm = optuna.create_study(direction='maximize')\n",
    "study_svm.optimize(objector_svc, n_trials=30)\n",
    "\n",
    "#suggest_loguniform은 로그 스케일 탐색에 유용합니다.\n",
    "#probability=True를 넣어야 predict_proba를 쓸 때 오류가 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "db2023ce-fd5b-45c7-8332-473b2588337f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 14:24:14,646] A new study created in memory with name: no-name-d07c7c75-d674-4f7e-8e10-5bf3ac8bd1ea\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\1726104957.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'eta':trial.suggest_loguniform('eta', 1e-3, 1e-1),\n",
      "C:\\Users\\JH\\anaconda\\Lib\\site-packages\\xgboost\\training.py:209: UserWarning: [14:24:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"colsample\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "C:\\Users\\JH\\anaconda\\Lib\\site-packages\\xgboost\\training.py:215: UserWarning: [14:24:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"colsample\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "[I 2025-05-16 14:24:14,827] Trial 0 finished with value: -0.8853971787293752 and parameters: {'eta': 0.0021047757444497615, 'max_depth': 7, 'subsample': 0.5613155612140542, 'colsample': 0.617790407529333}. Best is trial 0 with value: -0.8853971787293752.\n",
      "[I 2025-05-16 14:24:14,956] Trial 1 finished with value: -0.39762061278025307 and parameters: {'eta': 0.011800776950383455, 'max_depth': 6, 'subsample': 0.5690339434603358, 'colsample': 0.7659770412503984}. Best is trial 1 with value: -0.39762061278025307.\n",
      "[I 2025-05-16 14:24:15,053] Trial 2 finished with value: -0.17266056074450412 and parameters: {'eta': 0.06658328765508227, 'max_depth': 9, 'subsample': 0.7342893665013122, 'colsample': 0.6481783077617347}. Best is trial 2 with value: -0.17266056074450412.\n",
      "C:\\Users\\JH\\anaconda\\Lib\\site-packages\\xgboost\\training.py:209: UserWarning: [14:24:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"colsample\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "C:\\Users\\JH\\anaconda\\Lib\\site-packages\\xgboost\\training.py:215: UserWarning: [14:24:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"colsample\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "[I 2025-05-16 14:24:15,158] Trial 3 finished with value: -0.3249380205074946 and parameters: {'eta': 0.014753613556294088, 'max_depth': 9, 'subsample': 0.6283738141680564, 'colsample': 0.7971449396823542}. Best is trial 2 with value: -0.17266056074450412.\n",
      "[I 2025-05-16 14:24:15,282] Trial 4 finished with value: -0.1853366117179394 and parameters: {'eta': 0.04393556400536183, 'max_depth': 10, 'subsample': 0.8468867074206576, 'colsample': 0.6015708212086235}. Best is trial 2 with value: -0.17266056074450412.\n",
      "[I 2025-05-16 14:24:15,426] Trial 5 finished with value: -0.5901727998256683 and parameters: {'eta': 0.0061817212839319615, 'max_depth': 3, 'subsample': 0.8910626973648026, 'colsample': 0.8883658290026973}. Best is trial 2 with value: -0.17266056074450412.\n",
      "[I 2025-05-16 14:24:15,626] Trial 6 finished with value: -0.17095542319118975 and parameters: {'eta': 0.03535073089922126, 'max_depth': 7, 'subsample': 0.5711447234683631, 'colsample': 0.7239364611616474}. Best is trial 6 with value: -0.17095542319118975.\n",
      "[I 2025-05-16 14:24:15,784] Trial 7 finished with value: -0.1873421032105883 and parameters: {'eta': 0.0753284017493632, 'max_depth': 5, 'subsample': 0.9093367615058048, 'colsample': 0.8807978750020824}. Best is trial 6 with value: -0.17095542319118975.\n",
      "[I 2025-05-16 14:24:15,900] Trial 8 finished with value: -0.553622124393781 and parameters: {'eta': 0.007225188611483633, 'max_depth': 10, 'subsample': 0.6390814562594171, 'colsample': 0.8093027409341236}. Best is trial 6 with value: -0.17095542319118975.\n",
      "[I 2025-05-16 14:24:16,014] Trial 9 finished with value: -0.7454092355569205 and parameters: {'eta': 0.0036635397514830663, 'max_depth': 6, 'subsample': 0.8914638123847789, 'colsample': 0.685943278281417}. Best is trial 6 with value: -0.17095542319118975.\n",
      "C:\\Users\\JH\\anaconda\\Lib\\site-packages\\xgboost\\training.py:209: UserWarning: [14:24:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"colsample\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "C:\\Users\\JH\\anaconda\\Lib\\site-packages\\xgboost\\training.py:215: UserWarning: [14:24:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"colsample\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "[I 2025-05-16 14:24:16,153] Trial 10 finished with value: -0.20258645484844848 and parameters: {'eta': 0.026800381551473712, 'max_depth': 3, 'subsample': 0.7600036410936516, 'colsample': 0.9987079325726478}. Best is trial 6 with value: -0.17095542319118975.\n",
      "[I 2025-05-16 14:24:16,229] Trial 11 finished with value: -0.16834036828329166 and parameters: {'eta': 0.08992742931251574, 'max_depth': 8, 'subsample': 0.7352279665086573, 'colsample': 0.5064489651775973}. Best is trial 11 with value: -0.16834036828329166.\n",
      "[I 2025-05-16 14:24:16,356] Trial 12 finished with value: -0.2029474128286044 and parameters: {'eta': 0.029874897818888187, 'max_depth': 8, 'subsample': 0.9992029175733365, 'colsample': 0.5028540516955623}. Best is trial 11 with value: -0.16834036828329166.\n",
      "[I 2025-05-16 14:24:16,453] Trial 13 finished with value: -0.15141474702085056 and parameters: {'eta': 0.09589440888155547, 'max_depth': 8, 'subsample': 0.5016361210733093, 'colsample': 0.5012838549675841}. Best is trial 13 with value: -0.15141474702085056.\n",
      "[I 2025-05-16 14:24:16,548] Trial 14 finished with value: -0.1527213117790719 and parameters: {'eta': 0.09478343922459488, 'max_depth': 8, 'subsample': 0.5004151147239781, 'colsample': 0.5075509997356913}. Best is trial 13 with value: -0.15141474702085056.\n",
      "[I 2025-05-16 14:24:16,698] Trial 15 finished with value: -0.9770789488156636 and parameters: {'eta': 0.0011338126705614665, 'max_depth': 8, 'subsample': 0.5292591654614075, 'colsample': 0.5660929701230106}. Best is trial 13 with value: -0.15141474702085056.\n",
      "[I 2025-05-16 14:24:16,873] Trial 16 finished with value: -0.2955270568529765 and parameters: {'eta': 0.016427372161079506, 'max_depth': 5, 'subsample': 0.6540621007668097, 'colsample': 0.5634797466880717}. Best is trial 13 with value: -0.15141474702085056.\n",
      "[I 2025-05-16 14:24:17,014] Trial 17 finished with value: -0.1537177501618862 and parameters: {'eta': 0.053093818372565944, 'max_depth': 9, 'subsample': 0.5065525748836919, 'colsample': 0.5522015531714954}. Best is trial 13 with value: -0.15141474702085056.\n",
      "C:\\Users\\JH\\anaconda\\Lib\\site-packages\\xgboost\\training.py:209: UserWarning: [14:24:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"colsample\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "C:\\Users\\JH\\anaconda\\Lib\\site-packages\\xgboost\\training.py:215: UserWarning: [14:24:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"colsample\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "[I 2025-05-16 14:24:17,092] Trial 18 finished with value: -0.16234737139816083 and parameters: {'eta': 0.09650974003782654, 'max_depth': 7, 'subsample': 0.6824565452065732, 'colsample': 0.6601359249989428}. Best is trial 13 with value: -0.15141474702085056.\n",
      "[I 2025-05-16 14:24:17,213] Trial 19 finished with value: -0.2633924344182014 and parameters: {'eta': 0.01935906800745691, 'max_depth': 8, 'subsample': 0.5071611701394594, 'colsample': 0.5312885807635397}. Best is trial 13 with value: -0.15141474702085056.\n",
      "[I 2025-05-16 14:24:17,363] Trial 20 finished with value: -0.16317331121613585 and parameters: {'eta': 0.04567411140227588, 'max_depth': 5, 'subsample': 0.6074047868223375, 'colsample': 0.6052721485543935}. Best is trial 13 with value: -0.15141474702085056.\n",
      "[I 2025-05-16 14:24:17,472] Trial 21 finished with value: -0.15601449777682622 and parameters: {'eta': 0.05177095458347212, 'max_depth': 9, 'subsample': 0.500804750846033, 'colsample': 0.5613760067935543}. Best is trial 13 with value: -0.15141474702085056.\n",
      "[I 2025-05-16 14:24:17,599] Trial 22 finished with value: -0.15514184516544144 and parameters: {'eta': 0.055889164555612214, 'max_depth': 9, 'subsample': 0.5426110578467351, 'colsample': 0.530866253189686}. Best is trial 13 with value: -0.15141474702085056.\n",
      "[I 2025-05-16 14:24:17,676] Trial 23 finished with value: -0.15698139326026042 and parameters: {'eta': 0.09443765367221067, 'max_depth': 10, 'subsample': 0.5911248935109871, 'colsample': 0.5754567802025072}. Best is trial 13 with value: -0.15141474702085056.\n",
      "[I 2025-05-16 14:24:17,792] Trial 24 finished with value: -0.21339743490020435 and parameters: {'eta': 0.024760081086653514, 'max_depth': 8, 'subsample': 0.5022774192114678, 'colsample': 0.5050232869240731}. Best is trial 13 with value: -0.15141474702085056.\n",
      "[I 2025-05-16 14:24:17,932] Trial 25 finished with value: -0.153346551215897 and parameters: {'eta': 0.06165356875681429, 'max_depth': 9, 'subsample': 0.5406864474998558, 'colsample': 0.6352787653040693}. Best is trial 13 with value: -0.15141474702085056.\n",
      "[I 2025-05-16 14:24:18,073] Trial 26 finished with value: -0.16485468146701654 and parameters: {'eta': 0.06460955116926433, 'max_depth': 7, 'subsample': 0.6799798360485871, 'colsample': 0.7103059484192851}. Best is trial 13 with value: -0.15141474702085056.\n",
      "C:\\Users\\JH\\anaconda\\Lib\\site-packages\\xgboost\\training.py:209: UserWarning: [14:24:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"colsample\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "C:\\Users\\JH\\anaconda\\Lib\\site-packages\\xgboost\\training.py:215: UserWarning: [14:24:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"colsample\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "[I 2025-05-16 14:24:18,201] Trial 27 finished with value: -0.1622238273297747 and parameters: {'eta': 0.04068100563416714, 'max_depth': 10, 'subsample': 0.5421288854045044, 'colsample': 0.6338360496455288}. Best is trial 13 with value: -0.15141474702085056.\n",
      "[I 2025-05-16 14:24:18,320] Trial 28 finished with value: -0.15649081826210023 and parameters: {'eta': 0.07471557354084055, 'max_depth': 8, 'subsample': 0.6083088069609854, 'colsample': 0.6730529056203686}. Best is trial 13 with value: -0.15141474702085056.\n",
      "[I 2025-05-16 14:24:18,458] Trial 29 finished with value: -0.8285363936424256 and parameters: {'eta': 0.002781505954648361, 'max_depth': 7, 'subsample': 0.5779135294707393, 'colsample': 0.6064571426477088}. Best is trial 13 with value: -0.15141474702085056.\n"
     ]
    }
   ],
   "source": [
    "#XGBoost 분류기\n",
    "import xgboost as xgb\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    param={\n",
    "        'objective':'multi:softprob',\n",
    "        'num_class':3,\n",
    "        'eta':trial.suggest_loguniform('eta', 1e-3, 1e-1),\n",
    "        'max_depth':trial.suggest_int('max_depth',3,10),\n",
    "        'subsample':trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample':trial.suggest_float('colsample',0.5, 1.0)\n",
    "    }\n",
    "\n",
    "    dtrain=xgb.DMatrix(x,label=y)\n",
    "    cv=xgb.cv(param,dtrain,num_boost_round=100,nfold=3,metrics='mlogloss',early_stopping_rounds=10)\n",
    "    return -cv['test-mlogloss-mean'].min()\n",
    "\n",
    "\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d321a2-bcfa-4eac-9fc8-abf8a3d6c447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b666e18f-bfc9-4e6d-97cc-5d394c80a82f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "216904db-0838-4e70-a33c-875810a7910e",
   "metadata": {},
   "source": [
    "# 딥러닝(PyTorch) 모델 튜닝하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bd3d4e9f-4764-487f-9d1a-eb7eb6228b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_size, dropout_p):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, hidden_size)\n",
    "        self.drop = nn.Dropout(dropout_p)\n",
    "        self.fc2 = nn.Linear(hidden_size, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "edfaaff7-fe47-4ade-8adf-fb810922e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_torch(train):\n",
    "    hidden=train.suggest_int('hidden', 64, 512, step=64)\n",
    "    drop=train.suggest_float('drop',0.0, 0.5)\n",
    "    lr=train.suggest_loguniform('lr',1e-4, 1e-1)\n",
    "    weight_decay=train.suggest_loguniform('weight_decay', 1e-6, 1e-2)\n",
    "\n",
    "    model=MLP(hidden,drop).to(device)\n",
    "    criter=nn.CrossEntropyLoss()\n",
    "    optimy=optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.train()\n",
    "    data,target=next(iter(train_loader))\n",
    "    data,target=data.to(device),target.to(device)\n",
    "    optimy.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = criter(out, target)\n",
    "    loss.backward()\n",
    "    optimy.step()\n",
    "    pred = out.argmax(1)\n",
    "    acc = (pred == target).float().mean().item()\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8ad49d4e-5f4c-493d-a9a8-8c479d814a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 02:43:35,386] A new study created in memory with name: no-name-dd89d6e0-9771-4838-b9d8-ba5c98ffaa31\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\2543822558.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr=train.suggest_loguniform('lr',1e-4, 1e-1)\n",
      "C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\2543822558.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=train.suggest_loguniform('weight_decay', 1e-6, 1e-2)\n",
      "[W 2025-05-17 02:43:38,903] Trial 0 failed with parameters: {'hidden': 192, 'drop': 0.457096911118207, 'lr': 0.0009827088790178623, 'weight_decay': 2.5783602426486673e-05} because of the following error: NameError(\"name 'train_loader' is not defined\").\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\JH\\anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_39732\\2543822558.py\", line 16, in object_torch\n",
      "    data,target=next(iter(train_loader))\n",
      "                          ^^^^^^^^^^^^\n",
      "NameError: name 'train_loader' is not defined\n",
      "[W 2025-05-17 02:43:38,906] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m study_torch \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m study_torch\u001b[38;5;241m.\u001b[39moptimize(object_torch, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     _optimize(\n\u001b[0;32m    476\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    477\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    478\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    479\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    480\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    481\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    482\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    483\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    484\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    485\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         _optimize_sequential(\n\u001b[0;32m     64\u001b[0m             study,\n\u001b[0;32m     65\u001b[0m             func,\n\u001b[0;32m     66\u001b[0m             n_trials,\n\u001b[0;32m     67\u001b[0m             timeout,\n\u001b[0;32m     68\u001b[0m             catch,\n\u001b[0;32m     69\u001b[0m             callbacks,\n\u001b[0;32m     70\u001b[0m             gc_after_trial,\n\u001b[0;32m     71\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     72\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     73\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     74\u001b[0m         )\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[101], line 16\u001b[0m, in \u001b[0;36mobject_torch\u001b[1;34m(train)\u001b[0m\n\u001b[0;32m      9\u001b[0m optimy\u001b[38;5;241m=\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\n\u001b[0;32m     10\u001b[0m     model\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[0;32m     11\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m     12\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mweight_decay\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 16\u001b[0m data,target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[0;32m     17\u001b[0m data,target\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mto(device),target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     18\u001b[0m optimy\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda'if torch.cuda.is_available()else'cpu')\n",
    "study_torch = optuna.create_study(direction='maximize')\n",
    "study_torch.optimize(object_torch, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be5c8f-4a84-438d-9ad9-49155e8a3fac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CUDA 12.4)",
   "language": "python",
   "name": "cuda124"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
