{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "168d99c5-fb77-4571-b65c-32eca116471a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'torch._C._distributed_c10d.ProcessGroup' has no attribute 'Options'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptim\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda\\envs\\mygpuenv\\Lib\\site-packages\\torch\\__init__.py:2016\u001b[39m\n\u001b[32m   2009\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_compile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _disable_dynamo  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2011\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2012\u001b[39m \u001b[38;5;66;03m# Import interface functions defined in Python\u001b[39;00m\n\u001b[32m   2013\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2014\u001b[39m \n\u001b[32m   2015\u001b[39m \u001b[38;5;66;03m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2016\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _VF \u001b[38;5;28;01mas\u001b[39;00m _VF, functional \u001b[38;5;28;01mas\u001b[39;00m functional  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2017\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# usort: skip # noqa: F403\u001b[39;00m\n\u001b[32m   2019\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2020\u001b[39m \u001b[38;5;66;03m# Remove unnecessary members\u001b[39;00m\n\u001b[32m   2021\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda\\envs\\mygpuenv\\Lib\\site-packages\\torch\\functional.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, List, Optional, Sequence, Tuple, TYPE_CHECKING, Union\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _VF, Tensor\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _add_docstr\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda\\envs\\mygpuenv\\Lib\\site-packages\\torch\\nn\\__init__.py:8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparameter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m      3\u001b[39m     Buffer \u001b[38;5;28;01mas\u001b[39;00m Buffer,\n\u001b[32m      4\u001b[39m     Parameter \u001b[38;5;28;01mas\u001b[39;00m Parameter,\n\u001b[32m      5\u001b[39m     UninitializedBuffer \u001b[38;5;28;01mas\u001b[39;00m UninitializedBuffer,\n\u001b[32m      6\u001b[39m     UninitializedParameter \u001b[38;5;28;01mas\u001b[39;00m UninitializedParameter,\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# usort: skip # noqa: F403\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     attention \u001b[38;5;28;01mas\u001b[39;00m attention,\n\u001b[32m     11\u001b[39m     functional \u001b[38;5;28;01mas\u001b[39;00m functional,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     utils \u001b[38;5;28;01mas\u001b[39;00m utils,\n\u001b[32m     17\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparallel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataParallel \u001b[38;5;28;01mas\u001b[39;00m DataParallel\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda\\envs\\mygpuenv\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodule\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Module  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bilinear, Identity, LazyLinear, Linear  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     CELU,\n\u001b[32m      5\u001b[39m     ELU,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     Threshold,\n\u001b[32m     33\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda\\envs\\mygpuenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:29\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_prims_common\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeviceLikeType\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparameter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Buffer, Parameter\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_python_dispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_traceable_wrapper_subclass\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackwardHook, RemovableHandle\n\u001b[32m     33\u001b[39m __all__ = [\n\u001b[32m     34\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mregister_module_forward_pre_hook\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     35\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mregister_module_forward_hook\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mModule\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     43\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda\\envs\\mygpuenv\\Lib\\site-packages\\torch\\utils\\__init__.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mweakref\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     backcompat \u001b[38;5;28;01mas\u001b[39;00m backcompat,\n\u001b[32m     10\u001b[39m     collect_env \u001b[38;5;28;01mas\u001b[39;00m collect_env,\n\u001b[32m     11\u001b[39m     data \u001b[38;5;28;01mas\u001b[39;00m data,\n\u001b[32m     12\u001b[39m     deterministic \u001b[38;5;28;01mas\u001b[39;00m deterministic,\n\u001b[32m     13\u001b[39m     hooks \u001b[38;5;28;01mas\u001b[39;00m hooks,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_registration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     generate_methods_for_privateuse1_backend,\n\u001b[32m     17\u001b[39m     rename_privateuse1_backend,\n\u001b[32m     18\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcpp_backtrace\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_cpp_backtrace\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda\\envs\\mygpuenv\\Lib\\site-packages\\torch\\utils\\data\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     _DatasetKind,\n\u001b[32m      3\u001b[39m     DataLoader,\n\u001b[32m      4\u001b[39m     default_collate,\n\u001b[32m      5\u001b[39m     default_convert,\n\u001b[32m      6\u001b[39m     get_worker_info,\n\u001b[32m      7\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatapipes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_decorator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     argument_validation,\n\u001b[32m     10\u001b[39m     functional_datapipe,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     runtime_validation_disabled,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatapipes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatapipe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     DataChunk,\n\u001b[32m     18\u001b[39m     DFIterDataPipe,\n\u001b[32m     19\u001b[39m     IterDataPipe,\n\u001b[32m     20\u001b[39m     MapDataPipe,\n\u001b[32m     21\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda\\envs\\mygpuenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Generic, Iterable, List, Optional, TypeVar, Union\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdist\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_settings\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExceptionWrapper\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda\\envs\\mygpuenv\\Lib\\site-packages\\torch\\distributed\\__init__.py:122\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys.platform != \u001b[33m\"\u001b[39m\u001b[33mwin32\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_distributed_c10d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HashStore\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdevice_mesh\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeviceMesh, init_device_mesh\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# Variables prefixed with underscore are not auto imported\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# See the comment in `distributed_c10d.py` above `_backend` on why we expose\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# this.\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed_c10d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda\\envs\\mygpuenv\\Lib\\site-packages\\torch\\distributed\\device_mesh.py:64\u001b[39m\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     60\u001b[39m         logger.warning(\n\u001b[32m     61\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mDeviceMesh requires numpy >= 1.21 to be installed for type checking\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     62\u001b[39m         )\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_MeshEnv\u001b[39;00m(threading.local):\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     66\u001b[39m         \u001b[38;5;28mself\u001b[39m.mesh_stack: List[DeviceMesh] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda\\envs\\mygpuenv\\Lib\\site-packages\\torch\\distributed\\device_mesh.py:282\u001b[39m, in \u001b[36m_MeshEnv\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    272\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m    273\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMesh dimension \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmesh_dim_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m does not exist.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    274\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAvailable mesh dimensions are: mesh_dim_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice_mesh.mesh_dim_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    275\u001b[39m         )\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m not_none(device_mesh.mesh_dim_names.index(mesh_dim_name))\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_mesh_dim_group_options\u001b[39m(\n\u001b[32m    279\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    280\u001b[39m     dim: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m    281\u001b[39m     backend: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     pg_options: Optional[ProcessGroup.Options] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    283\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    284\u001b[39m     \u001b[38;5;28mself\u001b[39m.mesh_dim_group_options[dim] = (backend, pg_options)\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_slice_mesh_dims\u001b[39m(\n\u001b[32m    287\u001b[39m     \u001b[38;5;28mself\u001b[39m, device_mesh, mesh_dim_names\n\u001b[32m    288\u001b[39m ) -> List[Tuple[\u001b[38;5;28mint\u001b[39m, ...]]:\n",
      "\u001b[31mAttributeError\u001b[39m: type object 'torch._C._distributed_c10d.ProcessGroup' has no attribute 'Options'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18 # 기본 resnet18 로드\n",
    "from torch.ao.quantization import QuantStub, DeQuantStub, fuse_modules\n",
    "from torch.ao.quantization import get_default_qconfig\n",
    "from torch.ao.quantization.quantize import quantize_static # <--- 이 부분 수정\n",
    "import os\n",
    "import time\n",
    "import copy # deepcopy를 위해 임포트\n",
    "\n",
    "# 1. 하이퍼파라미터 및 설정\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 5\n",
    "CALIBRATION_BATCHES = 100\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 3. 데이터 로더 준비 (MNIST)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "calibration_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "# 4. 모델 학습 함수\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    print(f\"\\n모델 학습 시작 ({num_epochs} 에폭)...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}\")\n",
    "                running_loss = 0.0\n",
    "    print(\"모델 학습 완료.\")\n",
    "\n",
    "# 5. 모델 평가 함수\n",
    "def evaluate_model(model, test_loader, target_device=None):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    if target_device is None:\n",
    "        model_device = next(model.parameters()).device\n",
    "    else:\n",
    "        model_device = target_device\n",
    "\n",
    "    model.to(model_device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(model_device), labels.to(model_device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "# --- 메인 실행 로직 ---\n",
    "\n",
    "# 6. 모델 생성 및 초기 학습 (torchvision의 resnet18 사용)\n",
    "model_fp32 = resnet18(weights=None)\n",
    "\n",
    "model_fp32.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model_fp32.fc = nn.Linear(model_fp32.fc.in_features, 10)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_fp32.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "model_fp32 = model_fp32.to(DEVICE)\n",
    "train_model(model_fp32, train_loader, criterion, optimizer, NUM_EPOCHS)\n",
    "\n",
    "print(\"\\n--- FP32 모델 평가 ---\")\n",
    "fp32_accuracy = evaluate_model(model_fp32, test_loader, target_device=DEVICE)\n",
    "torch.save(model_fp32.state_dict(), \"resnet18_mnist_fp32.pth\")\n",
    "fp32_size = os.path.getsize(\"resnet18_mnist_fp32.pth\") / (1024 * 1024)\n",
    "print(f\"FP32 모델 크기: {fp32_size:.2f} MB\")\n",
    "\n",
    "# --- Static Quantization (Eager Mode 기반) ---\n",
    "\n",
    "# 7. Eager Mode Static Quantization 준비\n",
    "model_fp32.to(\"cpu\") # 모델을 CPU로 옮깁니다.\n",
    "model_fp32.eval()    # 평가 모드 설정\n",
    "\n",
    "# 7-1. Eager Mode 퓨징\n",
    "# torchvision resnet의 퓨징 로직을 따릅니다.\n",
    "# Conv - BatchNorm - ReLU 패턴을 퓨징하여 QuantizedConvReLU와 같이 만듭니다.\n",
    "# model_fp32 자체가 resnet18 인스턴스이므로, resnet에 내장된 fuse_model 메서드를 사용합니다.\n",
    "# 이 메서드는 인플레이스로 모듈을 퓨징합니다.\n",
    "fused_model_eager = copy.deepcopy(model_fp32)\n",
    "fused_model_eager.eval() # 퓨징 전 eval 모드 설정\n",
    "\n",
    "# resnet18 모델의 특정 패턴을 퓨징합니다.\n",
    "# resnet18의 fuse_model() 메서드는 내부적으로 Conv+BN, Conv+BN+ReLU 패턴을 찾아서 퓨징합니다.\n",
    "fused_model_eager.fuse_model()\n",
    "print(\"Eager Mode 모델 퓨징 완료.\")\n",
    "\n",
    "# QuantStub과 DeQuantStub 삽입 (모델의 입력과 출력을 양자화/역양자화)\n",
    "# Eager Mode에서는 이렇게 직접 삽입해야 합니다.\n",
    "model_with_quant_stubs = nn.Sequential(\n",
    "    QuantStub(),\n",
    "    fused_model_eager, # 퓨징된 모델을 Sequential 안에 넣습니다.\n",
    "    DeQuantStub()\n",
    ")\n",
    "\n",
    "# 7-2. QConfig 설정 (Eager Mode에서는 get_default_qconfig 사용)\n",
    "# QConfig는 모듈에 직접 할당됩니다.\n",
    "model_with_quant_stubs.qconfig = get_default_qconfig(\"fbgemm\")\n",
    "# print(f\"Eager Mode QConfig: {model_with_quant_stubs.qconfig}\") # QConfig 확인\n",
    "\n",
    "# 7-3. 모델 준비 (Eager Mode)\n",
    "# prepare 함수는 옵저버를 삽입합니다.\n",
    "# calibrate() 함수를 호출할 때 inplace=False로 새로운 모델을 반환하도록 합니다.\n",
    "# (prepare는 이제 prepare_fx와는 다르게 직접적인 함수 호출이 아닌, 내부적으로 처리될 수 있습니다.)\n",
    "# quantize_static은 prepare와 convert를 한 번에 처리합니다.\n",
    "# 따라서 prepare 단계는 quantize_static 함수가 내부적으로 처리합니다.\n",
    "# 여기서 prepared_model_eager는 단순히 quantize_static을 위한 중간 변수명입니다.\n",
    "# Eager mode에서는 이 부분에 `prepare` 함수를 직접 호출하는 방식도 사용 가능합니다.\n",
    "# 현재 방식은 quantize_static이 내부적으로 prepare를 처리합니다.\n",
    "\n",
    "# quantize_static의 첫 번째 인자로 qconfig와 모델을 전달하여 바로 양자화 진행\n",
    "# calibrate=True로 설정하여 캘리브레이션도 함께 수행\n",
    "print(\"\\n--- Static Quantization Calibration 시작 (Eager Mode) ---\")\n",
    "# calibrate_model = quantize_static(model_with_quant_stubs, qconfig=get_default_qconfig(\"fbgemm\"), inplace=False)\n",
    "# 위의 코드는 prepare와 convert를 한 번에 처리하므로, calibration을 따로 빼내기 어렵습니다.\n",
    "\n",
    "# Eager Mode의 올바른 Prepare -> Calibrate -> Convert 흐름\n",
    "# 1. 모델에 QConfig 할당 (위에서 이미 했음)\n",
    "# 2. prepare_qat (양자화 학습용) 또는 prepare (일반적인 양자화용)\n",
    "#    여기서는 정적 양자화이므로 prepare를 사용합니다.\n",
    "torch.ao.quantization.prepare(model_with_quant_stubs, inplace=True) # model_with_quant_stubs를 inplace로 변경\n",
    "\n",
    "# Calibration (보정)\n",
    "with torch.inference_mode():\n",
    "    for batch_idx, (inputs, labels) in enumerate(calibration_loader):\n",
    "        if batch_idx >= CALIBRATION_BATCHES:\n",
    "            break\n",
    "        inputs = inputs.to(\"cpu\")\n",
    "        model_with_quant_stubs(inputs) # prepare된 모델에 데이터 통과\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"  Calibration batch: {batch_idx}/{CALIBRATION_BATCHES}\")\n",
    "print(\"Calibration 완료.\")\n",
    "\n",
    "# 9. 양자화 적용 및 변환 (Eager Mode)\n",
    "# calibrate가 완료된 모델을 quantize_static으로 변환\n",
    "quantized_model_static_eager = quantize_static(model_with_quant_stubs, inplace=False)\n",
    "quantized_model_static_eager.eval()\n",
    "print(\"Eager Mode convert 완료.\")\n",
    "\n",
    "\n",
    "# 10. 양자화된 모델 가중치 타입 확인 (Eager Mode)\n",
    "print(\"\\n--- Eager Mode Quantized Model Weights Dtype 확인 ---\")\n",
    "for name, module in quantized_model_static_eager.named_modules():\n",
    "    # 양자화된 Conv2d와 Linear 모듈의 가중치는 QTensor 타입입니다.\n",
    "    # QTensor의 dtype을 확인해야 합니다.\n",
    "    if hasattr(module, 'weight') and module.weight is not None:\n",
    "        if isinstance(module.weight, torch.Tensor):\n",
    "            print(f\"모듈: {name}, 가중치 Dtype: {module.weight.dtype}\")\n",
    "        elif isinstance(module.weight, torch.quantized.QTensor): # 양자화된 텐서\n",
    "            print(f\"모듈: {name}, 가중치 Dtype: {module.weight.dtype}, QTensor.qscheme: {module.weight.qscheme}\")\n",
    "\n",
    "# 11. 양자화된 모델 평가 (Eager Mode)\n",
    "print(\"\\n--- Quantized Static (Eager Mode) 모델 평가 ---\")\n",
    "quantized_accuracy_eager = evaluate_model(quantized_model_static_eager, test_loader, target_device=torch.device(\"cpu\"))\n",
    "\n",
    "# 양자화된 모델 저장 (전체 모델 객체 저장)\n",
    "torch.save(quantized_model_static_eager, \"resnet18_mnist_quantized_static_eager.pth\")\n",
    "quantized_size_eager = os.path.getsize(\"resnet18_mnist_quantized_static_eager.pth\") / (1024 * 1024)\n",
    "print(f\"Quantized Static (Eager Mode) 모델 크기: {quantized_size_eager:.2f} MB\")\n",
    "\n",
    "print(\"\\n--- 최종 결과 비교 ---\")\n",
    "print(f\"FP32 모델 정확도: {fp32_accuracy:.2f}% (크기: {fp32_size:.2f} MB)\")\n",
    "print(f\"Static Quantized (Eager Mode) 모델 정확도: {quantized_accuracy_eager:.2f}% (크기: {quantized_size_eager:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc39f0f-9dbe-4f26-a0fd-14ec4725a3e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'quantize_static' from 'torch.ao.quantization.quantize' (C:\\Users\\JH\\anaconda\\envs\\torch_quant_env\\lib\\site-packages\\torch\\ao\\quantization\\quantize.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QuantStub, DeQuantStub, fuse_modules\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_default_qconfig\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quantize_static \u001b[38;5;66;03m# <--- 이 부분 수정\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'quantize_static' from 'torch.ao.quantization.quantize' (C:\\Users\\JH\\anaconda\\envs\\torch_quant_env\\lib\\site-packages\\torch\\ao\\quantization\\quantize.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18 # 기본 resnet18 로드\n",
    "from torch.ao.quantization import QuantStub, DeQuantStub, fuse_modules\n",
    "from torch.ao.quantization import get_default_qconfig\n",
    "from torch.ao.quantization.quantize import quantize_static # <--- 이 부분 수정\n",
    "import os\n",
    "import time\n",
    "import copy # deepcopy를 위해 임포트\n",
    "\n",
    "# 1. 하이퍼파라미터 및 설정\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 5\n",
    "CALIBRATION_BATCHES = 100\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 3. 데이터 로더 준비 (MNIST)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "calibration_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "# 4. 모델 학습 함수\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    print(f\"\\n모델 학습 시작 ({num_epochs} 에폭)...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}\")\n",
    "                running_loss = 0.0\n",
    "    print(\"모델 학습 완료.\")\n",
    "\n",
    "# 5. 모델 평가 함수\n",
    "def evaluate_model(model, test_loader, target_device=None):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    if target_device is None:\n",
    "        model_device = next(model.parameters()).device\n",
    "    else:\n",
    "        model_device = target_device\n",
    "\n",
    "    model.to(model_device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(model_device), labels.to(model_device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "# --- 메인 실행 로직 ---\n",
    "\n",
    "# 6. 모델 생성 및 초기 학습 (torchvision의 resnet18 사용)\n",
    "model_fp32 = resnet18(weights=None)\n",
    "\n",
    "model_fp32.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model_fp32.fc = nn.Linear(model_fp32.fc.in_features, 10)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_fp32.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "model_fp32 = model_fp32.to(DEVICE)\n",
    "train_model(model_fp32, train_loader, criterion, optimizer, NUM_EPOCHS)\n",
    "\n",
    "print(\"\\n--- FP32 모델 평가 ---\")\n",
    "fp32_accuracy = evaluate_model(model_fp32, test_loader, target_device=DEVICE)\n",
    "torch.save(model_fp32.state_dict(), \"resnet18_mnist_fp32.pth\")\n",
    "fp32_size = os.path.getsize(\"resnet18_mnist_fp32.pth\") / (1024 * 1024)\n",
    "print(f\"FP32 모델 크기: {fp32_size:.2f} MB\")\n",
    "\n",
    "# --- Static Quantization (Eager Mode 기반) ---\n",
    "\n",
    "# 7. Eager Mode Static Quantization 준비\n",
    "model_fp32.to(\"cpu\") # 모델을 CPU로 옮깁니다.\n",
    "model_fp32.eval()    # 평가 모드 설정\n",
    "\n",
    "# 7-1. Eager Mode 퓨징\n",
    "# torchvision resnet의 퓨징 로직을 따릅니다.\n",
    "# Conv - BatchNorm - ReLU 패턴을 퓨징하여 QuantizedConvReLU와 같이 만듭니다.\n",
    "# model_fp32 자체가 resnet18 인스턴스이므로, resnet에 내장된 fuse_model 메서드를 사용합니다.\n",
    "# 이 메서드는 인플레이스로 모듈을 퓨징합니다.\n",
    "fused_model_eager = copy.deepcopy(model_fp32)\n",
    "fused_model_eager.eval() # 퓨징 전 eval 모드 설정\n",
    "\n",
    "# resnet18 모델의 특정 패턴을 퓨징합니다.\n",
    "# resnet18의 fuse_model() 메서드는 내부적으로 Conv+BN, Conv+BN+ReLU 패턴을 찾아서 퓨징합니다.\n",
    "fused_model_eager.fuse_model()\n",
    "print(\"Eager Mode 모델 퓨징 완료.\")\n",
    "\n",
    "# QuantStub과 DeQuantStub 삽입 (모델의 입력과 출력을 양자화/역양자화)\n",
    "# Eager Mode에서는 이렇게 직접 삽입해야 합니다.\n",
    "model_with_quant_stubs = nn.Sequential(\n",
    "    QuantStub(),\n",
    "    fused_model_eager, # 퓨징된 모델을 Sequential 안에 넣습니다.\n",
    "    DeQuantStub()\n",
    ")\n",
    "\n",
    "# 7-2. QConfig 설정 (Eager Mode에서는 get_default_qconfig 사용)\n",
    "# QConfig는 모듈에 직접 할당됩니다.\n",
    "model_with_quant_stubs.qconfig = get_default_qconfig(\"fbgemm\")\n",
    "# print(f\"Eager Mode QConfig: {model_with_quant_stubs.qconfig}\") # QConfig 확인\n",
    "\n",
    "# 7-3. 모델 준비 (Eager Mode)\n",
    "# prepare 함수는 옵저버를 삽입합니다.\n",
    "# calibrate() 함수를 호출할 때 inplace=False로 새로운 모델을 반환하도록 합니다.\n",
    "# (prepare는 이제 prepare_fx와는 다르게 직접적인 함수 호출이 아닌, 내부적으로 처리될 수 있습니다.)\n",
    "# quantize_static은 prepare와 convert를 한 번에 처리합니다.\n",
    "# 따라서 prepare 단계는 quantize_static 함수가 내부적으로 처리합니다.\n",
    "# 여기서 prepared_model_eager는 단순히 quantize_static을 위한 중간 변수명입니다.\n",
    "# Eager mode에서는 이 부분에 `prepare` 함수를 직접 호출하는 방식도 사용 가능합니다.\n",
    "# 현재 방식은 quantize_static이 내부적으로 prepare를 처리합니다.\n",
    "\n",
    "# quantize_static의 첫 번째 인자로 qconfig와 모델을 전달하여 바로 양자화 진행\n",
    "# calibrate=True로 설정하여 캘리브레이션도 함께 수행\n",
    "print(\"\\n--- Static Quantization Calibration 시작 (Eager Mode) ---\")\n",
    "# calibrate_model = quantize_static(model_with_quant_stubs, qconfig=get_default_qconfig(\"fbgemm\"), inplace=False)\n",
    "# 위의 코드는 prepare와 convert를 한 번에 처리하므로, calibration을 따로 빼내기 어렵습니다.\n",
    "\n",
    "# Eager Mode의 올바른 Prepare -> Calibrate -> Convert 흐름\n",
    "# 1. 모델에 QConfig 할당 (위에서 이미 했음)\n",
    "# 2. prepare_qat (양자화 학습용) 또는 prepare (일반적인 양자화용)\n",
    "#    여기서는 정적 양자화이므로 prepare를 사용합니다.\n",
    "torch.ao.quantization.prepare(model_with_quant_stubs, inplace=True) # model_with_quant_stubs를 inplace로 변경\n",
    "\n",
    "# Calibration (보정)\n",
    "with torch.inference_mode():\n",
    "    for batch_idx, (inputs, labels) in enumerate(calibration_loader):\n",
    "        if batch_idx >= CALIBRATION_BATCHES:\n",
    "            break\n",
    "        inputs = inputs.to(\"cpu\")\n",
    "        model_with_quant_stubs(inputs) # prepare된 모델에 데이터 통과\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"  Calibration batch: {batch_idx}/{CALIBRATION_BATCHES}\")\n",
    "print(\"Calibration 완료.\")\n",
    "\n",
    "# 9. 양자화 적용 및 변환 (Eager Mode)\n",
    "# calibrate가 완료된 모델을 quantize_static으로 변환\n",
    "quantized_model_static_eager = quantize_static(model_with_quant_stubs, inplace=False)\n",
    "quantized_model_static_eager.eval()\n",
    "print(\"Eager Mode convert 완료.\")\n",
    "\n",
    "\n",
    "# 10. 양자화된 모델 가중치 타입 확인 (Eager Mode)\n",
    "print(\"\\n--- Eager Mode Quantized Model Weights Dtype 확인 ---\")\n",
    "for name, module in quantized_model_static_eager.named_modules():\n",
    "    # 양자화된 Conv2d와 Linear 모듈의 가중치는 QTensor 타입입니다.\n",
    "    # QTensor의 dtype을 확인해야 합니다.\n",
    "    if hasattr(module, 'weight') and module.weight is not None:\n",
    "        if isinstance(module.weight, torch.Tensor):\n",
    "            print(f\"모듈: {name}, 가중치 Dtype: {module.weight.dtype}\")\n",
    "        elif isinstance(module.weight, torch.quantized.QTensor): # 양자화된 텐서\n",
    "            print(f\"모듈: {name}, 가중치 Dtype: {module.weight.dtype}, QTensor.qscheme: {module.weight.qscheme}\")\n",
    "\n",
    "# 11. 양자화된 모델 평가 (Eager Mode)\n",
    "print(\"\\n--- Quantized Static (Eager Mode) 모델 평가 ---\")\n",
    "quantized_accuracy_eager = evaluate_model(quantized_model_static_eager, test_loader, target_device=torch.device(\"cpu\"))\n",
    "\n",
    "# 양자화된 모델 저장 (전체 모델 객체 저장)\n",
    "torch.save(quantized_model_static_eager, \"resnet18_mnist_quantized_static_eager.pth\")\n",
    "quantized_size_eager = os.path.getsize(\"resnet18_mnist_quantized_static_eager.pth\") / (1024 * 1024)\n",
    "print(f\"Quantized Static (Eager Mode) 모델 크기: {quantized_size_eager:.2f} MB\")\n",
    "\n",
    "print(\"\\n--- 최종 결과 비교 ---\")\n",
    "print(f\"FP32 모델 정확도: {fp32_accuracy:.2f}% (크기: {fp32_size:.2f} MB)\")\n",
    "print(f\"Static Quantized (Eager Mode) 모델 정확도: {quantized_accuracy_eager:.2f}% (크기: {quantized_size_eager:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96dd1bbb-e7cf-49c8-9d3a-e5bb139159da",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch.ao.quantization.quantize_lib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QuantStub, DeQuantStub, fuse_modules\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_default_qconfig\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantize_lib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quantize_static \u001b[38;5;66;03m# <--- THIS LINE IS THE LATEST FIX\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch.ao.quantization.quantize_lib'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18 # 기본 resnet18 로드\n",
    "from torch.ao.quantization import QuantStub, DeQuantStub, fuse_modules\n",
    "from torch.ao.quantization import get_default_qconfig\n",
    "from torch.ao.quantization.quantize_lib import quantize_static # <--- THIS LINE IS THE LATEST FIX\n",
    "import os\n",
    "import time\n",
    "import copy # deepcopy를 위해 임포트\n",
    "\n",
    "# 1. 하이퍼파라미터 및 설정\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 5\n",
    "CALIBRATION_BATCHES = 100\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 3. 데이터 로더 준비 (MNIST)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "calibration_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "# 4. 모델 학습 함수\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    print(f\"\\n모델 학습 시작 ({num_epochs} 에폭)...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}\")\n",
    "                running_loss = 0.0\n",
    "    print(\"모델 학습 완료.\")\n",
    "\n",
    "# 5. 모델 평가 함수\n",
    "def evaluate_model(model, test_loader, target_device=None):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    if target_device is None:\n",
    "        model_device = next(model.parameters()).device\n",
    "    else:\n",
    "        model_device = target_device\n",
    "\n",
    "    model.to(model_device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(model_device), labels.to(model_device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "# --- 메인 실행 로직 ---\n",
    "\n",
    "# 6. 모델 생성 및 초기 학습 (torchvision의 resnet18 사용)\n",
    "model_fp32 = resnet18(weights=None)\n",
    "\n",
    "model_fp32.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model_fp32.fc = nn.Linear(model_fp32.fc.in_features, 10)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_fp32.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "model_fp32 = model_fp32.to(DEVICE)\n",
    "train_model(model_fp32, train_loader, criterion, optimizer, NUM_EPOCHS)\n",
    "\n",
    "print(\"\\n--- FP32 모델 평가 ---\")\n",
    "fp32_accuracy = evaluate_model(model_fp32, test_loader, target_device=DEVICE)\n",
    "torch.save(model_fp32.state_dict(), \"resnet18_mnist_fp32.pth\")\n",
    "fp32_size = os.path.getsize(\"resnet18_mnist_fp32.pth\") / (1024 * 1024)\n",
    "print(f\"FP32 모델 크기: {fp32_size:.2f} MB\")\n",
    "\n",
    "# --- Static Quantization (Eager Mode 기반) ---\n",
    "\n",
    "# 7. Eager Mode Static Quantization 준비\n",
    "model_fp32.to(\"cpu\") # 모델을 CPU로 옮깁니다.\n",
    "model_fp32.eval()    # 평가 모드 설정\n",
    "\n",
    "# 7-1. Eager Mode 퓨징\n",
    "fused_model_eager = copy.deepcopy(model_fp32)\n",
    "fused_model_eager.eval()\n",
    "\n",
    "# resnet18 모델의 특정 패턴을 퓨징합니다.\n",
    "fused_model_eager.fuse_model()\n",
    "print(\"Eager Mode 모델 퓨징 완료.\")\n",
    "\n",
    "# QuantStub과 DeQuantStub 삽입 (모델의 입력과 출력을 양자화/역양자화)\n",
    "model_with_quant_stubs = nn.Sequential(\n",
    "    QuantStub(),\n",
    "    fused_model_eager, # 퓨징된 모델을 Sequential 안에 넣습니다.\n",
    "    DeQuantStub()\n",
    ")\n",
    "\n",
    "# 7-2. QConfig 설정 (Eager Mode에서는 get_default_qconfig 사용)\n",
    "model_with_quant_stubs.qconfig = get_default_qconfig(\"fbgemm\")\n",
    "\n",
    "# Eager Mode의 올바른 Prepare -> Calibrate -> Convert 흐름\n",
    "# 1. prepare 함수 호출 (옵저버 삽입)\n",
    "torch.ao.quantization.prepare(model_with_quant_stubs, inplace=True) # model_with_quant_stubs를 inplace로 변경\n",
    "print(\"Eager Mode prepare 완료.\")\n",
    "\n",
    "# Calibration (보정)\n",
    "print(\"\\n--- Static Quantization Calibration 시작 (Eager Mode) ---\")\n",
    "with torch.inference_mode():\n",
    "    for batch_idx, (inputs, labels) in enumerate(calibration_loader):\n",
    "        if batch_idx >= CALIBRATION_BATCHES:\n",
    "            break\n",
    "        inputs = inputs.to(\"cpu\")\n",
    "        model_with_quant_stubs(inputs) # prepare된 모델에 데이터 통과\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"  Calibration batch: {batch_idx}/{CALIBRATION_BATCHES}\")\n",
    "print(\"Calibration 완료.\")\n",
    "\n",
    "# 9. 양자화 적용 및 변환 (Eager Mode)\n",
    "quantized_model_static_eager = quantize_static(model_with_quant_stubs, inplace=False)\n",
    "quantized_model_static_eager.eval()\n",
    "print(\"Eager Mode convert 완료.\")\n",
    "\n",
    "\n",
    "# 10. 양자화된 모델 가중치 타입 확인 (Eager Mode)\n",
    "print(\"\\n--- Eager Mode Quantized Model Weights Dtype 확인 ---\")\n",
    "for name, module in quantized_model_static_eager.named_modules():\n",
    "    if hasattr(module, 'weight') and module.weight is not None:\n",
    "        if isinstance(module.weight, torch.Tensor):\n",
    "            print(f\"모듈: {name}, 가중치 Dtype: {module.weight.dtype}\")\n",
    "        elif isinstance(module.weight, torch.quantized.QTensor): # 양자화된 텐서\n",
    "            print(f\"모듈: {name}, 가중치 Dtype: {module.weight.dtype}, QTensor.qscheme: {module.weight.qscheme}\")\n",
    "\n",
    "# 11. 양자화된 모델 평가 (Eager Mode)\n",
    "print(\"\\n--- Quantized Static (Eager Mode) 모델 평가 ---\")\n",
    "quantized_accuracy_eager = evaluate_model(quantized_model_static_eager, test_loader, target_device=torch.device(\"cpu\"))\n",
    "\n",
    "# 양자화된 모델 저장 (전체 모델 객체 저장)\n",
    "torch.save(quantized_model_static_eager, \"resnet18_mnist_quantized_static_eager.pth\")\n",
    "quantized_size_eager = os.path.getsize(\"resnet18_mnist_quantized_static_eager.pth\") / (1024 * 1024)\n",
    "print(f\"Quantized Static (Eager Mode) 모델 크기: {quantized_size_eager:.2f} MB\")\n",
    "\n",
    "print(\"\\n--- 최종 결과 비교 ---\")\n",
    "print(f\"FP32 모델 정확도: {fp32_accuracy:.2f}% (크기: {fp32_size:.2f} MB)\")\n",
    "print(f\"Static Quantized (Eager Mode) 모델 정확도: {quantized_accuracy_eager:.2f}% (크기: {quantized_size_eager:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35564cbe-3c29-486d-9d35-dad0f5268709",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'quantize_static' from 'torch.quantization' (C:\\Users\\JH\\anaconda\\envs\\torch_quant_env\\lib\\site-packages\\torch\\quantization\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m resnet18 \u001b[38;5;66;03m# 기본 resnet18 로드\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Eager Mode Quantization을 위한 정확한 임포트\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# torch.ao.quantization 대신 torch.quantization 사용\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QuantStub, DeQuantStub, fuse_modules, get_default_qconfig, prepare, quantize_static\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'quantize_static' from 'torch.quantization' (C:\\Users\\JH\\anaconda\\envs\\torch_quant_env\\lib\\site-packages\\torch\\quantization\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18 # 기본 resnet18 로드\n",
    "\n",
    "# Eager Mode Quantization을 위한 정확한 임포트\n",
    "# torch.ao.quantization 대신 torch.quantization 사용\n",
    "from torch.quantization import QuantStub, DeQuantStub, fuse_modules, get_default_qconfig, prepare, quantize_static\n",
    "import os\n",
    "import time\n",
    "import copy # deepcopy를 위해 임포트\n",
    "\n",
    "# 1. 하이퍼파라미터 및 설정\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 5\n",
    "CALIBRATION_BATCHES = 100\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 3. 데이터 로더 준비 (MNIST)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "calibration_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "# 4. 모델 학습 함수\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    print(f\"\\n모델 학습 시작 ({num_epochs} 에폭)...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}\")\n",
    "                running_loss = 0.0\n",
    "    print(\"모델 학습 완료.\")\n",
    "\n",
    "# 5. 모델 평가 함수\n",
    "def evaluate_model(model, test_loader, target_device=None):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    if target_device is None:\n",
    "        model_device = next(model.parameters()).device\n",
    "    else:\n",
    "        model_device = target_device\n",
    "\n",
    "    model.to(model_device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(model_device), labels.to(model_device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "# --- 메인 실행 로직 ---\n",
    "\n",
    "# 6. 모델 생성 및 초기 학습 (torchvision의 resnet18 사용)\n",
    "model_fp32 = resnet18(weights=None)\n",
    "\n",
    "model_fp32.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model_fp32.fc = nn.Linear(model_fp32.fc.in_features, 10)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_fp32.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "model_fp32 = model_fp32.to(DEVICE)\n",
    "train_model(model_fp32, train_loader, criterion, optimizer, NUM_EPOCHS)\n",
    "\n",
    "print(\"\\n--- FP32 모델 평가 ---\")\n",
    "fp32_accuracy = evaluate_model(model_fp32, test_loader, target_device=DEVICE)\n",
    "torch.save(model_fp32.state_dict(), \"resnet18_mnist_fp32.pth\")\n",
    "fp32_size = os.path.getsize(\"resnet18_mnist_fp32.pth\") / (1024 * 1024)\n",
    "print(f\"FP32 모델 크기: {fp32_size:.2f} MB\")\n",
    "\n",
    "# --- Static Quantization (Eager Mode 기반) ---\n",
    "\n",
    "# 7. Eager Mode Static Quantization 준비\n",
    "model_fp32.to(\"cpu\") # 모델을 CPU로 옮깁니다.\n",
    "model_fp32.eval()    # 평가 모드 설정\n",
    "\n",
    "# 7-1. Eager Mode 퓨징\n",
    "fused_model_eager = copy.deepcopy(model_fp32)\n",
    "fused_model_eager.eval()\n",
    "\n",
    "# resnet18 모델의 특정 패턴을 퓨징합니다.\n",
    "# torchvision.models.resnet에는 fuse_model() 메서드가 내장되어 있어 편리합니다.\n",
    "fused_model_eager.fuse_model()\n",
    "print(\"Eager Mode 모델 퓨징 완료.\")\n",
    "\n",
    "# QuantStub과 DeQuantStub 삽입 (모델의 입력과 출력을 양자화/역양자화)\n",
    "model_with_quant_stubs = nn.Sequential(\n",
    "    QuantStub(), # 입력 양자화를 위한 Stub\n",
    "    fused_model_eager, # 퓨징된 모델\n",
    "    DeQuantStub() # 출력 역양자화를 위한 Stub\n",
    ")\n",
    "\n",
    "# 7-2. QConfig 설정 (Eager Mode에서는 get_default_qconfig 사용)\n",
    "model_with_quant_stubs.qconfig = get_default_qconfig(\"fbgemm\")\n",
    "\n",
    "# 7-3. 모델 준비 (Eager Mode)\n",
    "# prepare 함수 호출 (옵저버 삽입)\n",
    "prepare(model_with_quant_stubs, inplace=True) # model_with_quant_stubs를 inplace로 변경\n",
    "print(\"Eager Mode prepare 완료.\")\n",
    "\n",
    "# Calibration (보정)\n",
    "print(\"\\n--- Static Quantization Calibration 시작 (Eager Mode) ---\")\n",
    "with torch.inference_mode():\n",
    "    for batch_idx, (inputs, labels) in enumerate(calibration_loader):\n",
    "        if batch_idx >= CALIBRATION_BATCHES:\n",
    "            break\n",
    "        inputs = inputs.to(\"cpu\")\n",
    "        model_with_quant_stubs(inputs) # prepare된 모델에 데이터 통과\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"  Calibration batch: {batch_idx}/{CALIBRATION_BATCHES}\")\n",
    "print(\"Calibration 완료.\")\n",
    "\n",
    "# 9. 양자화 적용 및 변환 (Eager Mode)\n",
    "quantized_model_static_eager = quantize_static(model_with_quant_stubs, inplace=False)\n",
    "quantized_model_static_eager.eval()\n",
    "print(\"Eager Mode convert 완료.\")\n",
    "\n",
    "\n",
    "# 10. 양자화된 모델 가중치 타입 확인 (Eager Mode)\n",
    "print(\"\\n--- Eager Mode Quantized Model Weights Dtype 확인 ---\")\n",
    "for name, module in quantized_model_static_eager.named_modules():\n",
    "    if hasattr(module, 'weight') and module.weight is not None:\n",
    "        # 양자화된 텐서(QTensor)인지 확인\n",
    "        if isinstance(module.weight, torch.Tensor):\n",
    "            print(f\"모듈: {name}, 가중치 Dtype: {module.weight.dtype} (일반 텐서)\")\n",
    "        elif isinstance(module.weight, torch.quantized.QTensor):\n",
    "            print(f\"모듈: {name}, 가중치 Dtype: {module.weight.dtype}, QTensor.qscheme: {module.weight.qscheme} (양자화된 텐서)\")\n",
    "\n",
    "# 11. 양자화된 모델 평가 (Eager Mode)\n",
    "print(\"\\n--- Quantized Static (Eager Mode) 모델 평가 ---\")\n",
    "quantized_accuracy_eager = evaluate_model(quantized_model_static_eager, test_loader, target_device=torch.device(\"cpu\"))\n",
    "\n",
    "# 양자화된 모델 저장 (전체 모델 객체 저장)\n",
    "torch.save(quantized_model_static_eager, \"resnet18_mnist_quantized_static_eager.pth\")\n",
    "quantized_size_eager = os.path.getsize(\"resnet18_mnist_quantized_static_eager.pth\") / (1024 * 1024)\n",
    "print(f\"Quantized Static (Eager Mode) 모델 크기: {quantized_size_eager:.2f} MB\")\n",
    "\n",
    "print(\"\\n--- 최종 결과 비교 ---\")\n",
    "print(f\"FP32 모델 정확도: {fp32_accuracy:.2f}% (크기: {fp32_size:.2f} MB)\")\n",
    "print(f\"Static Quantized (Eager Mode) 모델 정확도: {quantized_accuracy_eager:.2f}% (크기: {quantized_size_eager:.2f} MB)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU Env)",
   "language": "python",
   "name": "mygpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
