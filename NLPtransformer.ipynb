{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08dad478-9907-4112-b315-d67c1c87a001",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 2일차 수업: 트랜스포머 (Transformer) 모델 심층 분석\n",
    "\n",
    "오늘 수업에서는 현대 자연어 처리의 핵심 모델인 **트랜스포머(Transformer)**에 대해 자세히 알아보겠습니다. 순환 신경망의 한계를 극복하고 뛰어난 성능을 보이는 트랜스포머의 구조와 작동 원리를 집중적으로 살펴보겠습니다.\n",
    "\n",
    "### 1. 트랜스포머 모델의 등장 배경 및 필요성\n",
    "\n",
    "* **순환 신경망의 한계 복습:** 어제 배웠던 RNN, LSTM, GRU는 순차적인 데이터 처리에 강점을 가지지만, 긴 시퀀스에서 **기울기 소실/폭주** 문제와 **장기 의존성 문제**를 완전히 해결하기 어려웠습니다. 또한, 순차적인 처리 방식 때문에 **병렬 처리**가 불가능하여 긴 문장의 학습 속도가 느리다는 단점도 있었습니다.\n",
    "* **트랜스포머의 등장:** 트랜스포머는 이러한 순환 신경망의 한계를 극복하고, 문장 내의 모든 단어 간의 관계를 직접적으로 파악하는 **어텐션(Attention)** 메커니즘을 도입하여 장거리 의존성 문제를 효과적으로 해결하고 병렬 처리를 가능하게 했습니다.\n",
    "\n",
    "### 2. 어텐션 메커니즘 (Attention Mechanism)\n",
    "\n",
    "* **핵심 아이디어:** 입력 시퀀스 내의 각 단어가 출력 시퀀스의 특정 단어를 생성할 때 얼마나 집중해야 하는지를 학습하는 메커니즘입니다. 즉, **문맥(context)**을 파악하여 중요한 정보에 더 많은 가중치를 부여합니다.\n",
    "* **작동 방식 (Query, Key, Value):** 어텐션은 세 가지 요소인 **Query (질의)**, **Key (키)**, **Value (값)** 벡터를 사용하여 계산됩니다.\n",
    "    * **Query (Q):** 현재 (디코더의) 단어에 대한 정보\n",
    "    * **Key (K):** 입력 (인코더의) 각 단어에 대한 정보\n",
    "    * **Value (V):** 입력 (인코더의) 각 단어의 실제 내용 정보\n",
    "* **어텐션 스코어 계산:** Query 벡터와 각 Key 벡터 간의 유사도를 계산하여 각 입력 단어에 대한 집중도를 나타내는 **어텐션 스코어**를 얻습니다. 유사도 함수로는 주로 **Dot Product (내적)**, **Scaled Dot Product**, **Cosine Similarity** 등이 사용됩니다.\n",
    "* **소프트맥스 함수 적용:** 얻어진 어텐션 스코어에 **소프트맥스(Softmax)** 함수를 적용하여 확률 분포 형태로 정규화합니다. 이를 통해 각 입력 단어에 대한 중요도를 0과 1 사이의 값으로 나타낼 수 있습니다.\n",
    "* **가중합 (Weighted Sum):** 정규화된 어텐션 스코어를 각 Value 벡터에 곱하여 **가중합**을 계산합니다. 이 가중합 벡터가 현재 (디코더의) 단어를 생성하는 데 중요한 정보를 담고 있는 문맥 벡터가 됩니다.\n",
    "\n",
    "### 3. 셀프 어텐션 (Self-Attention)\n",
    "\n",
    "* **핵심 아이디어:** 입력 시퀀스 내의 각 단어가 **자신을 포함한** 다른 모든 단어들과의 관계를 파악하는 어텐션 메커니즘입니다. 즉, 하나의 입력 시퀀스 내에서 각 단어의 문맥적 의미를 스스로 학습합니다.\n",
    "* **Query, Key, Value 생성:** 입력 시퀀스의 각 단어에 대해 서로 다른 가중치 행렬을 곱하여 Query, Key, Value 벡터를 각각 생성합니다.\n",
    "* **셀프 어텐션 과정:** 생성된 Query, Key, Value 벡터를 사용하여 앞서 설명한 어텐션 스코어 계산, 소프트맥스 함수 적용, 가중합 과정을 거쳐 각 단어의 문맥 정보가 반영된 새로운 표현을 얻습니다.\n",
    "\n",
    "### 4. 멀티 헤드 어텐션 (Multi-Head Attention)\n",
    "\n",
    "* **핵심 아이디어:** 여러 개의 독립적인 **어텐션 헤드(Attention Head)**를 병렬로 사용하여 다양한 관점에서 단어 간의 관계를 학습하는 메커니즘입니다.\n",
    "* **작동 방식:** 입력된 Query, Key, Value 벡터를 여러 개의 작은 Query, Key, Value 벡터로 선형 변환한 후, 각 헤드에서 독립적으로 셀프 어텐션을 수행합니다. 각 헤드의 출력은 다시 연결(Concatenate)되고, 최종적으로 또 다른 선형 변환을 거쳐 최종 출력 벡터를 얻습니다.\n",
    "* **효과:** 다양한 어텐션 패턴을 학습하여 모델이 더욱 풍부한 문맥 정보를 이해할 수 있도록 돕습니다. 예를 들어, 하나의 헤드는 문법적인 관계를 파악하고, 다른 헤드는 의미적인 관계를 파악할 수 있습니다.\n",
    "\n",
    "### 5. 포지셔널 인코딩 (Positional Encoding)\n",
    "\n",
    "* **필요성:** 트랜스포머는 순환 구조가 없어 단어의 순서 정보를 명시적으로 모델에 알려주어야 합니다.\n",
    "* **작동 방식:** 입력 시퀀스의 각 단어의 위치에 따라 고유한 벡터를 생성하여 단어 임베딩 벡터에 더해줍니다. 주로 사인(sine) 함수와 코사인(cosine) 함수를 사용하여 위치에 따른 고유한 패턴을 만듭니다.\n",
    "* **효과:** 모델이 단어의 순서 정보를 인식하고 활용하여 문장의 의미를 더 정확하게 파악할 수 있도록 합니다.\n",
    "\n",
    "### 6. 트랜스포머의 구조\n",
    "\n",
    "트랜스포머는 주로 **인코더(Encoder)**와 **디코더(Decoder)**로 구성됩니다.\n",
    "\n",
    "* **인코더:** 입력 시퀀스를 처리하여 문맥 정보를 담고 있는 중간 표현(contextualized representation)을 생성합니다. 여러 개의 동일한 **인코더 레이어**가 쌓여 있으며, 각 인코더 레이어는 **멀티 헤드 셀프 어텐션**과 **Position-wise Feed-Forward Network** (각 위치의 단어에 대해 독립적으로 적용되는 완전 연결 신경망)로 구성됩니다. 각 서브 레이어 후에는 **잔차 연결(Residual Connection)**과 **레이어 정규화(Layer Normalization)**가 적용되어 학습을 안정화시킵니다.\n",
    "* **디코더:** 인코더의 출력과 이전 디코더의 출력을 이용하여 목표 시퀀스를 생성합니다. 여러 개의 동일한 **디코더 레이어**가 쌓여 있으며, 각 디코더 레이어는 **마스크드 멀티 헤드 셀프 어텐션**, **멀티 헤드 어텐션 (인코더 출력에 대해 수행)**, **Position-wise Feed-Forward Network**로 구성됩니다. **마스크드 셀프 어텐션**은 디코더가 현재 시점 이후의 정보를 미리 보지 못하도록 가립니다 (autoregressive generation). 인코더-디코더 어텐션은 디코더가 인코더의 출력 (입력 문맥 정보)에 집중하여 다음 단어를 생성하는 데 도움을 줍니다. 각 서브 레이어 후에는 잔차 연결과 레이어 정규화가 적용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79801c7-1fad-43f4-af72-31f02e8d4c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4d447c9-aff8-4814-8ef5-7f56def6d4dd",
   "metadata": {},
   "source": [
    "\n",
    "\r\n",
    "## 3일차 수업: 트랜스포머 (Transformer) 기반 모델 (BERT, GPT) 및 자연어 생성 활용\r\n",
    "\r\n",
    "어제 트랜스포머 모델의 핵심 이론과 구조에 대해 자세히 알아보았습니다. 오늘은 트랜스포머 아키텍처를 기반으로 개발되어 자연어 처리 분야에서 혁혁한 성과를 거두고 있는 대표적인 모델인 **BERT (Bidirectional Encoder Representations from Transformers)**와 **GPT (Generative Pre-trained Transformer)**에 대해 배우고, 트랜스포머가 자연어 생성 task에 어떻게 활용되는지 살펴보겠습니다.\r\n",
    "\r\n",
    "### 1. BERT (Bidirectional Encoder Representations from Transformers)\r\n",
    "\r\n",
    "* **핵심 아이디어:** 트랜스포머의 **인코더(Encoder)** 구조를 활용하여 텍스트의 **양방향(Bidirectional)** 문맥 정보를 효과적으로 학습하는 데 초점을 맞춘 모델입니다.\r\n",
    "* **사전 학습 방식:** BERT는 두 가지 주요 사전 학습 task를 통해 풍부한 언어적 지식을 습득합니다.\r\n",
    "    * **Masked Language Modeling (MLM):** 입력 문장 내의 일부 단어를 `[MASK]` 토큰으로 가리고, 가려진 단어를 예측하는 task입니다. 이를 통해 모델은 주변 단어들의 양방향 문맥을 이해하는 능력을 키웁니다.\r\n",
    "    * **Next Sentence Prediction (NSP):** 두 개의 문장이 주어졌을 때, 두 번째 문장이 첫 번째 문장의 다음 문장인지 여부를 예측하는 task입니다. (최근 연구에서는 NSP의 효과에 대한 논란이 있으며, 일부 후속 모델에서는 제외되기도 합니다.)\r\n",
    "* **특징:**\r\n",
    "    * **양방향 문맥 이해:** MLM을 통해 문맥의 양쪽 방향을 모두 고려하여 단어의 의미를 파악하는 데 뛰어납니다.\r\n",
    "    * **다양한 downstream task에 적용 가능:** 사전 학습된 BERT 모델은 Fine-tuning이라는 과정을 통해 텍스트 분류, 개체명 인식, 질의응답 등 다양한 자연어 처리 task에 높은 성능을 보입니다.\r\n",
    "    * **`[CLS]` 토큰 활용:** 입력 시퀀스의 시작 부분에 추가되는 특별한 토큰 `[CLS]`의 최종 은닉층 표현은 전체 문장의 의미를 담고 있다고 여겨져, 문장 분류 task 등에 활용됩니다.\r\n",
    "    * **`[SEP]` 토큰 활용:** 문장 쌍을 입력할 때 문장들을 구분하는 데 사용됩니다.\r\n",
    "\r\n",
    "### 2. GPT (Generative Pre-trained Transformer)\r\n",
    "\r\n",
    "* **핵심 아이디어:** 트랜스포머의 **디코더(Decoder)** 구조를 활용하여 주어진 텍스트를 기반으로 **새로운 텍스트를 생성(Generation)**하는 데 특화된 모델입니다.\r\n",
    "* **사전 학습 방식:** GPT는 **다음 단어 예측(Next Token Prediction)**이라는 autoregressive (자기 회귀적) 방식으로 사전 학습됩니다. 모델은 주어진 이전 단어들의 시퀀스를 기반으로 다음에 올 단어의 확률 분포를 예측하는 것을 학습합니다.\r\n",
    "* **특징:**\r\n",
    "    * **텍스트 생성 능력:** 문맥을 이해하고 자연스럽고 일관성 있는 텍스트를 생성하는 데 뛰어납니다.\r\n",
    "    * **단방향 문맥 이해:** 디코더 기반 구조이므로, 특정 시점의 단어를 예측할 때 이전 단어들의 문맥만을 참고합니다 (Masked Self-Attention 활용).\r\n",
    "    * **다양한 생성 task에 적용 가능:** 텍스트 생성, 번역 (일부 모델), 질의응답 (생성 방식으로) 등 다양한 task에 활용될 수 있습니다.\r\n",
    "    * **모델 크기 확장:** GPT 계열 모델은 모델 크기를 지속적으로 확장하면서 더욱 강력한 생성 능력을 보여주고 있습니다 (GPT-2, GPT-3, GPT-4 등).\r\n",
    "\r\n",
    "### 3. 트랜스포머를 활용한 자연어 생성\r\n",
    "\r\n",
    "트랜스포머 아키텍처는 강력한 어텐션 메커니즘과 병렬 처리 능력 덕분에 자연어 생성 분야에서 뛰어난 성능을 보입니다. 주로 트랜스포머의 디코더 부분을 활용하거나, 인코더-디코더 전체 구조를 활용하여 다양한 자연어 생성 task를 수행합니다.\r\n",
    "\r\n",
    "* **텍스트 생성 (Text Generation):** GPT와 같은 디코더 기반 모델은 주어진 프롬프트(prompt)를 기반으로 소설, 시, 뉴스 기사 등 다양한 형식의 텍스트를 생성할 수 있습니다. 다음 단어 예측을 반복하면서 문맥에 맞는 단어를 순차적으로 생성합니다.\r\n",
    "* **기계 번역 (Machine Translation):** 트랜스포머의 인코더-디코더 구조는 기계 번역 task에서 높은 성능을 보입니다. 인코더가 원문의 문맥 정보를 추출하고, 디코더가 이를 기반으로 번역된 문장을 생성합니다. 어텐션 메커니즘은 번역 과정에서 원문의 어떤 단어에 집중해야 할지를 결정하는 데 중요한 역할을 합니다.\r\n",
    "* **텍스트 요약 (Text Summarization):** 트랜스포머 모델은 긴 문서를 이해하고 핵심 내용을 추출하여 짧은 요약문을 생성하는 데 활용될 수 있습니다. 인코더가 문서의 내용을 이해하고, 디코더가 요약문을 생성하는 방식으로 작동합니다 (Extractive 또는 Abstractive 요약).\r\n",
    "* **질의응답 (Question Answering):** 트랜스포머 모델은 주어진 질문에 대한 답변을 텍스트 내에서 추출하거나 생성하는 task를 수행할 수 있습니다. BERT는 주로 텍스트 내에서 답변의 범위를 찾는 데 활용되며, GPT와 같은 생성 모델은 답변을 직접 생성하는 데 사용될 수 있습니다.\r\n",
    "* **대화 시스템 (Dialogue Systems):** 트랜스포머 기반 모델은 사용자의 발화에 대해 적절한 응답을 생성하는 챗봇 개발에 활용됩니다. 문보겠습니다.\r\n",
    "\r\n",
    "궁금한 점이 있으시면 언제든지 질문해주세요! 수고 많으셨습니다. 😊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cdf6c9-d7fd-4ed9-802a-c4e5c6da4ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd6fd482-dd91-40ce-9676-cf9c0a980122",
   "metadata": {},
   "source": [
    "\n",
    "## 4일차 수업: 자연어 처리 및 생성 모델 평가 방법 (실습 포함)\n",
    "\n",
    "오늘 수업에서는 자연어 처리 및 생성 모델의 성능을 객관적으로 측정하는 다양한 평가 방법에 대해 자세히 알아보고, 파이썬 라이브러리를 이용하여 실제로 평가 지표를 계산해 보는 실습 시간을 갖겠습니다.\n",
    "\n",
    "### 1\\. 분류 (Classification) Task 평가\n",
    "\n",
    "  * **정확도 (Accuracy):** 전체 예측 중 정답을 맞춘 비율입니다.\n",
    "    $$\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}$$\n",
    "  * **정밀도 (Precision):** 모델이 긍정이라고 예측한 것 중에서 실제로 긍정인 비율입니다.\n",
    "    $$\\text{Precision} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Positives (FP)}}$$\n",
    "  * **재현율 (Recall):** 실제 긍정인 것 중에서 모델이 긍정이라고 예측한 비율입니다.\n",
    "    $$\\text{Recall} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Negatives (FN)}}$$\n",
    "  * **F1 점수 (F1 Score):** 정밀도와 재현율의 조화 평균입니다. 불균형한 데이터셋에서 성능을 평가할 때 유용합니다.\n",
    "    $$\\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
    "  * **AUC (Area Under the ROC Curve):** ROC(Receiver Operating Characteristic) 곡선 아래의 면적으로, 이진 분류 모델의 성능을 종합적으로 평가하는 지표입니다.\n",
    "\n",
    "### 2\\. 기계 번역 (Machine Translation) Task 평가\n",
    "\n",
    "  * **BLEU (Bilingual Evaluation Understudy):** 모델이 생성한 번역과 사람이 직접 번역한 여러 개의 참고 번역(reference translation)을 비교하여 유사도를 측정하는 지표입니다. n-gram의 정밀도를 기반으로 계산됩니다. 높을수록 좋은 성능을 의미합니다.\n",
    "  * **METEOR (Metric for Evaluation of Translation with Explicit Ordering):** BLEU의 단점을 보완하기 위해 제안된 지표로, 단어의 정확한 일치뿐만 아니라 어순, 형태소 분석 결과 등을 고려합니다.\n",
    "  * **TER (Translation Edit Rate):** 모델이 생성한 번역을 참고 번역과 똑같이 만들기 위해 필요한 편집 작업의 평균 횟수를 측정하는 지표입니다. 낮을수록 좋은 성능을 의미합니다.\n",
    "\n",
    "### 3\\. 텍스트 생성 (Text Generation) Task 평가\n",
    "\n",
    "  * **Perplexity:** 언어 모델이 주어진 텍스트를 얼마나 잘 예측하는지를 나타내는 지표입니다. 다음 단어를 예측할 때의 불확실성을 측정하며, 값이 낮을수록 좋은 모델입니다.\n",
    "  * **BLEU, METEOR, ROUGE (Recall-Oriented Understudy for Gisting Evaluation):** 생성된 텍스트와 참고 텍스트 간의 유사도를 측정하는 데 사용될 수 있습니다. 하지만 생성 모델의 창의성이나 다양성을 제대로 평가하지 못한다는 한계가 있습니다.\n",
    "  * **Human Evaluation (인간 평가):** 사람이 직접 생성된 텍스트를 읽고 자연스러움, 문법적 정확성, 의미의 적절성, 일관성 등을 주관적으로 평가하는 방법입니다. 가장 신뢰할 수 있는 평가 방법이지만, 비용과 시간이 많이 소요될 수 있습니다.\n",
    "\n",
    "### 4\\. 파이썬 실습: 평가 지표 계산\n",
    "\n",
    "이제 파이썬의 `scikit-learn`과 `nltk` 라이브러리를 사용하여 분류 및 텍스트 생성 task에 대한 평가 지표를 실제로 계산해 보겠습니다.\n",
    "\n",
    "**4.1 분류 Task 평가 실습:**\n",
    "\n",
    "**실습 설명:**\n",
    "\n",
    "  * 위 코드는 가상의 실제 레이블(`y_true`)과 모델 예측 값(`y_pred`), 그리고 AUC 계산을 위한 확률 값(`y_prob`)을 사용하여 다양한 분류 평가 지표를 계산하는 예시입니다.\n",
    "  * `scikit-learn` 라이브러리의 해당 함수들을 사용하여 정확도, 정밀도, 재현율, F1 점수, AUC를 쉽게 계산할 수 있습니다.\n",
    "  * `confusion_matrix` 함수는 혼동 행렬을 출력하여 모델의 예측 오류를 시각적으로 확인할 수 있도록 도와줍니다.\n",
    "\n",
    "**4.2 텍스트 생성 Task 평가 (BLEU) 실습:**\n",
    "\n",
    "**실습 설명:**\n",
    "\n",
    "  * 위 코드는 `nltk` 라이브러리의 `sentence_bleu` 함수를 사용하여 가상의 참고 번역(`reference`)과 모델이 생성한 번역 후보(`candidate1`, `candidate2`, `candidate3`) 간의 BLEU 점수를 계산하는 예시입니다.\n",
    "  * `weights` 파라미터를 조절하여 n-gram의 중요도를 설정할 수 있습니다.\n",
    "\n",
    "**실습 과제:**\n",
    "\n",
    "1.  위 코드를 직접 실행해보고 출력 결과를 확인하세요.\n",
    "2.  가상의 실제 레이블과 예측 값을 다양하게 변경해 보면서 분류 평가 지표가 어떻게 달라지는지 관찰해 보세요.\n",
    "3.  가상의 참고 번역과 생성된 번역을 바꿔보면서 BLEU 점수가 어떻게 변하는지 확인해 보세요. 특히 단어 순서나 포함된 단어의 종류에 따른 BLEU 점수 변화를 살펴보세요.\n",
    "\n",
    "오늘 수업은 여기까지입니다. 다양한 자연어 처리 및 생성 모델 평가 지표의 개념과 기본적인 계산 방법을 실습을 통해 이해하셨기를 바랍니다.\n",
    "\n",
    "궁금한 점이 있으시거나 실습 과정에서 어려움이 있다면 언제든지 질문해주세요\\! 수고 많으셨습니다. 😊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b0307b-c815-4074-b9c0-9bd91465cbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46ecdbc2-9d99-42d9-a131-009a8b392173",
   "metadata": {},
   "source": [
    "# 분류 Task 평가 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6e01e8f-fb7c-4aeb-b7f7-e88e19e17a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score,confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8d88849-99c5-41a2-ae9e-55660663b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([1, 0, 1, 0, 1, 1, 0, 0])\n",
    "y_pred = np.array([1, 1, 1, 0, 0, 1, 0, 1])\n",
    "y_prob = np.array([0.9, 0.7, 0.8, 0.3, 0.4, 0.6, 0.2, 0.8]) # AUC 계산을 위한 확률 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa7c35c9-7da0-42fb-aea6-d0f0388db94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6250\n",
      "Precision: 0.6000\n",
      "recall:0.7500\n",
      "F1:0.6667\n",
      "AUC : 0.6250\n",
      "CM :\n",
      "[[2 2]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "accuracy=accuracy_score(y_true,y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "precision=precision_score(y_true, y_pred)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "recall=recall_score(y_true,y_pred)\n",
    "print(f'recall:{recall:.4f}')\n",
    "\n",
    "f1=f1_score(y_true,y_pred)\n",
    "print(f\"F1:{f1:.4f}\")\n",
    "\n",
    "auc=roc_auc_score(y_true,y_pred)\n",
    "print(f\"AUC : {auc:.4f}\")\n",
    "\n",
    "cm=confusion_matrix(y_true,y_pred)\n",
    "print(\"CM :\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f4a3ac0a-e07c-4181-8fcb-3aa3c43bc2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\JH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\JH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\JH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\JH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\JH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\JH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\JH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\JH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\JH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\JH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bfaf0d27-e505-489a-8194-88b65847b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "reference = [['this', 'is', 'a', 'test', 'sentence']]\n",
    "# 가상의 모델 생성 번역\n",
    "candidate1 = ['this', 'is', 'a', 'test', 'sentence']\n",
    "candidate2 = ['this', 'is', 'good', 'sentence']\n",
    "candidate3 = ['a', 'test', 'sentence', 'this', 'is']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6381db63-e744-4894-bd47-0ed715568139",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu1=sentence_bleu(reference,candidate1)\n",
    "bleu2=sentence_bleu(reference,candidate2,weights=(0.5,0.5))\n",
    "bleu3=sentence_bleu(reference,candidate3,weights=(0.33,0.33,0.33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6f835c19-6c20-474c-8a84-bafb783a85df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU (unigram): 1.0000\n",
      "BLEU (bigram): 0.3894\n",
      "BLEU (trigram): 0.6329\n"
     ]
    }
   ],
   "source": [
    "print(f\"BLEU (unigram): {bleu1:.4f}\")\n",
    "print(f\"BLEU (bigram): {bleu2:.4f}\")\n",
    "print(f\"BLEU (trigram): {bleu3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7c8236-ed17-4ffa-9acf-5dd1c98abdbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94491866-3c53-4d8a-8320-ad035898f2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2173dc50-7b19-4cb9-8ed8-abd067715c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd8261e-fdb1-400d-8058-3f945444b836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CUDA 12.4)",
   "language": "python",
   "name": "cuda124"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
