{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dafed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as mp\n",
    "\n",
    "train_data=datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data=datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26d88cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map={\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",   \n",
    "}\n",
    "figure=mp.figure(figsize=(8,8))\n",
    "col,row=3,3\n",
    "for i in range(1,col*row+1):\n",
    "    sample=torch.randint(len(train_data),size=(1,)).item()\n",
    "    img,label=train_data[sample]\n",
    "    figure.add_subplot(row, col, i)\n",
    "    mp.title(labels_map[label])\n",
    "    mp.axis('off')\n",
    "    mp.imshow(img.squeeze(),cmap='gray')\n",
    "mp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55686aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as ps\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class cid(Dataset):\n",
    "    def __init__(self,annotations_file,img_dir,transform=None,target_transform=None):  #초기화\n",
    "        self.img_labels=ps.read_csv(annotation_file)\n",
    "        self.img_dir=img_dir\n",
    "        self.transform=transform\n",
    "        self.target_transform=target_transform\n",
    "    \n",
    "    def __len__(self):  #샘플수 반환\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self,idx):  #지정된 인덱스에 있는 D-set에서 샘플을 로드후 반환\n",
    "        img_path=os.path.join(self.img_dir,self.img_labels.iloc[idx,0])\n",
    "        image=read_image(img_path)\n",
    "        label=self.img_labels.iloc[idx,1]\n",
    "        if self.transform:\n",
    "            image=self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label=self.target_transform(label)\n",
    "            \n",
    "        return image,label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b5dbfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_load=DataLoader(train_data,batch_size=70, shuffle=True)\n",
    "test_load=DataLoader(test_data,batch_size=70, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "01cfd290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchtorch.Size([70, 1, 28, 28])\n",
      "labeltorch.Size([70])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:3\n"
     ]
    }
   ],
   "source": [
    "train_feature, train_label=next(iter(train_load))\n",
    "print(f'batch{train_feature.size()}')\n",
    "print(f'label{train_label.size()}')\n",
    "img=train_feature[0].squeeze()\n",
    "label=train_label[0]\n",
    "mp.imshow(img,cmap='gray')\n",
    "mp.show()\n",
    "print(f'label:{label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8725bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds=datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),   #이미지의 픽셀 강도 값을 조정합니다.\n",
    "    target_transform=Lambda(lambda y:torch.zeros(10,dtype=torch.float).scatter_(0,torch.tensor(y),value=1))\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cc3db932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "595b5cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda mode\n"
     ]
    }
   ],
   "source": [
    "device=(\n",
    "    'cuda'\n",
    "    if torch.cuda.is_available()\n",
    "    else 'map'\n",
    "    if torch.cuda.is_available()\n",
    "    else 'CPU'\n",
    ")\n",
    "print(f'{device} mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c7c1c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.linear_relu_stack=nn.Sequential(\n",
    "            nn.Linear(28*28,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10),\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.flatten(x)\n",
    "        logit=self.linear_relu_stack(x)\n",
    "        return logit\n",
    "model=NN().to(device)\n",
    "\n",
    "print(model)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1b6065dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:tensor([2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(1,28,28,device=device)\n",
    "logit=model(x)\n",
    "pred_p=nn.Softmax(dim=1)(logit)\n",
    "y_pred=pred_p.argmax(1)\n",
    "print(f'pred:{y_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "636f6681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n",
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "input_image=torch.rand(3,28,28)\n",
    "print(input_image.size())\n",
    "\n",
    "flatten=nn.Flatten()\n",
    "flat_image=flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f740f0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1=nn.Linear(in_features=28*28,out_features=20)\n",
    "hidden1=layer1(flat_image)\n",
    "print(hidden1.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a792b7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.1621, 0.0000, 0.0000, 0.0000, 0.2323, 0.0000, 0.0000, 0.0000,\n",
      "         0.0752, 0.3061, 0.0403, 0.7082, 0.2136, 0.3786, 0.0000, 0.3218, 0.0000,\n",
      "         0.0000, 0.1231],\n",
      "        [0.0000, 0.2784, 0.0000, 0.0000, 0.0000, 0.1173, 0.0000, 0.0571, 0.1219,\n",
      "         0.5451, 0.7355, 0.0000, 0.5337, 0.2811, 0.1844, 0.0000, 0.4823, 0.0970,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.7844, 0.0000, 0.0893, 0.0000, 0.1548, 0.0000, 0.0000, 0.3391,\n",
      "         0.1961, 0.6504, 0.0000, 0.5682, 0.3705, 0.0000, 0.0000, 0.2594, 0.0861,\n",
      "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0000, 0.1621, 0.0000, 0.0000, 0.0000, 0.2323, 0.0000, 0.0000, 0.0000,\n",
      "         0.0752, 0.3061, 0.0403, 0.7082, 0.2136, 0.3786, 0.0000, 0.3218, 0.0000,\n",
      "         0.0000, 0.1231],\n",
      "        [0.0000, 0.2784, 0.0000, 0.0000, 0.0000, 0.1173, 0.0000, 0.0571, 0.1219,\n",
      "         0.5451, 0.7355, 0.0000, 0.5337, 0.2811, 0.1844, 0.0000, 0.4823, 0.0970,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.7844, 0.0000, 0.0893, 0.0000, 0.1548, 0.0000, 0.0000, 0.3391,\n",
      "         0.1961, 0.6504, 0.0000, 0.5682, 0.3705, 0.0000, 0.0000, 0.2594, 0.0861,\n",
      "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'{hidden1}')\n",
    "hidden1=nn.ReLU()(hidden1)\n",
    "print(f'{hidden1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6dbd47f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_module=nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20,10)\n",
    ")\n",
    "input_image=torch.rand(3,28,28)\n",
    "logit=seq_module(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9b6f8366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "layer:linear_relu_stack.0.weight \\ size:torch.Size([512, 784])\\ value:tensor([[-0.0076, -0.0049, -0.0339,  ...,  0.0289, -0.0051, -0.0283],\n",
      "        [ 0.0227,  0.0143,  0.0335,  ...,  0.0290,  0.0165, -0.0255]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "layer:linear_relu_stack.0.bias \\ size:torch.Size([512])\\ value:tensor([-0.0070, -0.0220], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "layer:linear_relu_stack.2.weight \\ size:torch.Size([512, 512])\\ value:tensor([[-0.0052, -0.0139, -0.0086,  ...,  0.0192, -0.0060, -0.0293],\n",
      "        [-0.0232,  0.0157, -0.0248,  ...,  0.0321, -0.0260, -0.0362]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "layer:linear_relu_stack.2.bias \\ size:torch.Size([512])\\ value:tensor([ 0.0109, -0.0289], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "layer:linear_relu_stack.4.weight \\ size:torch.Size([10, 512])\\ value:tensor([[-0.0440,  0.0113,  0.0145,  ...,  0.0395,  0.0163, -0.0344],\n",
      "        [ 0.0002,  0.0314, -0.0222,  ..., -0.0011, -0.0143, -0.0197]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "layer:linear_relu_stack.4.bias \\ size:torch.Size([10])\\ value:tensor([-0.0364,  0.0073], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "softmax=nn.Softmax(dim=1)\n",
    "pred_p=softmax(logit)\n",
    "print(f'{model}\\n\\n')\n",
    "\n",
    "for name,param in model.named_parameters():\n",
    "    print(f'layer:{name} \\ size:{param.size()}\\ value:{param[:2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c6f1e443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x7f677a7f8f40>\n",
      "<BinaryCrossEntropyWithLogitsBackward0 object at 0x7f677a7f9570>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x=torch.ones(5)\n",
    "y=torch.zeros(3)\n",
    "w=torch.randn(5,3,requires_grad=True)\n",
    "b=torch.randn(3,requires_grad=True)\n",
    "z=torch.matmul(x,w)+b\n",
    "loss=torch.nn.functional.binary_cross_entropy_with_logits(z,y)\n",
    "\n",
    "print(f'{z.grad_fn}')\n",
    "print(f'{loss.grad_fn}')\n",
    "#Function. 이 객체는 순방향 으로 함수를 계산하는 방법 과 역방향 전파 단계에서 함수의 도함수를 계산하는 방법을 알고 있습니다. 역전파 함수에 대한 참조는 grad_fn텐서의 속성에 저장됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8873b064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2978, 0.2921, 0.2999],\n",
      "        [0.2978, 0.2921, 0.2999],\n",
      "        [0.2978, 0.2921, 0.2999],\n",
      "        [0.2978, 0.2921, 0.2999],\n",
      "        [0.2978, 0.2921, 0.2999]])\n",
      "tensor([0.2978, 0.2921, 0.2999])\n"
     ]
    }
   ],
   "source": [
    "#그라데이션 컴퓨팅\n",
    "\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "308053eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z=torch.matmul(x,w)+b\n",
    "\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z=torch.matmul(x,w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "99458b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "z=torch.matmul(x,w)+b\n",
    "z_det=z.detach()\n",
    "print(z_det.requires_grad)\n",
    "#DAG는 PyTorch에서 동적입니다. 주목해야 할 중요한 점은 그래프가 처음부터 다시 생성된다는 것입니다. 호출 할 때마다 .backward()autograd는 새 그래프를 채우기 시작합니다. 이것이 바로 모델에서 제어 흐름 문을 사용할 수 있게 해주는 것입니다. 필요한 경우 반복할 때마다 모양, 크기 및 작업을 변경할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a06e3f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first:tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.]])\n",
      "secend:tensor([[8., 4., 4., 4., 4.],\n",
      "        [4., 8., 4., 4., 4.],\n",
      "        [4., 4., 8., 4., 4.],\n",
      "        [4., 4., 4., 8., 4.]])\n",
      "자코비안:tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.]])\n"
     ]
    }
   ],
   "source": [
    "#자코비안 곱\n",
    "inp=torch.eye(4,5,requires_grad=True)\n",
    "out=(inp+1).pow(2).t()\n",
    "out.backward(torch.ones_like(out),retain_graph=True)\n",
    "print(f'first:{inp.grad}')\n",
    "out.backward(torch.ones_like(out),retain_graph=True)\n",
    "print(f'secend:{inp.grad}')\n",
    "inp.grad.zero_()\n",
    "out.backward(torch.ones_like(out),retain_graph=True)\n",
    "print(f'자코비안:{inp.grad}')\n",
    "#backward동일한 인수로 두 번째 호출을 수행하면 그래디언트 값이 달라집니다. 이는 전파를 수행할 때 backwardPyTorch가 기울기를 누적하기 때문에 발생합니다 . 즉, 계산된 기울기의 값이 grad계산 그래프의 모든 리프 노드 속성에 추가됩니다. 적절한 그래디언트를 계산하려면 grad 먼저 속성을 0으로 설정해야 합니다. 실제 훈련에서는 옵티마이저가 이를 수행하는 데 도움이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b53c85f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "train_data=datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "test_data=datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    "    \n",
    ")\n",
    "train_load=DataLoader(train_data, batch_size=64)\n",
    "test_load=DataLoader(test_data,batch_size=64)\n",
    "\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.linear_relu_stack=nn.Sequential(\n",
    "            \n",
    "            nn.Linear(28*28,512),\n",
    "            \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(512,512),\n",
    "            \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(512,10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x=self.flatten(x),\n",
    "        logit=self.linear_relu_stack(x)\n",
    "        return logit\n",
    "    \n",
    "model=NN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3f338088",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs10' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_105088/3644064430.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m  \u001b[0;31m#에포크 수 - 데이터 세트를 반복하는 횟수입니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m  \u001b[0;31m#배치 크기 - 매개변수가 업데이트되기 전에 네트워크를 통해 전파되는 데이터 샘플 수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mepochs10\u001b[0m  \u001b[0;31m#학습률 - 각 배치/에포크에서 모델 매개변수를 업데이트하는 정도입니다. 값이 작을수록 학습 속도가 느려지고 값이 크면 훈련 중에 예측할 수 없는 동작이 발생할 수 있습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'epochs10' is not defined"
     ]
    }
   ],
   "source": [
    "learning_rate=1e-3  #에포크 수 - 데이터 세트를 반복하는 횟수입니다.\n",
    "batch_size=70  #배치 크기 - 매개변수가 업데이트되기 전에 네트워크를 통해 전파되는 데이터 샘플 수\n",
    "epochs10  #학습률 - 각 배치/에포크에서 모델 매개변수를 업데이트하는 정도입니다. 값이 작을수록 학습 속도가 느려지고 값이 크면 훈련 중에 예측할 수 없는 동작이 발생할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "2143f902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'optimizer.zero_grad()모델 매개변수의 그라데이션을 재설정하려면 호출하세요 . 기본적으로 그라디언트는 합산됩니다. 이중 계산을 방지하기 위해 각 반복마다 명시적으로 0을 지정합니다.\\n\\n를 호출하여 예측 손실을 역전파합니다 loss.backward(). PyTorch는 각 매개변수에 대한 손실 기울기를 저장합니다.\\n\\n그래디언트가 있으면 optimizer.step()역방향 패스에서 수집된 그래디언트로 매개변수를 조정하기 위해 호출합니다.'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Train Loop - 훈련 데이터 세트를 반복하고 최적의 매개변수로 수렴하려고 시도합니다.\n",
    "\n",
    "검증/테스트 루프 - 테스트 데이터 세트를 반복하여 모델 성능이 향상되는지 확인합니다.'''\n",
    "\n",
    "loos_fn=nn.CrossEntropyLoss()\n",
    "opt=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "'''optimizer.zero_grad()모델 매개변수의 그라데이션을 재설정하려면 호출하세요 . 기본적으로 그라디언트는 합산됩니다. 이중 계산을 방지하기 위해 각 반복마다 명시적으로 0을 지정합니다.\n",
    "\n",
    "를 호출하여 예측 손실을 역전파합니다 loss.backward(). PyTorch는 각 매개변수에 대한 손실 기울기를 저장합니다.\n",
    "\n",
    "그래디언트가 있으면 optimizer.step()역방향 패스에서 수집된 그래디언트로 매개변수를 조정하기 위해 호출합니다.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "439fd9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader,model,loss_fn,opt):\n",
    "    size=len(dataloader.dataset)\n",
    "    \n",
    "    model.train()\n",
    "    for batch,(x,y)in enumerate(dataloader):\n",
    "        pred=model(x)\n",
    "        loss=loss_fn(pred,y)\n",
    "\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss,current=loss.item(),(batch+1)*len(x)\n",
    "            print(f'loss:{loss:>7f} [{current:>5d}/{size:>5d}]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "777d83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader,model,loss_fn):\n",
    "    model.eval()\n",
    "    \n",
    "    size=len(dataloader.dataset)\n",
    "    num_batches=len(dataloader)\n",
    "    test_loss,correct=0,0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x,y in dataloader:\n",
    "            pred=model(x)\n",
    "            test_loss += loss_fn(pred,y).item()\n",
    "            correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    #test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'testE: \\n Acc: {(100*correct):>0.1f}%, AVG LOSS: {test_loss:>8f} \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "0d7da773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1\n",
      "---------------------------------------\n",
      "loss:1.966899 [   64/60000]\n",
      "loss:1.942338 [ 6464/60000]\n",
      "loss:1.832552 [12864/60000]\n",
      "loss:1.869750 [19264/60000]\n",
      "loss:1.772771 [25664/60000]\n",
      "loss:1.722497 [32064/60000]\n",
      "loss:1.749596 [38464/60000]\n",
      "loss:1.642611 [44864/60000]\n",
      "loss:1.663311 [51264/60000]\n",
      "loss:1.572902 [57664/60000]\n",
      "testE: \n",
      " Acc: 59.6%, AVG LOSS: 1.575711 \n",
      "\n",
      "epoch : 2\n",
      "---------------------------------------\n",
      "loss:1.638615 [   64/60000]\n",
      "loss:1.602586 [ 6464/60000]\n",
      "loss:1.446741 [12864/60000]\n",
      "loss:1.515650 [19264/60000]\n",
      "loss:1.405232 [25664/60000]\n",
      "loss:1.388863 [32064/60000]\n",
      "loss:1.410285 [38464/60000]\n",
      "loss:1.326218 [44864/60000]\n",
      "loss:1.363683 [51264/60000]\n",
      "loss:1.263600 [57664/60000]\n",
      "testE: \n",
      " Acc: 62.2%, AVG LOSS: 1.287552 \n",
      "\n",
      "epoch : 3\n",
      "---------------------------------------\n",
      "loss:1.368521 [   64/60000]\n",
      "loss:1.343348 [ 6464/60000]\n",
      "loss:1.174529 [12864/60000]\n",
      "loss:1.275246 [19264/60000]\n",
      "loss:1.161607 [25664/60000]\n",
      "loss:1.174590 [32064/60000]\n",
      "loss:1.198127 [38464/60000]\n",
      "loss:1.134344 [44864/60000]\n",
      "loss:1.175147 [51264/60000]\n",
      "loss:1.085028 [57664/60000]\n",
      "testE: \n",
      " Acc: 64.0%, AVG LOSS: 1.110533 \n",
      "\n",
      "epoch : 4\n",
      "---------------------------------------\n",
      "loss:1.188684 [   64/60000]\n",
      "loss:1.180726 [ 6464/60000]\n",
      "loss:0.998497 [12864/60000]\n",
      "loss:1.127704 [19264/60000]\n",
      "loss:1.011108 [25664/60000]\n",
      "loss:1.034686 [32064/60000]\n",
      "loss:1.069701 [38464/60000]\n",
      "loss:1.014576 [44864/60000]\n",
      "loss:1.054761 [51264/60000]\n",
      "loss:0.976006 [57664/60000]\n",
      "testE: \n",
      " Acc: 65.8%, AVG LOSS: 0.997964 \n",
      "\n",
      "epoch : 5\n",
      "---------------------------------------\n",
      "loss:1.064992 [   64/60000]\n",
      "loss:1.076789 [ 6464/60000]\n",
      "loss:0.878994 [12864/60000]\n",
      "loss:1.030664 [19264/60000]\n",
      "loss:0.916933 [25664/60000]\n",
      "loss:0.936735 [32064/60000]\n",
      "loss:0.986142 [38464/60000]\n",
      "loss:0.936245 [44864/60000]\n",
      "loss:0.971716 [51264/60000]\n",
      "loss:0.903708 [57664/60000]\n",
      "testE: \n",
      " Acc: 67.2%, AVG LOSS: 0.921525 \n",
      "\n",
      "epoch : 6\n",
      "---------------------------------------\n",
      "loss:0.974094 [   64/60000]\n",
      "loss:1.005147 [ 6464/60000]\n",
      "loss:0.793201 [12864/60000]\n",
      "loss:0.962394 [19264/60000]\n",
      "loss:0.854358 [25664/60000]\n",
      "loss:0.864542 [32064/60000]\n",
      "loss:0.926832 [38464/60000]\n",
      "loss:0.882894 [44864/60000]\n",
      "loss:0.911493 [51264/60000]\n",
      "loss:0.851535 [57664/60000]\n",
      "testE: \n",
      " Acc: 68.4%, AVG LOSS: 0.866305 \n",
      "\n",
      "epoch : 7\n",
      "---------------------------------------\n",
      "loss:0.903690 [   64/60000]\n",
      "loss:0.951201 [ 6464/60000]\n",
      "loss:0.728881 [12864/60000]\n",
      "loss:0.911703 [19264/60000]\n",
      "loss:0.809625 [25664/60000]\n",
      "loss:0.809876 [32064/60000]\n",
      "loss:0.881372 [38464/60000]\n",
      "loss:0.844904 [44864/60000]\n",
      "loss:0.865761 [51264/60000]\n",
      "loss:0.811110 [57664/60000]\n",
      "testE: \n",
      " Acc: 69.9%, AVG LOSS: 0.824196 \n",
      "\n",
      "epoch : 8\n",
      "---------------------------------------\n",
      "loss:0.846746 [   64/60000]\n",
      "loss:0.907788 [ 6464/60000]\n",
      "loss:0.678585 [12864/60000]\n",
      "loss:0.872272 [19264/60000]\n",
      "loss:0.775635 [25664/60000]\n",
      "loss:0.767446 [32064/60000]\n",
      "loss:0.844383 [38464/60000]\n",
      "loss:0.816525 [44864/60000]\n",
      "loss:0.829778 [51264/60000]\n",
      "loss:0.778443 [57664/60000]\n",
      "testE: \n",
      " Acc: 71.1%, AVG LOSS: 0.790598 \n",
      "\n",
      "epoch : 9\n",
      "---------------------------------------\n",
      "loss:0.799260 [   64/60000]\n",
      "loss:0.871108 [ 6464/60000]\n",
      "loss:0.638000 [12864/60000]\n",
      "loss:0.840737 [19264/60000]\n",
      "loss:0.748340 [25664/60000]\n",
      "loss:0.733727 [32064/60000]\n",
      "loss:0.812697 [38464/60000]\n",
      "loss:0.794030 [44864/60000]\n",
      "loss:0.800598 [51264/60000]\n",
      "loss:0.750933 [57664/60000]\n",
      "testE: \n",
      " Acc: 72.4%, AVG LOSS: 0.762676 \n",
      "\n",
      "epoch : 10\n",
      "---------------------------------------\n",
      "loss:0.758754 [   64/60000]\n",
      "loss:0.838965 [ 6464/60000]\n",
      "loss:0.604365 [12864/60000]\n",
      "loss:0.814978 [19264/60000]\n",
      "loss:0.725449 [25664/60000]\n",
      "loss:0.706729 [32064/60000]\n",
      "loss:0.784858 [38464/60000]\n",
      "loss:0.775362 [44864/60000]\n",
      "loss:0.776375 [51264/60000]\n",
      "loss:0.727057 [57664/60000]\n",
      "testE: \n",
      " Acc: 73.5%, AVG LOSS: 0.738774 \n",
      "\n",
      "epoch : 11\n",
      "---------------------------------------\n",
      "loss:0.723608 [   64/60000]\n",
      "loss:0.810242 [ 6464/60000]\n",
      "loss:0.575927 [12864/60000]\n",
      "loss:0.793354 [19264/60000]\n",
      "loss:0.706153 [25664/60000]\n",
      "loss:0.684794 [32064/60000]\n",
      "loss:0.760009 [38464/60000]\n",
      "loss:0.759100 [44864/60000]\n",
      "loss:0.755776 [51264/60000]\n",
      "loss:0.706108 [57664/60000]\n",
      "testE: \n",
      " Acc: 74.4%, AVG LOSS: 0.717904 \n",
      "\n",
      "epoch : 12\n",
      "---------------------------------------\n",
      "loss:0.692874 [   64/60000]\n",
      "loss:0.784337 [ 6464/60000]\n",
      "loss:0.551396 [12864/60000]\n",
      "loss:0.774691 [19264/60000]\n",
      "loss:0.689624 [25664/60000]\n",
      "loss:0.666554 [32064/60000]\n",
      "loss:0.737402 [38464/60000]\n",
      "loss:0.744662 [44864/60000]\n",
      "loss:0.738088 [51264/60000]\n",
      "loss:0.687400 [57664/60000]\n",
      "testE: \n",
      " Acc: 75.2%, AVG LOSS: 0.699300 \n",
      "\n",
      "epoch : 13\n",
      "---------------------------------------\n",
      "loss:0.665688 [   64/60000]\n",
      "loss:0.760717 [ 6464/60000]\n",
      "loss:0.530014 [12864/60000]\n",
      "loss:0.758251 [19264/60000]\n",
      "loss:0.675245 [25664/60000]\n",
      "loss:0.651194 [32064/60000]\n",
      "loss:0.716712 [38464/60000]\n",
      "loss:0.731749 [44864/60000]\n",
      "loss:0.722794 [51264/60000]\n",
      "loss:0.670613 [57664/60000]\n",
      "testE: \n",
      " Acc: 75.9%, AVG LOSS: 0.682501 \n",
      "\n",
      "epoch : 14\n",
      "---------------------------------------\n",
      "loss:0.641503 [   64/60000]\n",
      "loss:0.739046 [ 6464/60000]\n",
      "loss:0.511261 [12864/60000]\n",
      "loss:0.743428 [19264/60000]\n",
      "loss:0.662776 [25664/60000]\n",
      "loss:0.638205 [32064/60000]\n",
      "loss:0.697694 [38464/60000]\n",
      "loss:0.720196 [44864/60000]\n",
      "loss:0.709563 [51264/60000]\n",
      "loss:0.655541 [57664/60000]\n",
      "testE: \n",
      " Acc: 76.6%, AVG LOSS: 0.667221 \n",
      "\n",
      "epoch : 15\n",
      "---------------------------------------\n",
      "loss:0.619855 [   64/60000]\n",
      "loss:0.719244 [ 6464/60000]\n",
      "loss:0.494685 [12864/60000]\n",
      "loss:0.729890 [19264/60000]\n",
      "loss:0.651872 [25664/60000]\n",
      "loss:0.626928 [32064/60000]\n",
      "loss:0.680255 [38464/60000]\n",
      "loss:0.709912 [44864/60000]\n",
      "loss:0.698257 [51264/60000]\n",
      "loss:0.641999 [57664/60000]\n",
      "testE: \n",
      " Acc: 77.1%, AVG LOSS: 0.653282 \n",
      "\n",
      "epoch : 16\n",
      "---------------------------------------\n",
      "loss:0.600507 [   64/60000]\n",
      "loss:0.701085 [ 6464/60000]\n",
      "loss:0.479840 [12864/60000]\n",
      "loss:0.717436 [19264/60000]\n",
      "loss:0.642213 [25664/60000]\n",
      "loss:0.617016 [32064/60000]\n",
      "loss:0.664291 [38464/60000]\n",
      "loss:0.700726 [44864/60000]\n",
      "loss:0.688548 [51264/60000]\n",
      "loss:0.629747 [57664/60000]\n",
      "testE: \n",
      " Acc: 77.5%, AVG LOSS: 0.640541 \n",
      "\n",
      "epoch : 17\n",
      "---------------------------------------\n",
      "loss:0.583075 [   64/60000]\n",
      "loss:0.684478 [ 6464/60000]\n",
      "loss:0.466434 [12864/60000]\n",
      "loss:0.705911 [19264/60000]\n",
      "loss:0.633633 [25664/60000]\n",
      "loss:0.608226 [32064/60000]\n",
      "loss:0.649646 [38464/60000]\n",
      "loss:0.692658 [44864/60000]\n",
      "loss:0.680256 [51264/60000]\n",
      "loss:0.618659 [57664/60000]\n",
      "testE: \n",
      " Acc: 77.9%, AVG LOSS: 0.628867 \n",
      "\n",
      "epoch : 18\n",
      "---------------------------------------\n",
      "loss:0.567280 [   64/60000]\n",
      "loss:0.669294 [ 6464/60000]\n",
      "loss:0.454291 [12864/60000]\n",
      "loss:0.695182 [19264/60000]\n",
      "loss:0.625863 [25664/60000]\n",
      "loss:0.600312 [32064/60000]\n",
      "loss:0.636168 [38464/60000]\n",
      "loss:0.685714 [44864/60000]\n",
      "loss:0.673185 [51264/60000]\n",
      "loss:0.608468 [57664/60000]\n",
      "testE: \n",
      " Acc: 78.3%, AVG LOSS: 0.618157 \n",
      "\n",
      "epoch : 19\n",
      "---------------------------------------\n",
      "loss:0.552921 [   64/60000]\n",
      "loss:0.655372 [ 6464/60000]\n",
      "loss:0.443198 [12864/60000]\n",
      "loss:0.685093 [19264/60000]\n",
      "loss:0.618814 [25664/60000]\n",
      "loss:0.593089 [32064/60000]\n",
      "loss:0.623882 [38464/60000]\n",
      "loss:0.679793 [44864/60000]\n",
      "loss:0.667249 [51264/60000]\n",
      "loss:0.598977 [57664/60000]\n",
      "testE: \n",
      " Acc: 78.6%, AVG LOSS: 0.608310 \n",
      "\n",
      "epoch : 20\n",
      "---------------------------------------\n",
      "loss:0.539799 [   64/60000]\n",
      "loss:0.642570 [ 6464/60000]\n",
      "loss:0.433061 [12864/60000]\n",
      "loss:0.675649 [19264/60000]\n",
      "loss:0.612278 [25664/60000]\n",
      "loss:0.586493 [32064/60000]\n",
      "loss:0.612603 [38464/60000]\n",
      "loss:0.674787 [44864/60000]\n",
      "loss:0.662275 [51264/60000]\n",
      "loss:0.590070 [57664/60000]\n",
      "testE: \n",
      " Acc: 79.0%, AVG LOSS: 0.599237 \n",
      "\n",
      "epoch : 21\n",
      "---------------------------------------\n",
      "loss:0.527717 [   64/60000]\n",
      "loss:0.630784 [ 6464/60000]\n",
      "loss:0.423759 [12864/60000]\n",
      "loss:0.666614 [19264/60000]\n",
      "loss:0.606130 [25664/60000]\n",
      "loss:0.580351 [32064/60000]\n",
      "loss:0.602272 [38464/60000]\n",
      "loss:0.670656 [44864/60000]\n",
      "loss:0.658074 [51264/60000]\n",
      "loss:0.581646 [57664/60000]\n",
      "testE: \n",
      " Acc: 79.3%, AVG LOSS: 0.590855 \n",
      "\n",
      "epoch : 22\n",
      "---------------------------------------\n",
      "loss:0.516575 [   64/60000]\n",
      "loss:0.619881 [ 6464/60000]\n",
      "loss:0.415196 [12864/60000]\n",
      "loss:0.657967 [19264/60000]\n",
      "loss:0.600224 [25664/60000]\n",
      "loss:0.574663 [32064/60000]\n",
      "loss:0.592726 [38464/60000]\n",
      "loss:0.667436 [44864/60000]\n",
      "loss:0.654471 [51264/60000]\n",
      "loss:0.573645 [57664/60000]\n",
      "testE: \n",
      " Acc: 79.6%, AVG LOSS: 0.583108 \n",
      "\n",
      "epoch : 23\n",
      "---------------------------------------\n",
      "loss:0.506246 [   64/60000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.609943 [ 6464/60000]\n",
      "loss:0.407297 [12864/60000]\n",
      "loss:0.649867 [19264/60000]\n",
      "loss:0.594384 [25664/60000]\n",
      "loss:0.569215 [32064/60000]\n",
      "loss:0.583954 [38464/60000]\n",
      "loss:0.664971 [44864/60000]\n",
      "loss:0.651192 [51264/60000]\n",
      "loss:0.565980 [57664/60000]\n",
      "testE: \n",
      " Acc: 79.9%, AVG LOSS: 0.575938 \n",
      "\n",
      "epoch : 24\n",
      "---------------------------------------\n",
      "loss:0.496662 [   64/60000]\n",
      "loss:0.600847 [ 6464/60000]\n",
      "loss:0.399923 [12864/60000]\n",
      "loss:0.642256 [19264/60000]\n",
      "loss:0.588652 [25664/60000]\n",
      "loss:0.564185 [32064/60000]\n",
      "loss:0.575943 [38464/60000]\n",
      "loss:0.663026 [44864/60000]\n",
      "loss:0.648357 [51264/60000]\n",
      "loss:0.558546 [57664/60000]\n",
      "testE: \n",
      " Acc: 80.1%, AVG LOSS: 0.569304 \n",
      "\n",
      "epoch : 25\n",
      "---------------------------------------\n",
      "loss:0.487663 [   64/60000]\n",
      "loss:0.592483 [ 6464/60000]\n",
      "loss:0.393098 [12864/60000]\n",
      "loss:0.635017 [19264/60000]\n",
      "loss:0.582947 [25664/60000]\n",
      "loss:0.559317 [32064/60000]\n",
      "loss:0.568476 [38464/60000]\n",
      "loss:0.661558 [44864/60000]\n",
      "loss:0.645892 [51264/60000]\n",
      "loss:0.551401 [57664/60000]\n",
      "testE: \n",
      " Acc: 80.3%, AVG LOSS: 0.563149 \n",
      "\n",
      "epoch : 26\n",
      "---------------------------------------\n",
      "loss:0.479197 [   64/60000]\n",
      "loss:0.584765 [ 6464/60000]\n",
      "loss:0.386774 [12864/60000]\n",
      "loss:0.628152 [19264/60000]\n",
      "loss:0.577242 [25664/60000]\n",
      "loss:0.554623 [32064/60000]\n",
      "loss:0.561607 [38464/60000]\n",
      "loss:0.660560 [44864/60000]\n",
      "loss:0.643661 [51264/60000]\n",
      "loss:0.544468 [57664/60000]\n",
      "testE: \n",
      " Acc: 80.5%, AVG LOSS: 0.557429 \n",
      "\n",
      "epoch : 27\n",
      "---------------------------------------\n",
      "loss:0.471183 [   64/60000]\n",
      "loss:0.577657 [ 6464/60000]\n",
      "loss:0.380865 [12864/60000]\n",
      "loss:0.621582 [19264/60000]\n",
      "loss:0.571581 [25664/60000]\n",
      "loss:0.550057 [32064/60000]\n",
      "loss:0.555266 [38464/60000]\n",
      "loss:0.659914 [44864/60000]\n",
      "loss:0.641582 [51264/60000]\n",
      "loss:0.537656 [57664/60000]\n",
      "testE: \n",
      " Acc: 80.7%, AVG LOSS: 0.552099 \n",
      "\n",
      "epoch : 28\n",
      "---------------------------------------\n",
      "loss:0.463575 [   64/60000]\n",
      "loss:0.571069 [ 6464/60000]\n",
      "loss:0.375298 [12864/60000]\n",
      "loss:0.615311 [19264/60000]\n",
      "loss:0.566014 [25664/60000]\n",
      "loss:0.545524 [32064/60000]\n",
      "loss:0.549321 [38464/60000]\n",
      "loss:0.659543 [44864/60000]\n",
      "loss:0.639652 [51264/60000]\n",
      "loss:0.531025 [57664/60000]\n",
      "testE: \n",
      " Acc: 80.9%, AVG LOSS: 0.547123 \n",
      "\n",
      "epoch : 29\n",
      "---------------------------------------\n",
      "loss:0.456340 [   64/60000]\n",
      "loss:0.564987 [ 6464/60000]\n",
      "loss:0.370046 [12864/60000]\n",
      "loss:0.609288 [19264/60000]\n",
      "loss:0.560448 [25664/60000]\n",
      "loss:0.541090 [32064/60000]\n",
      "loss:0.543763 [38464/60000]\n",
      "loss:0.659358 [44864/60000]\n",
      "loss:0.637798 [51264/60000]\n",
      "loss:0.524588 [57664/60000]\n",
      "testE: \n",
      " Acc: 81.0%, AVG LOSS: 0.542468 \n",
      "\n",
      "epoch : 30\n",
      "---------------------------------------\n",
      "loss:0.449433 [   64/60000]\n",
      "loss:0.559360 [ 6464/60000]\n",
      "loss:0.365085 [12864/60000]\n",
      "loss:0.603505 [19264/60000]\n",
      "loss:0.554948 [25664/60000]\n",
      "loss:0.536799 [32064/60000]\n",
      "loss:0.538527 [38464/60000]\n",
      "loss:0.659361 [44864/60000]\n",
      "loss:0.636006 [51264/60000]\n",
      "loss:0.518367 [57664/60000]\n",
      "testE: \n",
      " Acc: 81.2%, AVG LOSS: 0.538099 \n",
      "\n",
      "epoch : 31\n",
      "---------------------------------------\n",
      "loss:0.442811 [   64/60000]\n",
      "loss:0.554106 [ 6464/60000]\n",
      "loss:0.360399 [12864/60000]\n",
      "loss:0.597938 [19264/60000]\n",
      "loss:0.549571 [25664/60000]\n",
      "loss:0.532508 [32064/60000]\n",
      "loss:0.533579 [38464/60000]\n",
      "loss:0.659384 [44864/60000]\n",
      "loss:0.634141 [51264/60000]\n",
      "loss:0.512303 [57664/60000]\n",
      "testE: \n",
      " Acc: 81.3%, AVG LOSS: 0.533992 \n",
      "\n",
      "epoch : 32\n",
      "---------------------------------------\n",
      "loss:0.436461 [   64/60000]\n",
      "loss:0.549239 [ 6464/60000]\n",
      "loss:0.355961 [12864/60000]\n",
      "loss:0.592571 [19264/60000]\n",
      "loss:0.544234 [25664/60000]\n",
      "loss:0.528286 [32064/60000]\n",
      "loss:0.528910 [38464/60000]\n",
      "loss:0.659377 [44864/60000]\n",
      "loss:0.632242 [51264/60000]\n",
      "loss:0.506385 [57664/60000]\n",
      "testE: \n",
      " Acc: 81.5%, AVG LOSS: 0.530122 \n",
      "\n",
      "epoch : 33\n",
      "---------------------------------------\n",
      "loss:0.430406 [   64/60000]\n",
      "loss:0.544730 [ 6464/60000]\n",
      "loss:0.351721 [12864/60000]\n",
      "loss:0.587432 [19264/60000]\n",
      "loss:0.539013 [25664/60000]\n",
      "loss:0.524088 [32064/60000]\n",
      "loss:0.524479 [38464/60000]\n",
      "loss:0.659450 [44864/60000]\n",
      "loss:0.630365 [51264/60000]\n",
      "loss:0.500720 [57664/60000]\n",
      "testE: \n",
      " Acc: 81.5%, AVG LOSS: 0.526455 \n",
      "\n",
      "epoch : 34\n",
      "---------------------------------------\n",
      "loss:0.424648 [   64/60000]\n",
      "loss:0.540495 [ 6464/60000]\n",
      "loss:0.347767 [12864/60000]\n",
      "loss:0.582491 [19264/60000]\n",
      "loss:0.533990 [25664/60000]\n",
      "loss:0.520015 [32064/60000]\n",
      "loss:0.520336 [38464/60000]\n",
      "loss:0.659549 [44864/60000]\n",
      "loss:0.628522 [51264/60000]\n",
      "loss:0.495223 [57664/60000]\n",
      "testE: \n",
      " Acc: 81.6%, AVG LOSS: 0.522987 \n",
      "\n",
      "epoch : 35\n",
      "---------------------------------------\n",
      "loss:0.419119 [   64/60000]\n",
      "loss:0.536518 [ 6464/60000]\n",
      "loss:0.343993 [12864/60000]\n",
      "loss:0.577631 [19264/60000]\n",
      "loss:0.529123 [25664/60000]\n",
      "loss:0.516014 [32064/60000]\n",
      "loss:0.516556 [38464/60000]\n",
      "loss:0.659567 [44864/60000]\n",
      "loss:0.626706 [51264/60000]\n",
      "loss:0.489922 [57664/60000]\n",
      "testE: \n",
      " Acc: 81.7%, AVG LOSS: 0.519709 \n",
      "\n",
      "epoch : 36\n",
      "---------------------------------------\n",
      "loss:0.413679 [   64/60000]\n",
      "loss:0.532809 [ 6464/60000]\n",
      "loss:0.340437 [12864/60000]\n",
      "loss:0.572968 [19264/60000]\n",
      "loss:0.524295 [25664/60000]\n",
      "loss:0.512099 [32064/60000]\n",
      "loss:0.512995 [38464/60000]\n",
      "loss:0.659468 [44864/60000]\n",
      "loss:0.624853 [51264/60000]\n",
      "loss:0.484908 [57664/60000]\n",
      "testE: \n",
      " Acc: 81.7%, AVG LOSS: 0.516605 \n",
      "\n",
      "epoch : 37\n",
      "---------------------------------------\n",
      "loss:0.408440 [   64/60000]\n",
      "loss:0.529346 [ 6464/60000]\n",
      "loss:0.337063 [12864/60000]\n",
      "loss:0.568516 [19264/60000]\n",
      "loss:0.519538 [25664/60000]\n",
      "loss:0.508320 [32064/60000]\n",
      "loss:0.509562 [38464/60000]\n",
      "loss:0.659288 [44864/60000]\n",
      "loss:0.622964 [51264/60000]\n",
      "loss:0.480078 [57664/60000]\n",
      "testE: \n",
      " Acc: 81.7%, AVG LOSS: 0.513657 \n",
      "\n",
      "epoch : 38\n",
      "---------------------------------------\n",
      "loss:0.403367 [   64/60000]\n",
      "loss:0.526083 [ 6464/60000]\n",
      "loss:0.333859 [12864/60000]\n",
      "loss:0.564265 [19264/60000]\n",
      "loss:0.514887 [25664/60000]\n",
      "loss:0.504657 [32064/60000]\n",
      "loss:0.506270 [38464/60000]\n",
      "loss:0.658943 [44864/60000]\n",
      "loss:0.621048 [51264/60000]\n",
      "loss:0.475448 [57664/60000]\n",
      "testE: \n",
      " Acc: 81.8%, AVG LOSS: 0.510854 \n",
      "\n",
      "epoch : 39\n",
      "---------------------------------------\n",
      "loss:0.398439 [   64/60000]\n",
      "loss:0.523024 [ 6464/60000]\n",
      "loss:0.330787 [12864/60000]\n",
      "loss:0.560170 [19264/60000]\n",
      "loss:0.510360 [25664/60000]\n",
      "loss:0.501088 [32064/60000]\n",
      "loss:0.503134 [38464/60000]\n",
      "loss:0.658492 [44864/60000]\n",
      "loss:0.619129 [51264/60000]\n",
      "loss:0.471027 [57664/60000]\n",
      "testE: \n",
      " Acc: 81.8%, AVG LOSS: 0.508177 \n",
      "\n",
      "epoch : 40\n",
      "---------------------------------------\n",
      "loss:0.393666 [   64/60000]\n",
      "loss:0.520130 [ 6464/60000]\n",
      "loss:0.327848 [12864/60000]\n",
      "loss:0.556252 [19264/60000]\n",
      "loss:0.505928 [25664/60000]\n",
      "loss:0.497583 [32064/60000]\n",
      "loss:0.500125 [38464/60000]\n",
      "loss:0.657936 [44864/60000]\n",
      "loss:0.617195 [51264/60000]\n",
      "loss:0.466850 [57664/60000]\n",
      "testE: \n",
      " Acc: 81.9%, AVG LOSS: 0.505623 \n",
      "\n",
      "epoch : 41\n",
      "---------------------------------------\n",
      "loss:0.389011 [   64/60000]\n",
      "loss:0.517377 [ 6464/60000]\n",
      "loss:0.325003 [12864/60000]\n",
      "loss:0.552489 [19264/60000]\n",
      "loss:0.501603 [25664/60000]\n",
      "loss:0.494168 [32064/60000]\n",
      "loss:0.497239 [38464/60000]\n",
      "loss:0.657264 [44864/60000]\n",
      "loss:0.615286 [51264/60000]\n",
      "loss:0.462871 [57664/60000]\n",
      "testE: \n",
      " Acc: 82.0%, AVG LOSS: 0.503178 \n",
      "\n",
      "epoch : 42\n",
      "---------------------------------------\n",
      "loss:0.384496 [   64/60000]\n",
      "loss:0.514807 [ 6464/60000]\n",
      "loss:0.322302 [12864/60000]\n",
      "loss:0.548831 [19264/60000]\n",
      "loss:0.497399 [25664/60000]\n",
      "loss:0.490858 [32064/60000]\n",
      "loss:0.494477 [38464/60000]\n",
      "loss:0.656412 [44864/60000]\n",
      "loss:0.613383 [51264/60000]\n",
      "loss:0.459123 [57664/60000]\n",
      "testE: \n",
      " Acc: 82.0%, AVG LOSS: 0.500833 \n",
      "\n",
      "epoch : 43\n",
      "---------------------------------------\n",
      "loss:0.380116 [   64/60000]\n",
      "loss:0.512359 [ 6464/60000]\n",
      "loss:0.319745 [12864/60000]\n",
      "loss:0.545292 [19264/60000]\n",
      "loss:0.493316 [25664/60000]\n",
      "loss:0.487619 [32064/60000]\n",
      "loss:0.491834 [38464/60000]\n",
      "loss:0.655495 [44864/60000]\n",
      "loss:0.611468 [51264/60000]\n",
      "loss:0.455541 [57664/60000]\n",
      "testE: \n",
      " Acc: 82.0%, AVG LOSS: 0.498581 \n",
      "\n",
      "epoch : 44\n",
      "---------------------------------------\n",
      "loss:0.375887 [   64/60000]\n",
      "loss:0.510047 [ 6464/60000]\n",
      "loss:0.317281 [12864/60000]\n",
      "loss:0.541910 [19264/60000]\n",
      "loss:0.489369 [25664/60000]\n",
      "loss:0.484478 [32064/60000]\n",
      "loss:0.489271 [38464/60000]\n",
      "loss:0.654443 [44864/60000]\n",
      "loss:0.609506 [51264/60000]\n",
      "loss:0.452127 [57664/60000]\n",
      "testE: \n",
      " Acc: 82.2%, AVG LOSS: 0.496420 \n",
      "\n",
      "epoch : 45\n",
      "---------------------------------------\n",
      "loss:0.371767 [   64/60000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.507843 [ 6464/60000]\n",
      "loss:0.314917 [12864/60000]\n",
      "loss:0.538620 [19264/60000]\n",
      "loss:0.485496 [25664/60000]\n",
      "loss:0.481456 [32064/60000]\n",
      "loss:0.486737 [38464/60000]\n",
      "loss:0.653248 [44864/60000]\n",
      "loss:0.607579 [51264/60000]\n",
      "loss:0.448926 [57664/60000]\n",
      "testE: \n",
      " Acc: 82.2%, AVG LOSS: 0.494342 \n",
      "\n",
      "epoch : 46\n",
      "---------------------------------------\n",
      "loss:0.367793 [   64/60000]\n",
      "loss:0.505749 [ 6464/60000]\n",
      "loss:0.312642 [12864/60000]\n",
      "loss:0.535440 [19264/60000]\n",
      "loss:0.481751 [25664/60000]\n",
      "loss:0.478546 [32064/60000]\n",
      "loss:0.484263 [38464/60000]\n",
      "loss:0.652047 [44864/60000]\n",
      "loss:0.605700 [51264/60000]\n",
      "loss:0.445878 [57664/60000]\n",
      "testE: \n",
      " Acc: 82.3%, AVG LOSS: 0.492345 \n",
      "\n",
      "epoch : 47\n",
      "---------------------------------------\n",
      "loss:0.363906 [   64/60000]\n",
      "loss:0.503736 [ 6464/60000]\n",
      "loss:0.310439 [12864/60000]\n",
      "loss:0.532375 [19264/60000]\n",
      "loss:0.478118 [25664/60000]\n",
      "loss:0.475754 [32064/60000]\n",
      "loss:0.481895 [38464/60000]\n",
      "loss:0.650732 [44864/60000]\n",
      "loss:0.603809 [51264/60000]\n",
      "loss:0.443021 [57664/60000]\n",
      "testE: \n",
      " Acc: 82.4%, AVG LOSS: 0.490417 \n",
      "\n",
      "epoch : 48\n",
      "---------------------------------------\n",
      "loss:0.360135 [   64/60000]\n",
      "loss:0.501814 [ 6464/60000]\n",
      "loss:0.308311 [12864/60000]\n",
      "loss:0.529441 [19264/60000]\n",
      "loss:0.474600 [25664/60000]\n",
      "loss:0.473091 [32064/60000]\n",
      "loss:0.479586 [38464/60000]\n",
      "loss:0.649329 [44864/60000]\n",
      "loss:0.601902 [51264/60000]\n",
      "loss:0.440340 [57664/60000]\n",
      "testE: \n",
      " Acc: 82.4%, AVG LOSS: 0.488555 \n",
      "\n",
      "epoch : 49\n",
      "---------------------------------------\n",
      "loss:0.356498 [   64/60000]\n",
      "loss:0.499981 [ 6464/60000]\n",
      "loss:0.306243 [12864/60000]\n",
      "loss:0.526638 [19264/60000]\n",
      "loss:0.471148 [25664/60000]\n",
      "loss:0.470458 [32064/60000]\n",
      "loss:0.477385 [38464/60000]\n",
      "loss:0.647868 [44864/60000]\n",
      "loss:0.600034 [51264/60000]\n",
      "loss:0.437760 [57664/60000]\n",
      "testE: \n",
      " Acc: 82.5%, AVG LOSS: 0.486757 \n",
      "\n",
      "epoch : 50\n",
      "---------------------------------------\n",
      "loss:0.353001 [   64/60000]\n",
      "loss:0.498228 [ 6464/60000]\n",
      "loss:0.304253 [12864/60000]\n",
      "loss:0.523910 [19264/60000]\n",
      "loss:0.467757 [25664/60000]\n",
      "loss:0.467948 [32064/60000]\n",
      "loss:0.475301 [38464/60000]\n",
      "loss:0.646313 [44864/60000]\n",
      "loss:0.598238 [51264/60000]\n",
      "loss:0.435287 [57664/60000]\n",
      "testE: \n",
      " Acc: 82.5%, AVG LOSS: 0.485018 \n",
      "\n",
      "epoch : 51\n",
      "---------------------------------------\n",
      "loss:0.349599 [   64/60000]\n",
      "loss:0.496485 [ 6464/60000]\n",
      "loss:0.302327 [12864/60000]\n",
      "loss:0.521318 [19264/60000]\n",
      "loss:0.464489 [25664/60000]\n",
      "loss:0.465568 [32064/60000]\n",
      "loss:0.473231 [38464/60000]\n",
      "loss:0.644751 [44864/60000]\n",
      "loss:0.596456 [51264/60000]\n",
      "loss:0.432963 [57664/60000]\n",
      "testE: \n",
      " Acc: 82.6%, AVG LOSS: 0.483336 \n",
      "\n",
      "epoch : 52\n",
      "---------------------------------------\n",
      "loss:0.346288 [   64/60000]\n",
      "loss:0.494767 [ 6464/60000]\n",
      "loss:0.300460 [12864/60000]\n",
      "loss:0.518815 [19264/60000]\n",
      "loss:0.461330 [25664/60000]\n",
      "loss:0.463251 [32064/60000]\n",
      "loss:0.471237 [38464/60000]\n",
      "loss:0.643151 [44864/60000]\n",
      "loss:0.594690 [51264/60000]\n",
      "loss:0.430772 [57664/60000]\n",
      "testE: \n",
      " Acc: 82.7%, AVG LOSS: 0.481708 \n",
      "\n",
      "epoch : 53\n",
      "---------------------------------------\n",
      "loss:0.343041 [   64/60000]\n",
      "loss:0.493137 [ 6464/60000]\n",
      "loss:0.298624 [12864/60000]\n",
      "loss:0.516402 [19264/60000]\n",
      "loss:0.458217 [25664/60000]\n",
      "loss:0.460961 [32064/60000]\n",
      "loss:0.469295 [38464/60000]\n",
      "loss:0.641542 [44864/60000]\n",
      "loss:0.592947 [51264/60000]\n",
      "loss:0.428690 [57664/60000]\n",
      "testE: \n",
      " Acc: 82.8%, AVG LOSS: 0.480121 \n",
      "\n",
      "epoch : 54\n",
      "---------------------------------------\n",
      "loss:0.339922 [   64/60000]\n",
      "loss:0.491532 [ 6464/60000]\n",
      "loss:0.296842 [12864/60000]\n",
      "loss:0.514071 [19264/60000]\n",
      "loss:0.455214 [25664/60000]\n",
      "loss:0.458696 [32064/60000]\n",
      "loss:0.467370 [38464/60000]\n",
      "loss:0.640008 [44864/60000]\n",
      "loss:0.591345 [51264/60000]\n",
      "loss:0.426723 [57664/60000]\n",
      "testE: \n",
      " Acc: 82.8%, AVG LOSS: 0.478568 \n",
      "\n",
      "epoch : 55\n",
      "---------------------------------------\n",
      "loss:0.336921 [   64/60000]\n",
      "loss:0.489931 [ 6464/60000]\n",
      "loss:0.295125 [12864/60000]\n",
      "loss:0.511797 [19264/60000]\n",
      "loss:0.452230 [25664/60000]\n",
      "loss:0.456485 [32064/60000]\n",
      "loss:0.465444 [38464/60000]\n",
      "loss:0.638463 [44864/60000]\n",
      "loss:0.589761 [51264/60000]\n",
      "loss:0.424840 [57664/60000]\n",
      "testE: \n",
      " Acc: 82.8%, AVG LOSS: 0.477046 \n",
      "\n",
      "epoch : 56\n",
      "---------------------------------------\n",
      "loss:0.334038 [   64/60000]\n",
      "loss:0.488301 [ 6464/60000]\n",
      "loss:0.293478 [12864/60000]\n",
      "loss:0.509568 [19264/60000]\n",
      "loss:0.449379 [25664/60000]\n",
      "loss:0.454386 [32064/60000]\n",
      "loss:0.463500 [38464/60000]\n",
      "loss:0.636883 [44864/60000]\n",
      "loss:0.588054 [51264/60000]\n",
      "loss:0.423107 [57664/60000]\n",
      "testE: \n",
      " Acc: 82.8%, AVG LOSS: 0.475582 \n",
      "\n",
      "epoch : 57\n",
      "---------------------------------------\n",
      "loss:0.331178 [   64/60000]\n",
      "loss:0.486823 [ 6464/60000]\n",
      "loss:0.291890 [12864/60000]\n",
      "loss:0.507447 [19264/60000]\n",
      "loss:0.446543 [25664/60000]\n",
      "loss:0.452322 [32064/60000]\n",
      "loss:0.461702 [38464/60000]\n",
      "loss:0.635212 [44864/60000]\n",
      "loss:0.586404 [51264/60000]\n",
      "loss:0.421461 [57664/60000]\n",
      "testE: \n",
      " Acc: 82.9%, AVG LOSS: 0.474163 \n",
      "\n",
      "epoch : 58\n",
      "---------------------------------------\n",
      "loss:0.328378 [   64/60000]\n",
      "loss:0.485340 [ 6464/60000]\n",
      "loss:0.290302 [12864/60000]\n",
      "loss:0.505401 [19264/60000]\n",
      "loss:0.443680 [25664/60000]\n",
      "loss:0.450303 [32064/60000]\n",
      "loss:0.459974 [38464/60000]\n",
      "loss:0.633508 [44864/60000]\n",
      "loss:0.584784 [51264/60000]\n",
      "loss:0.419843 [57664/60000]\n",
      "testE: \n",
      " Acc: 82.9%, AVG LOSS: 0.472788 \n",
      "\n",
      "epoch : 59\n",
      "---------------------------------------\n",
      "loss:0.325692 [   64/60000]\n",
      "loss:0.483867 [ 6464/60000]\n",
      "loss:0.288808 [12864/60000]\n",
      "loss:0.503409 [19264/60000]\n",
      "loss:0.440889 [25664/60000]\n",
      "loss:0.448328 [32064/60000]\n",
      "loss:0.458224 [38464/60000]\n",
      "loss:0.631739 [44864/60000]\n",
      "loss:0.583174 [51264/60000]\n",
      "loss:0.418310 [57664/60000]\n",
      "testE: \n",
      " Acc: 83.0%, AVG LOSS: 0.471454 \n",
      "\n",
      "epoch : 60\n",
      "---------------------------------------\n",
      "loss:0.323065 [   64/60000]\n",
      "loss:0.482408 [ 6464/60000]\n",
      "loss:0.287369 [12864/60000]\n",
      "loss:0.501530 [19264/60000]\n",
      "loss:0.438192 [25664/60000]\n",
      "loss:0.446418 [32064/60000]\n",
      "loss:0.456544 [38464/60000]\n",
      "loss:0.629927 [44864/60000]\n",
      "loss:0.581615 [51264/60000]\n",
      "loss:0.416873 [57664/60000]\n",
      "testE: \n",
      " Acc: 83.2%, AVG LOSS: 0.470149 \n",
      "\n",
      "epoch : 61\n",
      "---------------------------------------\n",
      "loss:0.320522 [   64/60000]\n",
      "loss:0.480975 [ 6464/60000]\n",
      "loss:0.285973 [12864/60000]\n",
      "loss:0.499712 [19264/60000]\n",
      "loss:0.435553 [25664/60000]\n",
      "loss:0.444651 [32064/60000]\n",
      "loss:0.454905 [38464/60000]\n",
      "loss:0.628103 [44864/60000]\n",
      "loss:0.580029 [51264/60000]\n",
      "loss:0.415487 [57664/60000]\n",
      "testE: \n",
      " Acc: 83.2%, AVG LOSS: 0.468879 \n",
      "\n",
      "epoch : 62\n",
      "---------------------------------------\n",
      "loss:0.318075 [   64/60000]\n",
      "loss:0.479548 [ 6464/60000]\n",
      "loss:0.284614 [12864/60000]\n",
      "loss:0.497943 [19264/60000]\n",
      "loss:0.432993 [25664/60000]\n",
      "loss:0.442920 [32064/60000]\n",
      "loss:0.453252 [38464/60000]\n",
      "loss:0.626297 [44864/60000]\n",
      "loss:0.578434 [51264/60000]\n",
      "loss:0.414158 [57664/60000]\n",
      "testE: \n",
      " Acc: 83.3%, AVG LOSS: 0.467640 \n",
      "\n",
      "epoch : 63\n",
      "---------------------------------------\n",
      "loss:0.315662 [   64/60000]\n",
      "loss:0.478109 [ 6464/60000]\n",
      "loss:0.283293 [12864/60000]\n",
      "loss:0.496244 [19264/60000]\n",
      "loss:0.430491 [25664/60000]\n",
      "loss:0.441229 [32064/60000]\n",
      "loss:0.451645 [38464/60000]\n",
      "loss:0.624495 [44864/60000]\n",
      "loss:0.576849 [51264/60000]\n",
      "loss:0.412886 [57664/60000]\n",
      "testE: \n",
      " Acc: 83.3%, AVG LOSS: 0.466430 \n",
      "\n",
      "epoch : 64\n",
      "---------------------------------------\n",
      "loss:0.313362 [   64/60000]\n",
      "loss:0.476729 [ 6464/60000]\n",
      "loss:0.282015 [12864/60000]\n",
      "loss:0.494567 [19264/60000]\n",
      "loss:0.428090 [25664/60000]\n",
      "loss:0.439580 [32064/60000]\n",
      "loss:0.450048 [38464/60000]\n",
      "loss:0.622680 [44864/60000]\n",
      "loss:0.575285 [51264/60000]\n",
      "loss:0.411670 [57664/60000]\n",
      "testE: \n",
      " Acc: 83.4%, AVG LOSS: 0.465248 \n",
      "\n",
      "epoch : 65\n",
      "---------------------------------------\n",
      "loss:0.311167 [   64/60000]\n",
      "loss:0.475383 [ 6464/60000]\n",
      "loss:0.280761 [12864/60000]\n",
      "loss:0.492909 [19264/60000]\n",
      "loss:0.425686 [25664/60000]\n",
      "loss:0.437953 [32064/60000]\n",
      "loss:0.448521 [38464/60000]\n",
      "loss:0.620819 [44864/60000]\n",
      "loss:0.573761 [51264/60000]\n",
      "loss:0.410507 [57664/60000]\n",
      "testE: \n",
      " Acc: 83.4%, AVG LOSS: 0.464094 \n",
      "\n",
      "epoch : 66\n",
      "---------------------------------------\n",
      "loss:0.309052 [   64/60000]\n",
      "loss:0.473976 [ 6464/60000]\n",
      "loss:0.279551 [12864/60000]\n",
      "loss:0.491271 [19264/60000]\n",
      "loss:0.423337 [25664/60000]\n",
      "loss:0.436420 [32064/60000]\n",
      "loss:0.447008 [38464/60000]\n",
      "loss:0.619031 [44864/60000]\n",
      "loss:0.572254 [51264/60000]\n",
      "loss:0.409357 [57664/60000]\n",
      "testE: \n",
      " Acc: 83.5%, AVG LOSS: 0.462960 \n",
      "\n",
      "epoch : 67\n",
      "---------------------------------------\n",
      "loss:0.306990 [   64/60000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.472569 [ 6464/60000]\n",
      "loss:0.278408 [12864/60000]\n",
      "loss:0.489683 [19264/60000]\n",
      "loss:0.421057 [25664/60000]\n",
      "loss:0.434941 [32064/60000]\n",
      "loss:0.445510 [38464/60000]\n",
      "loss:0.617266 [44864/60000]\n",
      "loss:0.570705 [51264/60000]\n",
      "loss:0.408262 [57664/60000]\n",
      "testE: \n",
      " Acc: 83.5%, AVG LOSS: 0.461849 \n",
      "\n",
      "epoch : 68\n",
      "---------------------------------------\n",
      "loss:0.304983 [   64/60000]\n",
      "loss:0.471130 [ 6464/60000]\n",
      "loss:0.277309 [12864/60000]\n",
      "loss:0.488174 [19264/60000]\n",
      "loss:0.418831 [25664/60000]\n",
      "loss:0.433512 [32064/60000]\n",
      "loss:0.444021 [38464/60000]\n",
      "loss:0.615503 [44864/60000]\n",
      "loss:0.569144 [51264/60000]\n",
      "loss:0.407216 [57664/60000]\n",
      "testE: \n",
      " Acc: 83.6%, AVG LOSS: 0.460757 \n",
      "\n",
      "epoch : 69\n",
      "---------------------------------------\n",
      "loss:0.303022 [   64/60000]\n",
      "loss:0.469679 [ 6464/60000]\n",
      "loss:0.276242 [12864/60000]\n",
      "loss:0.486674 [19264/60000]\n",
      "loss:0.416676 [25664/60000]\n",
      "loss:0.432112 [32064/60000]\n",
      "loss:0.442592 [38464/60000]\n",
      "loss:0.613785 [44864/60000]\n",
      "loss:0.567600 [51264/60000]\n",
      "loss:0.406274 [57664/60000]\n",
      "testE: \n",
      " Acc: 83.6%, AVG LOSS: 0.459685 \n",
      "\n",
      "epoch : 70\n",
      "---------------------------------------\n",
      "loss:0.301166 [   64/60000]\n",
      "loss:0.468352 [ 6464/60000]\n",
      "loss:0.275189 [12864/60000]\n",
      "loss:0.485225 [19264/60000]\n",
      "loss:0.414548 [25664/60000]\n",
      "loss:0.430765 [32064/60000]\n",
      "loss:0.441153 [38464/60000]\n",
      "loss:0.612096 [44864/60000]\n",
      "loss:0.566175 [51264/60000]\n",
      "loss:0.405349 [57664/60000]\n",
      "testE: \n",
      " Acc: 83.6%, AVG LOSS: 0.458638 \n",
      "\n",
      "epoch : 71\n",
      "---------------------------------------\n",
      "loss:0.299342 [   64/60000]\n",
      "loss:0.466993 [ 6464/60000]\n",
      "loss:0.274140 [12864/60000]\n",
      "loss:0.483820 [19264/60000]\n",
      "loss:0.412429 [25664/60000]\n",
      "loss:0.429435 [32064/60000]\n",
      "loss:0.439729 [38464/60000]\n",
      "loss:0.610439 [44864/60000]\n",
      "loss:0.564713 [51264/60000]\n",
      "loss:0.404481 [57664/60000]\n",
      "testE: \n",
      " Acc: 83.7%, AVG LOSS: 0.457605 \n",
      "\n",
      "epoch : 72\n",
      "---------------------------------------\n",
      "loss:0.297567 [   64/60000]\n",
      "loss:0.465620 [ 6464/60000]\n",
      "loss:0.273114 [12864/60000]\n",
      "loss:0.482411 [19264/60000]\n",
      "loss:0.410318 [25664/60000]\n",
      "loss:0.428209 [32064/60000]\n",
      "loss:0.438258 [38464/60000]\n",
      "loss:0.608780 [44864/60000]\n",
      "loss:0.563249 [51264/60000]\n",
      "loss:0.403566 [57664/60000]\n",
      "testE: \n",
      " Acc: 83.8%, AVG LOSS: 0.456593 \n",
      "\n",
      "epoch : 73\n",
      "---------------------------------------\n",
      "loss:0.295812 [   64/60000]\n",
      "loss:0.464230 [ 6464/60000]\n",
      "loss:0.272115 [12864/60000]\n",
      "loss:0.481013 [19264/60000]\n",
      "loss:0.408295 [25664/60000]\n",
      "loss:0.426972 [32064/60000]\n",
      "loss:0.436801 [38464/60000]\n",
      "loss:0.607100 [44864/60000]\n",
      "loss:0.561801 [51264/60000]\n",
      "loss:0.402693 [57664/60000]\n",
      "testE: \n",
      " Acc: 83.8%, AVG LOSS: 0.455598 \n",
      "\n",
      "epoch : 74\n",
      "---------------------------------------\n",
      "loss:0.294119 [   64/60000]\n",
      "loss:0.462820 [ 6464/60000]\n",
      "loss:0.271118 [12864/60000]\n",
      "loss:0.479658 [19264/60000]\n",
      "loss:0.406271 [25664/60000]\n",
      "loss:0.425723 [32064/60000]\n",
      "loss:0.435430 [38464/60000]\n",
      "loss:0.605443 [44864/60000]\n",
      "loss:0.560352 [51264/60000]\n",
      "loss:0.401844 [57664/60000]\n",
      "testE: \n",
      " Acc: 83.8%, AVG LOSS: 0.454616 \n",
      "\n",
      "epoch : 75\n",
      "---------------------------------------\n",
      "loss:0.292494 [   64/60000]\n",
      "loss:0.461429 [ 6464/60000]\n",
      "loss:0.270140 [12864/60000]\n",
      "loss:0.478323 [19264/60000]\n",
      "loss:0.404336 [25664/60000]\n",
      "loss:0.424427 [32064/60000]\n",
      "loss:0.434106 [38464/60000]\n",
      "loss:0.603811 [44864/60000]\n",
      "loss:0.558967 [51264/60000]\n",
      "loss:0.401072 [57664/60000]\n",
      "testE: \n",
      " Acc: 83.9%, AVG LOSS: 0.453655 \n",
      "\n",
      "epoch : 76\n",
      "---------------------------------------\n",
      "loss:0.290890 [   64/60000]\n",
      "loss:0.460069 [ 6464/60000]\n",
      "loss:0.269220 [12864/60000]\n",
      "loss:0.477002 [19264/60000]\n",
      "loss:0.402425 [25664/60000]\n",
      "loss:0.423118 [32064/60000]\n",
      "loss:0.432751 [38464/60000]\n",
      "loss:0.602203 [44864/60000]\n",
      "loss:0.557562 [51264/60000]\n",
      "loss:0.400296 [57664/60000]\n",
      "testE: \n",
      " Acc: 83.9%, AVG LOSS: 0.452706 \n",
      "\n",
      "epoch : 77\n",
      "---------------------------------------\n",
      "loss:0.289340 [   64/60000]\n",
      "loss:0.458751 [ 6464/60000]\n",
      "loss:0.268339 [12864/60000]\n",
      "loss:0.475723 [19264/60000]\n",
      "loss:0.400466 [25664/60000]\n",
      "loss:0.421809 [32064/60000]\n",
      "loss:0.431393 [38464/60000]\n",
      "loss:0.600641 [44864/60000]\n",
      "loss:0.556250 [51264/60000]\n",
      "loss:0.399608 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.0%, AVG LOSS: 0.451777 \n",
      "\n",
      "epoch : 78\n",
      "---------------------------------------\n",
      "loss:0.287768 [   64/60000]\n",
      "loss:0.457424 [ 6464/60000]\n",
      "loss:0.267495 [12864/60000]\n",
      "loss:0.474443 [19264/60000]\n",
      "loss:0.398548 [25664/60000]\n",
      "loss:0.420531 [32064/60000]\n",
      "loss:0.430053 [38464/60000]\n",
      "loss:0.599096 [44864/60000]\n",
      "loss:0.554881 [51264/60000]\n",
      "loss:0.398875 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.0%, AVG LOSS: 0.450857 \n",
      "\n",
      "epoch : 79\n",
      "---------------------------------------\n",
      "loss:0.286233 [   64/60000]\n",
      "loss:0.456053 [ 6464/60000]\n",
      "loss:0.266681 [12864/60000]\n",
      "loss:0.473149 [19264/60000]\n",
      "loss:0.396607 [25664/60000]\n",
      "loss:0.419266 [32064/60000]\n",
      "loss:0.428713 [38464/60000]\n",
      "loss:0.597554 [44864/60000]\n",
      "loss:0.553604 [51264/60000]\n",
      "loss:0.398233 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.0%, AVG LOSS: 0.449948 \n",
      "\n",
      "epoch : 80\n",
      "---------------------------------------\n",
      "loss:0.284760 [   64/60000]\n",
      "loss:0.454724 [ 6464/60000]\n",
      "loss:0.265922 [12864/60000]\n",
      "loss:0.471874 [19264/60000]\n",
      "loss:0.394705 [25664/60000]\n",
      "loss:0.418065 [32064/60000]\n",
      "loss:0.427366 [38464/60000]\n",
      "loss:0.595978 [44864/60000]\n",
      "loss:0.552330 [51264/60000]\n",
      "loss:0.397572 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.0%, AVG LOSS: 0.449053 \n",
      "\n",
      "epoch : 81\n",
      "---------------------------------------\n",
      "loss:0.283352 [   64/60000]\n",
      "loss:0.453409 [ 6464/60000]\n",
      "loss:0.265181 [12864/60000]\n",
      "loss:0.470625 [19264/60000]\n",
      "loss:0.392846 [25664/60000]\n",
      "loss:0.416858 [32064/60000]\n",
      "loss:0.426054 [38464/60000]\n",
      "loss:0.594350 [44864/60000]\n",
      "loss:0.551098 [51264/60000]\n",
      "loss:0.396954 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.1%, AVG LOSS: 0.448163 \n",
      "\n",
      "epoch : 82\n",
      "---------------------------------------\n",
      "loss:0.282015 [   64/60000]\n",
      "loss:0.452109 [ 6464/60000]\n",
      "loss:0.264469 [12864/60000]\n",
      "loss:0.469440 [19264/60000]\n",
      "loss:0.390994 [25664/60000]\n",
      "loss:0.415641 [32064/60000]\n",
      "loss:0.424785 [38464/60000]\n",
      "loss:0.592744 [44864/60000]\n",
      "loss:0.549892 [51264/60000]\n",
      "loss:0.396328 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.1%, AVG LOSS: 0.447297 \n",
      "\n",
      "epoch : 83\n",
      "---------------------------------------\n",
      "loss:0.280676 [   64/60000]\n",
      "loss:0.450779 [ 6464/60000]\n",
      "loss:0.263771 [12864/60000]\n",
      "loss:0.468246 [19264/60000]\n",
      "loss:0.389186 [25664/60000]\n",
      "loss:0.414500 [32064/60000]\n",
      "loss:0.423547 [38464/60000]\n",
      "loss:0.591198 [44864/60000]\n",
      "loss:0.548666 [51264/60000]\n",
      "loss:0.395730 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.2%, AVG LOSS: 0.446446 \n",
      "\n",
      "epoch : 84\n",
      "---------------------------------------\n",
      "loss:0.279352 [   64/60000]\n",
      "loss:0.449468 [ 6464/60000]\n",
      "loss:0.263075 [12864/60000]\n",
      "loss:0.467060 [19264/60000]\n",
      "loss:0.387469 [25664/60000]\n",
      "loss:0.413379 [32064/60000]\n",
      "loss:0.422360 [38464/60000]\n",
      "loss:0.589730 [44864/60000]\n",
      "loss:0.547451 [51264/60000]\n",
      "loss:0.395173 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.2%, AVG LOSS: 0.445600 \n",
      "\n",
      "epoch : 85\n",
      "---------------------------------------\n",
      "loss:0.278079 [   64/60000]\n",
      "loss:0.448195 [ 6464/60000]\n",
      "loss:0.262394 [12864/60000]\n",
      "loss:0.465881 [19264/60000]\n",
      "loss:0.385824 [25664/60000]\n",
      "loss:0.412237 [32064/60000]\n",
      "loss:0.421218 [38464/60000]\n",
      "loss:0.588321 [44864/60000]\n",
      "loss:0.546174 [51264/60000]\n",
      "loss:0.394580 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.2%, AVG LOSS: 0.444763 \n",
      "\n",
      "epoch : 86\n",
      "---------------------------------------\n",
      "loss:0.276861 [   64/60000]\n",
      "loss:0.446972 [ 6464/60000]\n",
      "loss:0.261693 [12864/60000]\n",
      "loss:0.464691 [19264/60000]\n",
      "loss:0.384072 [25664/60000]\n",
      "loss:0.411127 [32064/60000]\n",
      "loss:0.420054 [38464/60000]\n",
      "loss:0.586960 [44864/60000]\n",
      "loss:0.544903 [51264/60000]\n",
      "loss:0.393988 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.3%, AVG LOSS: 0.443937 \n",
      "\n",
      "epoch : 87\n",
      "---------------------------------------\n",
      "loss:0.275621 [   64/60000]\n",
      "loss:0.445752 [ 6464/60000]\n",
      "loss:0.260983 [12864/60000]\n",
      "loss:0.463507 [19264/60000]\n",
      "loss:0.382353 [25664/60000]\n",
      "loss:0.409990 [32064/60000]\n",
      "loss:0.418893 [38464/60000]\n",
      "loss:0.585607 [44864/60000]\n",
      "loss:0.543765 [51264/60000]\n",
      "loss:0.393414 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.4%, AVG LOSS: 0.443122 \n",
      "\n",
      "epoch : 88\n",
      "---------------------------------------\n",
      "loss:0.274414 [   64/60000]\n",
      "loss:0.444556 [ 6464/60000]\n",
      "loss:0.260294 [12864/60000]\n",
      "loss:0.462320 [19264/60000]\n",
      "loss:0.380660 [25664/60000]\n",
      "loss:0.408860 [32064/60000]\n",
      "loss:0.417706 [38464/60000]\n",
      "loss:0.584240 [44864/60000]\n",
      "loss:0.542693 [51264/60000]\n",
      "loss:0.392861 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.4%, AVG LOSS: 0.442315 \n",
      "\n",
      "epoch : 89\n",
      "---------------------------------------\n",
      "loss:0.273231 [   64/60000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.443381 [ 6464/60000]\n",
      "loss:0.259587 [12864/60000]\n",
      "loss:0.461152 [19264/60000]\n",
      "loss:0.379027 [25664/60000]\n",
      "loss:0.407742 [32064/60000]\n",
      "loss:0.416546 [38464/60000]\n",
      "loss:0.582895 [44864/60000]\n",
      "loss:0.541615 [51264/60000]\n",
      "loss:0.392335 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.4%, AVG LOSS: 0.441516 \n",
      "\n",
      "epoch : 90\n",
      "---------------------------------------\n",
      "loss:0.272080 [   64/60000]\n",
      "loss:0.442218 [ 6464/60000]\n",
      "loss:0.258885 [12864/60000]\n",
      "loss:0.459980 [19264/60000]\n",
      "loss:0.377382 [25664/60000]\n",
      "loss:0.406580 [32064/60000]\n",
      "loss:0.415369 [38464/60000]\n",
      "loss:0.581575 [44864/60000]\n",
      "loss:0.540529 [51264/60000]\n",
      "loss:0.391831 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.4%, AVG LOSS: 0.440726 \n",
      "\n",
      "epoch : 91\n",
      "---------------------------------------\n",
      "loss:0.270942 [   64/60000]\n",
      "loss:0.441125 [ 6464/60000]\n",
      "loss:0.258134 [12864/60000]\n",
      "loss:0.458816 [19264/60000]\n",
      "loss:0.375751 [25664/60000]\n",
      "loss:0.405403 [32064/60000]\n",
      "loss:0.414164 [38464/60000]\n",
      "loss:0.580265 [44864/60000]\n",
      "loss:0.539472 [51264/60000]\n",
      "loss:0.391331 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.4%, AVG LOSS: 0.439947 \n",
      "\n",
      "epoch : 92\n",
      "---------------------------------------\n",
      "loss:0.269825 [   64/60000]\n",
      "loss:0.440016 [ 6464/60000]\n",
      "loss:0.257438 [12864/60000]\n",
      "loss:0.457609 [19264/60000]\n",
      "loss:0.374140 [25664/60000]\n",
      "loss:0.404283 [32064/60000]\n",
      "loss:0.412948 [38464/60000]\n",
      "loss:0.579027 [44864/60000]\n",
      "loss:0.538321 [51264/60000]\n",
      "loss:0.390876 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.4%, AVG LOSS: 0.439175 \n",
      "\n",
      "epoch : 93\n",
      "---------------------------------------\n",
      "loss:0.268740 [   64/60000]\n",
      "loss:0.438846 [ 6464/60000]\n",
      "loss:0.256725 [12864/60000]\n",
      "loss:0.456454 [19264/60000]\n",
      "loss:0.372570 [25664/60000]\n",
      "loss:0.403148 [32064/60000]\n",
      "loss:0.411681 [38464/60000]\n",
      "loss:0.577787 [44864/60000]\n",
      "loss:0.537151 [51264/60000]\n",
      "loss:0.390473 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.5%, AVG LOSS: 0.438411 \n",
      "\n",
      "epoch : 94\n",
      "---------------------------------------\n",
      "loss:0.267687 [   64/60000]\n",
      "loss:0.437677 [ 6464/60000]\n",
      "loss:0.256049 [12864/60000]\n",
      "loss:0.455280 [19264/60000]\n",
      "loss:0.370918 [25664/60000]\n",
      "loss:0.401975 [32064/60000]\n",
      "loss:0.410437 [38464/60000]\n",
      "loss:0.576495 [44864/60000]\n",
      "loss:0.536008 [51264/60000]\n",
      "loss:0.389985 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.5%, AVG LOSS: 0.437657 \n",
      "\n",
      "epoch : 95\n",
      "---------------------------------------\n",
      "loss:0.266702 [   64/60000]\n",
      "loss:0.436518 [ 6464/60000]\n",
      "loss:0.255461 [12864/60000]\n",
      "loss:0.454087 [19264/60000]\n",
      "loss:0.369303 [25664/60000]\n",
      "loss:0.400926 [32064/60000]\n",
      "loss:0.409293 [38464/60000]\n",
      "loss:0.575235 [44864/60000]\n",
      "loss:0.534886 [51264/60000]\n",
      "loss:0.389505 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.5%, AVG LOSS: 0.436910 \n",
      "\n",
      "epoch : 96\n",
      "---------------------------------------\n",
      "loss:0.265751 [   64/60000]\n",
      "loss:0.435401 [ 6464/60000]\n",
      "loss:0.254926 [12864/60000]\n",
      "loss:0.452943 [19264/60000]\n",
      "loss:0.367797 [25664/60000]\n",
      "loss:0.399884 [32064/60000]\n",
      "loss:0.408152 [38464/60000]\n",
      "loss:0.573904 [44864/60000]\n",
      "loss:0.533773 [51264/60000]\n",
      "loss:0.389084 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.6%, AVG LOSS: 0.436170 \n",
      "\n",
      "epoch : 97\n",
      "---------------------------------------\n",
      "loss:0.264829 [   64/60000]\n",
      "loss:0.434309 [ 6464/60000]\n",
      "loss:0.254407 [12864/60000]\n",
      "loss:0.451752 [19264/60000]\n",
      "loss:0.366302 [25664/60000]\n",
      "loss:0.398852 [32064/60000]\n",
      "loss:0.407076 [38464/60000]\n",
      "loss:0.572615 [44864/60000]\n",
      "loss:0.532711 [51264/60000]\n",
      "loss:0.388656 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.6%, AVG LOSS: 0.435440 \n",
      "\n",
      "epoch : 98\n",
      "---------------------------------------\n",
      "loss:0.263911 [   64/60000]\n",
      "loss:0.433185 [ 6464/60000]\n",
      "loss:0.253898 [12864/60000]\n",
      "loss:0.450593 [19264/60000]\n",
      "loss:0.364801 [25664/60000]\n",
      "loss:0.397804 [32064/60000]\n",
      "loss:0.406015 [38464/60000]\n",
      "loss:0.571297 [44864/60000]\n",
      "loss:0.531658 [51264/60000]\n",
      "loss:0.388255 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.6%, AVG LOSS: 0.434720 \n",
      "\n",
      "epoch : 99\n",
      "---------------------------------------\n",
      "loss:0.263036 [   64/60000]\n",
      "loss:0.432084 [ 6464/60000]\n",
      "loss:0.253401 [12864/60000]\n",
      "loss:0.449425 [19264/60000]\n",
      "loss:0.363370 [25664/60000]\n",
      "loss:0.396763 [32064/60000]\n",
      "loss:0.404942 [38464/60000]\n",
      "loss:0.569970 [44864/60000]\n",
      "loss:0.530588 [51264/60000]\n",
      "loss:0.387877 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.7%, AVG LOSS: 0.434004 \n",
      "\n",
      "epoch : 100\n",
      "---------------------------------------\n",
      "loss:0.262176 [   64/60000]\n",
      "loss:0.431019 [ 6464/60000]\n",
      "loss:0.252913 [12864/60000]\n",
      "loss:0.448296 [19264/60000]\n",
      "loss:0.361916 [25664/60000]\n",
      "loss:0.395763 [32064/60000]\n",
      "loss:0.403878 [38464/60000]\n",
      "loss:0.568761 [44864/60000]\n",
      "loss:0.529567 [51264/60000]\n",
      "loss:0.387474 [57664/60000]\n",
      "testE: \n",
      " Acc: 84.8%, AVG LOSS: 0.433294 \n",
      "\n",
      "asdsdfdfg\n"
     ]
    }
   ],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "opt=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "epoch=100\n",
    "\n",
    "for t in range(epoch):\n",
    "    \n",
    "    print(f'epoch : {t+1}\\n---------------------------------------')\n",
    "    \n",
    "    train_loop(train_load,model,loss_fn,opt)\n",
    "    test_loop(test_load, model,loss_fn)\n",
    "    \n",
    "print('asdsdfdfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "651360dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4f391c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.vgg16(weights='IMAGENET1K_V1')\n",
    "#model=models.vgg16(weights='IMAGENET1K_V1')\n",
    "torch.save(model.state_dict(),'model_weights.pth')\n",
    "#torch.save(model.state_dict(),'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6f55a3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=models.vgg16()\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a4b47ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'model.pth')\n",
    "modle=torch.load('model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22615f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d7355a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d255b534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a0610f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f17d8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7cb3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2982770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a87b77f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1429f265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3f0af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b29af0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0aae0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be25512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b7adf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
