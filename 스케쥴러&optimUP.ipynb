{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52d94052-2d83-4775-8b01-d47ac6566072",
   "metadata": {},
   "source": [
    "# Learning Rate Scheduling\n",
    "# AdamW, RAdam, QHAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51e4bd3f-1186-4647-ba95-f302d3c76892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR#LambdaLR\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader as loader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f37c4958-f938-4479-a12a-350ff42b67aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Compleat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=(0.485, 0.456, 0.406),\n",
    "        std=(0.229, 0.224, 0.225)\n",
    "    )\n",
    "])\n",
    "\n",
    "train_data=datasets.CIFAR10(root='./data', download=True,transform=transform)\n",
    "test_data=datasets.CIFAR10(root='./data',download=True, transform=transform)\n",
    "\n",
    "train_loader=loader(train_data,batch_size=64,shuffle=True,num_workers=4)\n",
    "test_loader=loader(test_data, batch_size=128,shuffle=True, num_workers=4)\n",
    "\n",
    "print(\"Compleat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01bf362e-22b1-4840-aabb-fc20321ddfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=models.resnet18(pretrained=True)\n",
    "num_ftrs=model.fc.in_features\n",
    "model.fc=nn.Linear(num_ftrs,10) # CIFAR-10은 10개 클래스\n",
    "model=model.to(device:= torch.device('cuda'if torch.cuda.is_available()else'cpu'))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4728d579-f58e-419c-9c80-c5900df61d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimy=optim.AdamW(model.parameters(),lr=1e-3,weight_decay=1e-4)\n",
    "criter=nn.CrossEntropyLoss()\n",
    "schedule=CosineAnnealingLR(optimy,T_max=20,eta_min=1e-5)\n",
    "\n",
    "num_epoch=50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d9ffc3ff-d720-45b1-9967-ccb7e7ac9975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 — Train Loss: 0.0030\n",
      "Epoch 2/50 — Train Loss: 0.0071\n",
      "Epoch 3/50 — Train Loss: 0.0097\n",
      "Epoch 4/50 — Train Loss: 0.0070\n",
      "Epoch 5/50 — Train Loss: 0.0095\n",
      "Epoch 6/50 — Train Loss: 0.0116\n",
      "Epoch 7/50 — Train Loss: 0.0086\n",
      "Epoch 8/50 — Train Loss: 0.0078\n",
      "Epoch 9/50 — Train Loss: 0.0100\n",
      "Epoch 10/50 — Train Loss: 0.0087\n",
      "Epoch 11/50 — Train Loss: 0.0068\n",
      "Epoch 12/50 — Train Loss: 0.0099\n",
      "Epoch 13/50 — Train Loss: 0.0103\n",
      "Epoch 14/50 — Train Loss: 0.0085\n",
      "Epoch 15/50 — Train Loss: 0.0072\n",
      "Epoch 16/50 — Train Loss: 0.0080\n",
      "Epoch 17/50 — Train Loss: 0.0069\n",
      "Epoch 18/50 — Train Loss: 0.0094\n",
      "Epoch 19/50 — Train Loss: 0.0089\n",
      "Epoch 20/50 — Train Loss: 0.0067\n",
      "Epoch 21/50 — Train Loss: 0.0063\n",
      "Epoch 22/50 — Train Loss: 0.0077\n",
      "Epoch 23/50 — Train Loss: 0.0086\n",
      "Epoch 24/50 — Train Loss: 0.0084\n",
      "Epoch 25/50 — Train Loss: 0.0070\n",
      "Epoch 26/50 — Train Loss: 0.0060\n",
      "Epoch 27/50 — Train Loss: 0.0073\n",
      "Epoch 28/50 — Train Loss: 0.0066\n",
      "Epoch 29/50 — Train Loss: 0.0076\n",
      "Epoch 30/50 — Train Loss: 0.0066\n",
      "Epoch 31/50 — Train Loss: 0.0061\n",
      "Epoch 32/50 — Train Loss: 0.0056\n",
      "Epoch 33/50 — Train Loss: 0.0072\n",
      "Epoch 34/50 — Train Loss: 0.0047\n",
      "Epoch 35/50 — Train Loss: 0.0069\n",
      "Epoch 36/50 — Train Loss: 0.0035\n",
      "Epoch 37/50 — Train Loss: 0.0067\n",
      "Epoch 38/50 — Train Loss: 0.0071\n",
      "Epoch 39/50 — Train Loss: 0.0079\n",
      "Epoch 40/50 — Train Loss: 0.0052\n",
      "Epoch 41/50 — Train Loss: 0.0057\n",
      "Epoch 42/50 — Train Loss: 0.0061\n",
      "Epoch 43/50 — Train Loss: 0.0068\n",
      "Epoch 44/50 — Train Loss: 0.0055\n",
      "Epoch 45/50 — Train Loss: 0.0059\n",
      "Epoch 46/50 — Train Loss: 0.0044\n",
      "Epoch 47/50 — Train Loss: 0.0066\n",
      "Epoch 48/50 — Train Loss: 0.0054\n",
      "Epoch 49/50 — Train Loss: 0.0058\n",
      "Epoch 50/50 — Train Loss: 0.0049\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    total=0.0\n",
    "    for data,target in train_loader:\n",
    "        data=data.to(device)\n",
    "        target=target.to(device)\n",
    "        optimy.zero_grad()\n",
    "        out=model(data)\n",
    "        loss=criter(out, target)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=1.0)\n",
    "        optimy.step()\n",
    "        total+=loss.item()*data.size(0)\n",
    "    schedule.step()\n",
    "    train_loss=total/len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epoch} — Train Loss: {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5bb0b15b-cb1c-4cfa-b880-0454465a1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdamW (Decoupled Weight Decay)\\\n",
    "#Decoupled Weight Decay는 weight decay(𝜆) 항을 옵티마이저 업데이트와 분리해,\n",
    "#학습률 스케일과 독립적으로 작동시킵니다\n",
    "lr=1e-3\n",
    "optimy=optim.AdamW(model.parameters(),lr=lr,weight_decay=1e-2)\n",
    "# Decoupled L2 페널티 :contentReference[oaicite:11]{index=11})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f35be848-4986-4940-a243-96edc61d9c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAdam (Rectified Adam)\n",
    "optimy=optim.RAdam(model.parameters(),lr=lr,betas=(0.9,0.999), eps=1e-8)\n",
    "#RAdam은 초기 분산 추정의 불안정을 워밍업 형태로 보정한 옵티마이저로,\n",
    "#초반에는 Momentum SGD처럼 동작하다가 이후 Adam 업데이트로 전환됩니다 \n",
    "# :contentReference[oaicite:13]{index=13}\n",
    "#0.088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45977120-bd79-4ae7-8722-feda89f1a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QHAdam (Quasi-Hyperbolic Adam)\n",
    "#QHAdam은 Adam의 1·2차 모멘트 추정에 Quasi-Hyperbolic Momentum을 적용해,\n",
    "#plain SGD와 momentum SGD의 장점을 가중 평균하듯 결합합니다\n",
    "\n",
    "from qhoptim.pyt import QHAdam as qha\n",
    "optimy=qha(model.parameters(), lr=lr, nus=(0.7,1.0), betas=(0.995,0.999), weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ea2bf-018a-482e-bc8d-17f6ab16cc97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12b85da9-fced-470a-a8ce-6217a4f4e62d",
   "metadata": {},
   "source": [
    "30초 동안 생각함\r\n",
    "\r\n",
    "\r\n",
    "아래는 **AdamW**, **RAdam**, **QHAdam** 세 옵티마이저의 주요 하이퍼파라미터가 의미하는 바를 정리한 내용입니다. 각 파라미터가 어떻게 동작에 영향을 주는지 이론적인 설명과 함께, PyTorch(또는 qhoptim) 구현 시 기본값과 조정 팁을 제공하며, 관련 논문·문서에서 발췌한 내용을 풍부한 인용과 함께 담았습니다.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 1. AdamW의 주요 파라미터\r\n",
    "\r\n",
    "### 1.1 `weight_decay`\r\n",
    "\r\n",
    "AdamW에서의 weight decay(𝜆)는 **파라미터 업데이트** 단계에서 직접 $\\theta \\leftarrow \\theta - \\eta\\,\\bigl(\\hat m_t / (\\sqrt{\\hat v_t} + \\epsilon)\\bigr) - \\eta\\,\\lambda\\,\\theta$ 형태로 적용되는 **decoupled L2 규제** 계수입니다.\r\n",
    "\r\n",
    "* 전통적 L2 정규화(Loss에 $\\tfrac{\\lambda}{2}\\|\\theta\\|^2$ 부가)와 달리, 학습률 스케일과 분리되어 **일관된 정규화 효과**를 냅니다 ([Medium][1], [Stack Overflow][2]).\r\n",
    "* 기본값은 `1e-2`이며, 일반화 성능을 높이려면 `1e-4`∼`1e-2` 사이에서 실험합니다 ([PyTorch][3]).\r\n",
    "\r\n",
    "### 1.2 `betas=(β₁, β₂)`\r\n",
    "\r\n",
    "* $\\beta_1$ (1차 모멘트 감쇠): 과거 그래디언트의 **지수이동평균**을 계산하는 계수 (기본값 `0.9`).\r\n",
    "* $\\beta_2$ (2차 모멘트 감쇠): 과거 그래디언트 제곱의 **지수이동평균**을 계산하는 계수 (기본값 `0.999`).\r\n",
    "* 이 두 값은 학습률을 **파라미터별로 조정**하는 핵심으로, 모멘텀과 RMSprop의 장점을 결합합니다 ([PyTorch][3]).\r\n",
    "\r\n",
    "### 1.3 `eps`\r\n",
    "\r\n",
    "* 분모 $\\sqrt{\\hat v_t} + \\epsilon$ 에 더해지는 작은 상수로, **수치 불안정성(NaN/Inf)** 방지를 위해 사용합니다.\r\n",
    "* 기본값 `1e-8`이며, FP16/Mixed-Precision 환경에서 **더 큰 ε** (`1e-6` 등)를 쓰면 안정성이 증가합니다 ([PyTorch][3]).\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 2. RAdam의 주요 파라미터\r\n",
    "\r\n",
    "### 2.1 `betas=(β₁, β₂)`\r\n",
    "\r\n",
    "* Adam과 동일하게, 1차·2차 모멘트 감쇠 계수입니다 (기본값 `(0.9, 0.999)`).\r\n",
    "* 초반 분산 추정 불안정 문제를 **자동 워밍업**으로 완화한 RAdam에서도 동일한 역할을 합니다 ([PyTorch][4]).\r\n",
    "\r\n",
    "### 2.2 `eps`\r\n",
    "\r\n",
    "* AdamW와 마찬가지로 분모 안정화를 위한 작은 상수 (`1e-8`).\r\n",
    "* RAdam 구현에 따라 `1e-6`을 기본으로 쓰는 경우도 있으므로, **문서 확인 후** 조정하세요 ([training-api.cerebras.ai][5]).\r\n",
    "\r\n",
    "### 2.3 `weight_decay`\r\n",
    "\r\n",
    "* L2 페널티 계수로, 기본값 `0`.\r\n",
    "* `decoupled_weight_decay=True`로 설정하면 **AdamW 방식**으로 weight decay를 분리 적용할 수 있습니다 ([PyTorch][4]).\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 3. QHAdam의 주요 파라미터\r\n",
    "\r\n",
    "설치: `pip install qhoptim` (Facebook Research 제공) ([facebookresearch.github.io][6]).\r\n",
    "\r\n",
    "### 3.1 `nus=(ν₁, ν₂)`\r\n",
    "\r\n",
    "* **Quasi-Hyperbolic Momentum (QHM)** 에서 모멘텀과 분산 감쇠를 즉시 조절하는 파라미터입니다.\r\n",
    "\r\n",
    "  * $\\nu_1$ (첫 번째 QHM): **모멘텀** 항의 즉각적 비중 조절 (추천값 `0.7`).\r\n",
    "  * $\\nu_2$ (두 번째 QHM): **분산(2차 모멘트)** 항의 즉각적 비중 조절 (추천값 `1.0`).\r\n",
    "* ν를 조절해 **SGD↔Momentum** 또는 **Adam↔RAdam** 형태로 유연하게 전환할 수 있습니다 ([facebookresearch.github.io][7]).\r\n",
    "\r\n",
    "### 3.2 `betas=(β₁, β₂)`\r\n",
    "\r\n",
    "* QHAdam에서도 **1차·2차 모멘트 감쇠** 계수로 작용하며, 기본값은 `(0.9, 0.999)`.\r\n",
    "* ν와 조합해 **즉각성**(plain gradient)과 **지속성**(momentum/RMS) 비중을 세밀하게 조절합니다 ([facebookresearch.github.io][6]).\r\n",
    "\r\n",
    "### 3.3 `eps`\r\n",
    "\r\n",
    "* 분모 안정화 용 상수 (`1e-8`).\r\n",
    "* QHAdam도 **분산 추정** 분모에 더해져, 작은 그래디언트에서도 수치적 안정성을 보장합니다 ([facebookresearch.github.io][6]).\r\n",
    "\r\n",
    "### 3.4 `weight_decay`\r\n",
    "\r\n",
    "* AdamW와 같이 decoupled L2 규제(기본값 `0`).\r\n",
    "* `decouple_weight_decay=True`로 설정하면 **QHAdamW** 형태로 독립 규제를 적용할 수 있습니다 ([facebookresearch.github.io][6]).\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "이상으로, **weight\\_decay**, **betas**, **nus**, **eps** 네 가지 파라미터가 각 옵티마이저에서 어떻게 동작하고, 기본값과 조정 팁은 무엇인지 살펴보았습니다. 실제 실험에서는 **학습률**과 함께 이들 값을 튜닝해 보면서, 안정성과 일반화 성능 간 균형을 맞추시는 것을 권장드립니다.\r\n",
    "\r\n",
    "[1]: https://yassin01.medium.com/adam-vs-adamw-understanding-weight-decay-and-its-impact-on-model-performance-b7414f0af8a1?utm_source=chatgpt.com \"Adam vs. AdamW: Understanding Weight Decay and Its Impact on ...\"\r\n",
    "[2]: https://stackoverflow.com/questions/64621585/pytorch-optimizer-adamw-and-adam-with-weight-decay?utm_source=chatgpt.com \"PyTorch Optimizer: AdamW and Adam with weight decay\"\r\n",
    "[3]: https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html?utm_source=chatgpt.com \"AdamW — PyTorch 2.7 documentation\"\r\n",
    "[4]: https://pytorch.org/docs/stable/generated/torch.optim.RAdam.html?utm_source=chatgpt.com \"RAdam — PyTorch 2.7 documentation\"\r\n",
    "[5]: https://training-api.cerebras.ai/en/latest/_modules/cerebras/pytorch/optim/RAdam.html?utm_source=chatgpt.com \"cerebras.pytorch.optim.RAdam\"\r\n",
    "[6]: https://facebookresearch.github.io/qhoptim/pyt.html?utm_source=chatgpt.com \"Quasi-hyperbolic optimizers for PyTorch — qhoptim 1.1.0 ...\"\r\n",
    "[7]: https://facebookresearch.github.io/qhoptim/?utm_source=chatgpt.com \"Quasi-hyperbolic optimization — qhoptim 1.1.0 documentation\"\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7cff9b-97da-400a-88bb-85fdec4e3dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f92ff6d-dd65-49ff-94d1-67f565bea151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a780e3c-f054-4e42-8512-d10fedf19a9d",
   "metadata": {},
   "source": [
    "\n",
    "\r\n",
    "\r\n",
    "AdamW, RAdam, QHAdam 세 옵티마이저의 주요 하이퍼파라미터(`weight_decay`, `betas`, `nus`, `eps`)가 모델 학습에 어떤 역할을 하는지 정리했습니다. 요약하면:\r\n",
    "\r\n",
    "* **`weight_decay`**: L2 정규화 강도(AdamW/QHAdam) 또는 0일 때 비활성(기본 RAdam)로, 파라미터 크기 제어를 직접 적용합니다.\r\n",
    "* **`betas=(β₁, β₂)`**: 1차·2차 모멘트(모멘텀·분산) 지수이동평균 감쇠율로, 과거 그래디언트 정보의 “기억 깊이”를 설정합니다.\r\n",
    "* **`nus=(ν₁, ν₂)`**(QHAdam 전용): QHM 방식으로 1·2차 모멘트 즉시 반영 비중을 조절해, 순수 SGD와 모멘텀의 중간 거동을 구현합니다.\r\n",
    "* **`eps`**: 분모 안정성을 위한 작은 상수로, 수치적 NaN/Inf 방지와 FP16 환경 대응을 돕습니다.\r\n",
    "\r\n",
    "아래에서 옵티마이저별로 각 파라미터가 구체적으로 어떤 의미인지, 기본값과 조정 팁을 살펴보세요.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 1. AdamW\r\n",
    "\r\n",
    "### 1.1 `weight_decay`\r\n",
    "\r\n",
    "* **Decoupled Weight Decay**: 파라미터 업데이트 직전에 직접\r\n",
    "  $\\theta \\leftarrow \\theta - \\eta\\,\\lambda\\,\\theta$ 형태로 L2 페널티를 적용합니다 ([PyTorch][1], [Papers with Code][2]).\r\n",
    "* 전통적 L2 정규화(Loss에 추가)와 달리, 학습률 스케일과 **독립적으로** 동작해 하이퍼파라미터 튜닝이 용이합니다 ([Origins AI][3]).\r\n",
    "* **기본값**: `0.01`. 일반화 성능을 위해 `1e-4`∼`1e-2` 범위에서 실험합니다 ([Learn R, Python & Data Science Online][4]).\r\n",
    "\r\n",
    "### 1.2 `betas=(β₁, β₂)`\r\n",
    "\r\n",
    "* $\\beta_1$: 1차 모멘트(모멘텀) EMA 감쇠율, 기본 `0.9` (과거 기울기를 90% 유지) ([Cross Validated][5]).\r\n",
    "* $\\beta_2$: 2차 모멘트(RMSprop) EMA 감쇠율, 기본 `0.999` (과거 제곱 기울기를 99.9% 유지) ([PyTorch Forums][6]).\r\n",
    "* 값이 클수록 과거 정보에 **더 큰 비중**을 두며, 작을수록 최신 기울기에 **더 민감**해집니다 ([Cross Validated][5]).\r\n",
    "\r\n",
    "### 1.3 `eps`\r\n",
    "\r\n",
    "* 분모 $\\sqrt{\\hat v_t} + \\epsilon$ 에 더해지는 작은 상수로, 수치적 **안정성**(NaN/Inf 방지)에 기여합니다 ([PyTorch][1]).\r\n",
    "* **기본값**: `1e-8`. FP16/Mixed Precision 환경 시 `1e-6` 등으로 늘리면 안정성이 더욱 향상됩니다 ([KDnuggets][7]).\r\n",
    "\r\n",
    "### 1.4 조합 팁\r\n",
    "\r\n",
    "* **스케줄러**: CosineAnnealingLR, StepLR 등과 함께 사용할 때 최적의 일반화 성능을 기대할 수 있습니다 ([Origins AI][3]).\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 2. RAdam\r\n",
    "\r\n",
    "### 2.1 `betas=(β₁, β₂)`\r\n",
    "\r\n",
    "* Adam과 동일하게, 1차·2차 모멘트 EMA 감쇠율입니다 (기본 `(0.9, 0.999)`) .\r\n",
    "* **Warmup** 효과를 내장해, 초기 분산 추정 불안정 문제를 자동 보정합니다 ([GitHub][8]).\r\n",
    "\r\n",
    "### 2.2 `eps`\r\n",
    "\r\n",
    "* AdamW와 마찬가지로 **수치 안전성**을 위한 상수 (`1e-8`), 일부 구현에서는 `1e-6` 기본인 경우도 있습니다 ([Facebook Research][9]).\r\n",
    "\r\n",
    "### 2.3 `weight_decay`\r\n",
    "\r\n",
    "* 기본값 `0`.\r\n",
    "* `decoupled_weight_decay=True` 로 설정하면 **AdamW 스타일**로 L2 규제를 분리 적용할 수 있습니다 ([PyTorch Forums][10]).\r\n",
    "\r\n",
    "### 2.4 핵심 효과\r\n",
    "\r\n",
    "* 초반 스텝에서는 **모멘텀 SGD**와 유사하게 동작하다가, 이후 **Adam** 업데이트로 전환해 안정적 수렴을 돕습니다 ([GitHub][8]).\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 3. QHAdam\r\n",
    "\r\n",
    "### 3.1 `nus=(ν₁, ν₂)`\r\n",
    "\r\n",
    "* Quasi-Hyperbolic Momentum(QHM) 기반 감쇠 파라미터로, 평범한 SGD 스텝과 모멘텀 스텝을 **가중 평균**하듯 결합합니다 ([Facebook Research][9]).\r\n",
    "\r\n",
    "  * $\\nu_1$: 모멘텀 즉시 반영 비중 (추천 `0.7`) ([OpenReview][11]).\r\n",
    "  * $\\nu_2$: 분산 즉시 반영 비중 (추천 `1.0`) ([OpenReview][11]).\r\n",
    "\r\n",
    "### 3.2 `betas=(β₁, β₂)`\r\n",
    "\r\n",
    "* 1·2차 모멘트 감쇠율로, 기본 `(0.9, 0.999)`.\r\n",
    "* QHM ν와 결합해 **순수 SGD**에서 **강한 모멘텀**까지 다양한 업데이트 거동을 실험할 수 있습니다 ([Papers with Code][12]).\r\n",
    "\r\n",
    "### 3.3 `eps`\r\n",
    "\r\n",
    "* 분모 안정화 상수 (`1e-8`), 그래디언트가 매우 작을 때 수치적 NaN을 방지합니다 ([Facebook Research][13]).\r\n",
    "\r\n",
    "### 3.4 `weight_decay`\r\n",
    "\r\n",
    "* 기본 `0`.\r\n",
    "* `decouple_weight_decay=True` 로 설정하면 **QHAdamW** 형태로, AdamW식 decoupled L2 규제를 쓸 수 있습니다 ([GitHub][14]).\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 참조 논문·문서\r\n",
    "\r\n",
    "1. Loshchilov & Hutter, “Decoupled Weight Decay Regularization” ([Papers with Code][2])\r\n",
    "2. Liu et al., “On the Variance of the Adaptive Learning Rate and Beyond” ([GitHub][8])\r\n",
    "3. Ma & Yarats, “Quasi-Hyperbolic Momentum and Adam for Deep Learning” ([OpenReview][11])\r\n",
    "\r\n",
    "위 파라미터들을 조합해, 다양한 학습 시나리오에서 최적화 성능과 일반화 능력을 극대화해 보세요!\r\n",
    "\r\n",
    "[1]: https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html?utm_source=chatgpt.com \"AdamW — PyTorch 2.7 documentation\"\r\n",
    "[2]: https://paperswithcode.com/method/adamw?utm_source=chatgpt.com \"AdamW Explained - Papers With Code\"\r\n",
    "[3]: https://originshq.com/blog/decoupled-weight-decay-regularization-bye-bye-adam-optimizer/?utm_source=chatgpt.com \"Decoupled Weight Decay Regularization: Bye Bye Adam Optimizer\"\r\n",
    "[4]: https://www.datacamp.com/tutorial/adamw-optimizer-in-pytorch?utm_source=chatgpt.com \"AdamW Optimizer in PyTorch Tutorial - DataCamp\"\r\n",
    "[5]: https://stats.stackexchange.com/questions/265400/deep-learning-how-does-beta-1-and-beta-2-in-the-adam-optimizer-affect-its-lear?utm_source=chatgpt.com \"Deep Learning: How does beta_1 and beta_2 in the Adam ...\"\r\n",
    "[6]: https://discuss.pytorch.org/t/the-impact-of-beta-value-in-adam-optimizer/153757?utm_source=chatgpt.com \"The impact of Beta value in adam optimizer - PyTorch Forums\"\r\n",
    "[7]: https://www.kdnuggets.com/2022/12/tuning-adam-optimizer-parameters-pytorch.html?utm_source=chatgpt.com \"Tuning Adam Optimizer Parameters in PyTorch - KDnuggets\"\r\n",
    "[8]: https://github.com/facebookresearch/qhoptim?utm_source=chatgpt.com \"facebookresearch/qhoptim: Implementations of quasi-hyperbolic ...\"\r\n",
    "[9]: https://facebookresearch.github.io/qhoptim/?utm_source=chatgpt.com \"Quasi-hyperbolic optimization — qhoptim 1.1.0 documentation\"\r\n",
    "[10]: https://discuss.pytorch.org/t/difference-between-adam-and-adamw-in-pytorch/109173?utm_source=chatgpt.com \"Difference between Adam and AdamW in pytorch - nlp\"\r\n",
    "[11]: https://openreview.net/pdf/d2ea4b4ed5c48630b8c757bb107e9d470a5957ff.pdf?utm_source=chatgpt.com \"[PDF] quasi-hyperbolic momentum and adam for - OpenReview\"\r\n",
    "[12]: https://paperswithcode.com/method/qhadam?utm_source=chatgpt.com \"QHAdam Explained | Papers With Code\"\r\n",
    "[13]: https://facebookresearch.github.io/qhoptim/pyt.html?utm_source=chatgpt.com \"Quasi-hyperbolic optimizers for PyTorch — qhoptim 1.1.0 ...\"\r\n",
    "[14]: https://github.com/iprally/qhadamw-pytorch?utm_source=chatgpt.com \"QHAdamW: Optimizer combining QHAdam and AdamW - GitHub\"\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94274591-648a-4c9d-a6c2-526a693456e2",
   "metadata": {},
   "source": [
    "**Explaining L2 regularization and L2 norm**\r\n",
    "\r\n",
    "L2 정규화와 L2 노름은 관련이 있지만 동일하지 않습니다. L2 노름은 벡터의 유클리드 거리, 즉 각 값의 제곱합에 대한 제곱근을 의미합니다. 반면 L2 정규화는 가중치에 대해 L2 노름의 제곱을 추가하여 모델의 복잡도를 제어합니다. 즉, L2 정규화는 L2 노름을 기반으로 하지만, 제약을 추가하는 방식이 다릅니다. 이 둘은 연결되어 있지만 개념적으로 다릅니다.\r\n",
    "\r\n",
    "\r\n",
    "6초 동안 생각함\r\n",
    "\r\n",
    "\r\n",
    "L2 정규화(L2 regularization)와 L2 노름(L2 norm)은 밀접하게 연관되어 있지만, **동일한 개념은 아닙니다**.\r\n",
    "\r\n",
    "## 1. L2 노름 (Euclidean Norm)\r\n",
    "\r\n",
    "* 벡터 $w = (w_1, w_2, \\dots, w_n)$에 대해\r\n",
    "\r\n",
    "  $$\r\n",
    "    \\|w\\|_2 = \\sqrt{\\,w_1^2 + w_2^2 + \\cdots + w_n^2\\,}\r\n",
    "  $$\r\n",
    "\r\n",
    "  으로 정의되는 **유클리드 거리** 혹은 **2-노름**입니다 ([Kaggle][1]).\r\n",
    "* 기하학적으로, 원점에서 벡터까지의 직선 거리를 나타냅니다.\r\n",
    "\r\n",
    "## 2. L2 정규화 (L2 Regularization)\r\n",
    "\r\n",
    "* 머신러닝 모델의 **과적합(overfitting)** 을 방지하기 위해 손실 함수에 **L2 노름의 제곱**을 패널티로 추가하는 기법입니다 ([Built In][2]).\r\n",
    "* 예를 들어, 회귀 손실 $L_{\\text{data}}(w)$에 대해\r\n",
    "\r\n",
    "  $$\r\n",
    "    L(w) = L_{\\text{data}}(w) + \\lambda \\,\\|w\\|_2^2\r\n",
    "  $$\r\n",
    "\r\n",
    "  와 같이 가중치 $w$의 **제곱 L2 노름**을 더해 줍니다.\r\n",
    "* 이 제곱 항 때문에 **ridge regression(능형 회귀)** 라고도 불립니다.\r\n",
    "\r\n",
    "## 3. 차이점 요약\r\n",
    "\r\n",
    "| 구분 | L2 노름 (`‖w‖₂`)        | L2 정규화 (`λ‖w‖₂²`)      |\r\n",
    "| -- | --------------------- | ---------------------- |\r\n",
    "| 정의 | 벡터 크기(거리)             | 손실 함수에 더하는 패널티 항       |\r\n",
    "| 수식 | $\\sqrt{\\sum_i w_i^2}$ | $\\lambda \\sum_i w_i^2$ |\r\n",
    "| 목적 | 거리·길이 측정              | 파라미터 축소·과적합 방지         |\r\n",
    "\r\n",
    "* **L2 정규화**는 **L2 노름**을 기반으로 하지만, 실제로는 “노름의 제곱”을 손실에 더하는 **정규화 기법**입니다 ([Analytics Vidhya][3]).\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "따라서 “L2 정규화가 L2 노름인가?”라는 질문에 대한 답은:\r\n",
    "\r\n",
    "> **L2 정규화는 L2 노름을 이용해 패널티 항을 추가하는 기법이며, L2 노름 자체와는 목적과 수식이 다릅니다.**\r\n",
    "\r\n",
    "[1]: https://www.kaggle.com/code/residentmario/l1-norms-versus-l2-norms?utm_source=chatgpt.com \"L1 Norms versus L2 Norms - Kaggle\"\r\n",
    "[2]: https://builtin.com/data-science/l2-regularization?utm_source=chatgpt.com \"L1 and L2 Regularization Methods, Explained | Built In\"\r\n",
    "[3]: https://www.analyticsvidhya.com/blog/2024/01/vector-norms-in-machine-learning-decoding-l1-and-l2-norms/?utm_source=chatgpt.com \"Vector Norms in Machine Learning: Decoding L1 and L2 Norms\"\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac782e-310a-4ab5-958e-917fd062e9ec",
   "metadata": {},
   "source": [
    "\n",
    "\r\n",
    "사용자는 \"회귀손실값+손실함수\\*L2노름 값이 L2 정규화인가?\"라고 묻고 있습니다. L2 정규화는 손실 함수에 L2 노름 제곱에 λ 값을 곱한 항을 더하는 방식입니다. 그들은 회귀손실값과 L2노름을 곱한다고 언급했지만, 올바른 식은 전체 손실 = 회귀손실 + λ \\* ||w||2^2입니다. 간단하게 말하면 네, L2 정규화는 가중치의 L2 노름 제곱에 λ를 곱해 손실 함수에 추가하는 것입니다.\r\n",
    "\r\n",
    "**검토 중**\r\n",
    "\r\n",
    "웹 검색이 필요하지 않을 수도 있지만, 가이드라인을 따라 참고문헌을 제공해야 해요. 이번에는 동적인 뉴스가 아니라 일반적인 머신러닝 개념이니까 웹을 사용할 필요는 없을 것 같네요. 그렇지만, 신뢰할 수 있는 고품질 자료에서 최소 3개의 인용을 확보해야 하므로, \"L2 regularization formula\"를 검색할 수 있을 것 같아요. 그래도 저는 이 개념에 대해 충분히 자신이 있네요.\r\n",
    "\r\n",
    "\r\n",
    "7초 동안 생각함\r\n",
    "\r\n",
    "\r\n",
    "아주 정확합니다. L2 정규화(L2 regularization)는 **원래의 손실 함수**(예: 회귀 손실)에 **L2 노름의 제곱**을 곱한 항을 더하는 방식입니다.\r\n",
    "\r\n",
    "즉, 모델 파라미터 $w$에 대해\r\n",
    "\r\n",
    "$$\r\n",
    "\\text{Total Loss}\r\n",
    "=\\;L_{\\rm data}(w)\\;+\\;\\lambda\\,\\|w\\|_2^2\r\n",
    "$$\r\n",
    "\r\n",
    "를 최소화하는 것이 바로 L2 정규화입니다.\r\n",
    "\r\n",
    "* 여기서 $L_{\\rm data}(w)$는 예컨대 **MSE(Mean Squared Error)** 같은 회귀 손실입니다.\r\n",
    "* $\\lambda>0$는 **정규화 계수**(weight decay)로, 패널티 강도를 조절합니다 ([Google for Developers][1], [Wikipedia][2]).\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 왜 “제곱” 노름인가?\r\n",
    "\r\n",
    "* L2 노름 $\\|w\\|_2$는 $\\sqrt{\\sum_i w_i^2}$ 이지만, 수식 편의를 위해 **노름의 제곱** $\\|w\\|_2^2=\\sum_i w_i^2$ 를 사용합니다.\r\n",
    "* 제곱을 쓰면 **미분**이 간단해지고, 연속·볼록(convex) 최적화가 보장됩니다 ([Medium][3], [Stack Overflow][4]).\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 정리\r\n",
    "\r\n",
    "1. **기본 손실**: 회귀 문제라면 $L_{\\rm data}=\\mathrm{MSE}$.\r\n",
    "2. **정규화 항**: $\\lambda\\,\\|w\\|_2^2$.\r\n",
    "3. **총 손실**:\r\n",
    "\r\n",
    "   $$\r\n",
    "     \\mathrm{MSE}(y,\\hat y)\r\n",
    "     \\;+\\;\\lambda\\,\\sum_i w_i^2.\r\n",
    "   $$\r\n",
    "\r\n",
    "이렇게 하면 모델이 과도하게 큰 가중치를 갖지 못하도록 **패널티**를 부여하여 과적합을 방지하게 됩니다. ([Built In][5], [Medium][3])\r\n",
    "\r\n",
    "[1]: https://developers.google.com/machine-learning/crash-course/overfitting/regularization?utm_source=chatgpt.com \"Overfitting: L2 regularization | Machine Learning\"\r\n",
    "[2]: https://en.wikipedia.org/wiki/Regularization_%28mathematics%29?utm_source=chatgpt.com \"Regularization (mathematics)\"\r\n",
    "[3]: https://medium.com/%40alejandro.itoaramendia/l1-and-l2-regularization-part-1-a-complete-guide-51cf45bb4ade?utm_source=chatgpt.com \"L1 and L2 Regularization (Part 1): A Complete Guide - Medium\"\r\n",
    "[4]: https://stackoverflow.com/questions/58905671/compute-the-loss-of-l1-and-l2-regularization?utm_source=chatgpt.com \"Compute the Loss of L1 and L2 regularization - Stack Overflow\"\r\n",
    "[5]: https://builtin.com/data-science/l2-regularization?utm_source=chatgpt.com \"L1 and L2 Regularization Methods, Explained | Built In\"\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829e78ba-820f-427b-8f7f-47455481610e",
   "metadata": {},
   "source": [
    "\n",
    "\r\n",
    "\r\n",
    "`λ`(람다)는 L2 정규화 항의 **강도**를 조절하는 **하이퍼파라미터**입니다.\r\n",
    "\r\n",
    "* **역할**\r\n",
    "\r\n",
    "  * 원래 손실(예: MSE)에 더해지는 `λ‖w‖₂²` 항의 계수로,\r\n",
    "  * `λ`가 크면 가중치 `w`를 작게 만드는 제약이 강해져 **모델이 단순해지고 과적합이 줄어듭니다**.\r\n",
    "  * 반대로 `λ`가 작으면 정규화 효과가 약해져 **모델이 데이터에 더 잘 맞으려 하며** 과적합 위험이 커집니다.\r\n",
    "\r\n",
    "* **수식 예**\r\n",
    "\r\n",
    "  $$\r\n",
    "    \\mathcal{L}(w)\r\n",
    "    = \\underbrace{\\tfrac1N\\sum_i (y_i - \\hat y_i)^2}_{\\displaystyle\\text{MSE}}\r\n",
    "    \\;+\\;\\lambda\\,\\sum_j w_j^2.\r\n",
    "  $$\r\n",
    "\r\n",
    "* **튜닝 팁**\r\n",
    "\r\n",
    "  1. 보통 `10^{-4}`, `10^{-3}`, `10^{-2}` 처럼 **로그 스케일**로 탐색합니다.\r\n",
    "  2. 검증 데이터에서 손실 혹은 정확도를 관찰하며, **가장 좋은 성능을 내는 λ**를 선택합니다.\r\n",
    "  3. 학습률(`lr`)과 상호작용하므로, 종종 **lr과 λ를 함께** 그리드·랜덤·베이지안 탐색합니다.\r\n",
    "\r\n",
    "요약하자면, `λ`는 **모델 복잡도**와 **일반화 성능** 간의 균형을 맞추는 핵심 파라미터입니다.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59910fc7-441d-4680-af3b-deebc6913d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6230c4f-13a7-4291-a8ea-3c860f70b16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4da185-74da-4b4b-85ea-1c17d1cc1b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a9e85ac-0bb9-4c37-adac-5ae1abeebb5f",
   "metadata": {},
   "source": [
    "# 스케줄러"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dbb245-9afb-46fb-9ca1-5edc064d3ad9",
   "metadata": {},
   "source": [
    "1. LambdaLR\n",
    "동작: 사용자 정의 함수 lr_lambda(epoch)가 반환하는 값으로 매 에폭마다 학습률을 곱해 조정합니다 \n",
    "pytorch-argus.readthedocs.io.\n",
    "\n",
    "용도: 아주 유연한 커스텀 스케줄링이 필요할 때 사용합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bdfbba44-c278-410a-b3c5-182674d1b81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "scheduler=LambdaLR(optimy,lr_lambda=lambda t:0.95**t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b11dd7-8e91-403d-b1fb-38532cf9dd38",
   "metadata": {},
   "source": [
    "2. MultiplicativeLR\n",
    "동작: lr_lambda(epoch) 함수를 매 에폭마다 호출해, 현재 학습률에 그 결과를 곱합니다 \n",
    "PyTorch\n",
    "\n",
    "용도: 지수적(Exponential) 감소 외에 임의 곡선 형태가 필요할 때 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "535f4dd6-a0f9-4c29-b31f-977c4120a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import MultiplicativeLR\n",
    "scheduler=MultiplicativeLR(optimy, lr_lambda=lambda t:0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cee116-097e-4f89-ae9d-9803ad657666",
   "metadata": {},
   "source": [
    "3. StepLR\n",
    "동작: 매 step_size 에폭마다 학습률을 gamma만큼 곱해 감소시킵니다 \n",
    "PyTorch\n",
    ".\n",
    "\n",
    "용도: 일정 주기로 간헐적 대폭 감소가 필요할 때 적합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a4239bff-bdb7-417e-a848-e787b38210be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "scheduler=StepLR(optimy,step_size=10,gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0b6538-e8ea-4a74-a0c4-98772e163a3d",
   "metadata": {},
   "source": [
    "4. MultiStepLR\n",
    "동작: milestones 리스트에 지정된 에폭에서 학습률을 gamma만큼 감소시킵니다 \n",
    "pytorch-argus.readthedocs.io\n",
    ".\n",
    "\n",
    "용도: 비균등한 에폭 간격으로 스케줄링할 때 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5b5a49ce-7b94-4974-86c0-7d6d716fb26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "scheduler=MultiStepLR(optimy, milestones=[30, 80], gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6568edbc-bcfe-4ae1-9f98-42bc4f7080dc",
   "metadata": {},
   "source": [
    "5. ExponentialLR\n",
    "동작: 매 에폭마다 학습률을 gamma만큼 지수적으로 감소시킵니다 \n",
    "pytorch-argus.readthedocs.io\n",
    ".\n",
    "\n",
    "용도: 완만하지만 지속적인 학습률 감소가 필요할 때 적합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "96960577-2665-447e-af31-c074f0cc2427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "scheduler=ExponentialLR(optimy, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb651a-df8f-4344-bc67-d6502bde35ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5d66e16-9684-4016-9c8d-2de70e625d75",
   "metadata": {},
   "source": [
    "# 주기적 및 성능 기반 스케줄러"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432d50b7-28f5-430f-ac49-5d0738b5783c",
   "metadata": {},
   "source": [
    "6. CosineAnnealingLR\n",
    "동작: 코사인 곡선을 따라 학습률을 eta_min에서 eta_max 사이로 조절합니다 \n",
    "PyTorch\n",
    ".\n",
    "\n",
    "용도: 부드러운 주기적 감소가 필요한 대규모 학습에 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f92ea97e-9970-4cbe-b64f-64c31bb08c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "scheduler=CosineAnnealingLR(optimy, T_max=50, eta_min=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35a8a8c-1732-4451-8ac7-8986701351fb",
   "metadata": {},
   "source": [
    "7. CosineAnnealingWarmRestarts\n",
    "동작: CosineAnnealing을 반복(restart)해 학습률을 여러 번 부활시키며 감소시킵니다 \n",
    "PyTorch\n",
    ".\n",
    "\n",
    "용도: 한 번의 주기가 아닌 여러 주기로 학습률을 재증폭하고자 할 때 사용합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a9fd59d0-c78d-4783-8ce7-76907c8f83e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "scheduler=CosineAnnealingWarmRestarts(optimy, T_0=10,T_mult=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d63a851-1639-437f-a3b1-a51518899748",
   "metadata": {},
   "source": [
    "8. ReduceLROnPlateau\n",
    "동작: 검증(loss 또는 accuracy)이 patience 에폭 동안 개선되지 않으면 학습률을 factor만큼 감소시킵니다 \n",
    "GeeksforGeeks\n",
    ".\n",
    "\n",
    "용도: 학습 정체 구간에 자동 반응해 LR을 줄이려 할 때 적합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cd2e6bad-0a57-4942-a60d-b4da75f3f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "scheduler=ReduceLROnPlateau(optimy, mode='min',factor=0.5,patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df763ed-a781-481f-9a99-42477014296f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "816d715a-9e3a-4f74-8b36-d637cff0786c",
   "metadata": {},
   "source": [
    "# 배치 단위 스케줄러 및 체이닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317b12e9-77f4-4926-bc6f-f60087a2523d",
   "metadata": {},
   "source": [
    "9. CyclicLR\n",
    "동작: 학습률을 “최저→최고→최저” 사이에서 삼각형(triangle) 모양으로 반복 변화시킵니다 \n",
    "PyTorch\n",
    ".\n",
    "\n",
    "용도: 빠른 수렴과 탈출을 위해 주기적으로 LR을 변동시킬 때 사용합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "dd12d332-8d95-49b2-ba92-d817e718d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "scheduler=CyclicLR(optimy, base_lr=1e-5,max_lr=1e-3,step_size_up=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4df2dc-f6e0-4b54-addf-1b2058ba2008",
   "metadata": {},
   "source": [
    "10. OneCycleLR\n",
    "동작: 학습률을 “초기→최고→초기보다 낮은 최저”로 배치 단위(batch)에서 조절합니다 \n",
    "PyTorch\n",
    ".\n",
    "\n",
    "용도: Super-convergence 기법을 활용해 매우 빠른 학습이 필요할 때 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "358be6d7-761b-4a62-9f48-1736da6386b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "scheduler=OneCycleLR(optimy,max_lr=1e-3,total_steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714d2dfe-b53c-4104-8a9a-2dc31d7a6664",
   "metadata": {},
   "source": [
    "11. ChainedScheduler\n",
    "동작: 여러 스케줄러를 순차적으로 연결해 step()을 한 번에 호출할 수 있게 해 줍니다 \n",
    "PyTorch\n",
    ".\n",
    "\n",
    "용도: Warmup + CosineAnnealing 같이 다단계 스케줄링 파이프라인을 구현할 때 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "36c4bc5f-c7f9-4ea0-995b-b8226d6752db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.AdamW(model.parameters(), lr=lr,weight_decay=1e-2)\n",
    "total_warmup_steps=10\n",
    "# total_warmup_steps 만큼 0 → 1 비율로 증가\n",
    "def warmup_lambda(step):\n",
    "    return min((step + 1) / total_warmup_steps, 1.0)\n",
    "\n",
    "warmup_scheduler = LambdaLR(optimizer, lr_lambda=warmup_lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f18ea148-47d9-43b6-b078-4b2c4bdf888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "total_epochs=3\n",
    "minimum_lr=9\n",
    "cosine_scheduler = CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=total_epochs,  # 코사인 한 주기당 에폭 수\n",
    "    eta_min=minimum_lr   # 최저 학습률\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "76206a11-936a-4f00-8ae6-a687077dbca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ChainedScheduler\n",
    "scheduler = ChainedScheduler([warmup_scheduler, cosine_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "945a6355-4fcb-4193-9e83-37ccc1701c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ChainedScheduler\n",
    "\n",
    "# 사용자가 정의한 여러 스케줄러\n",
    "warmup_scheduler   = LambdaLR(optimy,lr_lambda=lambda t:0.95**t)\n",
    "cosine_scheduler   = ExponentialLR(optimy, gamma=0.95)\n",
    "plateau_scheduler  = MultiplicativeLR(optimy, lr_lambda=lambda t:0.9)\n",
    "\n",
    "# 원하는 순서와 개수로 묶어 한 세트로 동작시키기\n",
    "scheduler = ChainedScheduler([\n",
    "    warmup_scheduler,\n",
    "    cosine_scheduler,\n",
    "    plateau_scheduler\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dad34a1-47bb-4dcc-b35f-f6664f5554b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31511508-667f-4a7b-a45b-1d3b9e811c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e1b01d-7711-4315-9a43-b2746c599acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b948c-09ea-45ab-b49e-edd61b663e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76944b-3515-49d2-9cea-02a100bfc104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566758d1-31dc-4c8f-bf85-2629aec9b134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72aafca-c30f-4f9f-823f-5e1b144dac4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f5e179-fbbf-459d-8681-f01578a709e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CUDA 12.4)",
   "language": "python",
   "name": "cuda124"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
